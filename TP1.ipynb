{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMxeKeAlQq5Kd1KRdRKxLjK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsl3468a/IA/blob/master/TP1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B5LOy92AZfT",
        "outputId": "74bb2f15-7121-466a-ea6a-759fd9d9e368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-16 23:31:12--  https://raw.githubusercontent.com/elbixos/L3_IA/master/Cours/TP/winequality-red.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84199 (82K) [text/plain]\n",
            "Saving to: ‘winequality-red.csv’\n",
            "\n",
            "\rwinequality-red.csv   0%[                    ]       0  --.-KB/s               \rwinequality-red.csv 100%[===================>]  82.23K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2022-03-16 23:31:13 (10.4 MB/s) - ‘winequality-red.csv’ saved [84199/84199]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "url=\"https://raw.githubusercontent.com/elbixos/L3_IA/master/Cours/TP/winequality-red.csv\"\n",
        "\n",
        "!wget $url"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename=\"winequality-red.csv\"\n",
        "data = pd.read_csv(filename,sep=';')\n",
        "\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCrojAh2A4qf",
        "outputId": "5b0f846a-451b-4625-ee8d-5e14345e3474"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1599 entries, 0 to 1598\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed acidity         1599 non-null   float64\n",
            " 1   volatile acidity      1599 non-null   float64\n",
            " 2   citric acid           1599 non-null   float64\n",
            " 3   residual sugar        1599 non-null   float64\n",
            " 4   chlorides             1599 non-null   float64\n",
            " 5   free sulfur dioxide   1599 non-null   float64\n",
            " 6   total sulfur dioxide  1599 non-null   float64\n",
            " 7   density               1599 non-null   float64\n",
            " 8   pH                    1599 non-null   float64\n",
            " 9   sulphates             1599 non-null   float64\n",
            " 10  alcohol               1599 non-null   float64\n",
            " 11  quality               1599 non-null   int64  \n",
            "dtypes: float64(11), int64(1)\n",
            "memory usage: 150.0 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.shape)\n",
        "nb = data.shape[0]\n",
        "print(\"nb exemples\",nb)\n",
        "data.head(4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "J006ja0AEvNY",
        "outputId": "ab97faa1-98e6-4bdd-8096-89f3d150524c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1599, 12)\n",
            "nb exemples 1599\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "0            7.4              0.70         0.00             1.9      0.076   \n",
              "1            7.8              0.88         0.00             2.6      0.098   \n",
              "2            7.8              0.76         0.04             2.3      0.092   \n",
              "3           11.2              0.28         0.56             1.9      0.075   \n",
              "\n",
              "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
              "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
              "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
              "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
              "\n",
              "   alcohol  quality  \n",
              "0      9.4        5  \n",
              "1      9.8        5  \n",
              "2      9.8        5  \n",
              "3      9.8        6  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c6f915d-caa7-4ffb-a615-7bd90362d658\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c6f915d-caa7-4ffb-a615-7bd90362d658')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c6f915d-caa7-4ffb-a615-7bd90362d658 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c6f915d-caa7-4ffb-a615-7bd90362d658');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = data[\"fixed acidity\"]\n",
        "print (x)\n",
        "print(type(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qiw4ODuRFCF-",
        "outputId": "7ba771d3-ddb2-44e5-f418-54e3f98f5319"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        7.4\n",
            "1        7.8\n",
            "2        7.8\n",
            "3       11.2\n",
            "4        7.4\n",
            "        ... \n",
            "1594     6.2\n",
            "1595     5.9\n",
            "1596     6.3\n",
            "1597     5.9\n",
            "1598     6.0\n",
            "Name: fixed acidity, Length: 1599, dtype: float64\n",
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(7,7))  # Create a figure and an axes.\n",
        "ax.scatter(data[\"fixed acidity\"], data[\"pH\"], marker='.',  label='vins')\n",
        "# Plot some data on the axes.\n",
        "ax.set_xlabel('acidity')  # Add an x-label to the axes.\n",
        "ax.set_ylabel('ph')  # Add a y-label to the axes.\n",
        "ax.set_title(\"Mon beau graphique\")  # Add a title to the axes.\n",
        "ax.legend();  # Add a legend."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "mAMtPBOXFP83",
        "outputId": "e36854dd-1981-4ab8-8260-b961e6a3700c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.savefig('acidity_pH.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "S-CDAE0lFtDO",
        "outputId": "72e6c530-3d32-44e9-c79b-87da310907cd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(7,7))  # Create a figure and an axes.\n",
        "ax.scatter(data[\"alcohol\"], data[\"density\"], marker='.',  label='vins')\n",
        "# Plot some data on the axes.\n",
        "ax.set_xlabel('alcohol')  # Add an x-label to the axes.\n",
        "ax.set_ylabel('density')  # Add a y-label to the axes.\n",
        "ax.set_title(\"Mon beau graphique\")  # Add a title to the axes.\n",
        "ax.legend();  # Add a legend."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "0Sv1hM2dGLnE",
        "outputId": "c64e8e09-1413-48df-a85e-b998bfd97f2e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcYAAAG5CAYAAAAUFpQ9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9e3xW1ZX//1m5AcGAIVCChASiGDFolaAJVQtOxSK1tWJblKr1UrUzdmb8dm60M2OttZZ+p52xnfqrV2q1BaFe+Np+8YLzQ7EtCRBEJWIEQxIChEuIEAmQy7O/f5xznpxznrVPzslzf7Ler1deyT7Pueyzz5O9zlp7XUgpBUEQBEEQDLKS3QFBEARBSCVEMAqCIAiCDRGMgiAIgmBDBKMgCIIg2BDBKAiCIAg2RDAKgiAIgg0RjIKQQIiomYiuSHY/EgkRTSUiRUQ5ms+/R0RPJLpfgqBDBKMwbDGFVA8RjXdtf9ucyKcmp2fDC6XUg0qpbya7H4JgIYJRGO7sBnCD1SCi8wDkJ687qYdO0xOETEUEozDceQbAzbb2NwA8bd+BiMYS0dNEdIiIWojo34goy/zsFiL6ExH9lIg6iWg3EV01yDUvIqL3zf1/TUQjbde6moi2EdHHRPQXIjrf9tlSIvqIiLrM46+1fXYfEf3W1h7MfDnL1Iy7iOj3RLSKiB4wP5tHRG1E9C9E1A7g10RUSER/NMeg0/y7xHa+N4jox0S0iYiOEdH/IaJxrst+nYhaiegwEf2rR99vMse5g4j+1W5+JqKnrH7a+2prn0FEz5v93E1EfzfIsxCECEQwCsOdWgBjiGgGEWUDuB7Ab137/DeAsQDKAcyFIUhvtX1eDaARwHgA/xvAk0REHtf8OoDPAzgTwNkA/g0AiOhCAMsB3AWgCMCjAF4iohHmcR8BuMzsyw8A/JaIJgW9YSLKA/AigKcAjAOwEsC1rt2Kzc/KANwJY674tdkuBXACwC9dx9wM4DYAkwD0AfiF6/NLAVQA+ByAe4loBtO3cwH8CsBNAM6AMQ4l7v0095UF4A8A3gEw2bzOPUT0eT/HC4KFCEZBGNAa5wPYAWCv9YFNWH5XKdWllGoG8DMYE7dFi1LqcaVUP4DfwBAMEz2u90ul1B6l1BEAP8KAKfdOAI8qpeqUUv1Kqd8AOAWgBgCUUr9XSu1TSoWUUqsA7ARw8RDutwZADoBfKKV6lVIvANjk2icE4PtKqVNKqRNKqQ6l1PNKqW6lVJfZ77muY55RSm1XSh0H8O8AvmaOn8UPzHO9A0N4fZrp21cA/FEptUEpdco8T8jnfV0EYIJS6n6lVI9SqgnA4zCenyD4RtYOBMEQjBsATIPLjApDC8wF0GLb1gJDI7Fot/5QSnWbyuJpHtfb4zrXGebfZQC+QUR/a/s8z/qciG4G8B0AU83PTjP7F5QzAOxVzgoCe1z7HFJKnbQaRJQP4L8ALABQaG4uIKJs84WAu69cV//abX93gx+jM+znUUodJ6KOwW8JgDF+ZxDRx7Zt2QDe8nm8IAAQjVEQoJRqgeGEsxDAC66PDwPohTHpWpTCplUOgSmuc+0z/94D4EdKqdNtP/lKqZVEVAZD+/k2gCKl1OkAtgOwTLbH4XQaKva4/n4Ak13m3imufdxld/4Bhhm0Wik1BsBnze26c5TCGLfDHv3Q9S18HlMgF9k+97rPPQB2u8avQCm1MGAfhGGOCEZBMLgdwF+ZZsAwpja0GsCPiKjAFFDfQeQ6ZBDuJqIS0znlXwGsMrc/DuBbRFRNBqOJ6AtEVABgNAxhdQgAiOhWADNt59wG4LNEVEpEYwF81+P6GwH0A/g2EeUQ0TUY3CRbAGNd8WOz399n9rmRiM41hdn9AJ6zaZN+eQ7A1UR0qbkWej+c89Q2AAuJaBwRFQO4x/bZJgBdptPQKCLKJqKZRHRRwD4IwxwRjIIAQCn1kVJqi+bjv4WhqTQB+BOAFTCcZIbKCgCvmef7CMADZh+2ALgDhlNLJ4BdAG4xP3sfxtrmRgAHAJwH4M+2/q+DIWDfBVAP4I+6iyulegAsgvEy8DGAG839T3n0+SEAo2BogLUAXmH2eQaGQ087gJEAAnuEKqUaANwNY4z2wxiHNtsuz8BYn2yGMYarbMf2A7gawAUwLACHATwBw1lJEHxDUqhYEAQiqgPwiFLq10M8/g0Av1VKxTyDDRE1A/imUur1WJ9bEDhEYxSEYQgRzSWiYtOU+g0A54PXAgVh2CFeqYIwPKmAsXY6GoZJ9ytKqf3J7ZIgpAZiShUEQRAEG2JKFQRBEAQbw8KUOn78eDV16tRkd0MQBEFIEerr6w8rpSZwnw0LwTh16lRs2aLzxBcEQRCGG0TUovtMTKmCIAiCYEMEoyAIgiDYEMEoCIIgCDaGxRqjIAiCoKe3txdtbW04efLk4DunGSNHjkRJSQlyc3N9HyOCURAEYZjT1taGgoICTJ06Fd41ttMLpRQ6OjrQ1taGadOm+T4urqZUIlpORAeJaLvmcyKiXxDRLiJ6l4hm2T77BhHtNH++wRz7ku68giAIgn9OnjyJoqKijBKKAEBEKCoqCqwJx3uN8SkYhU11XAVguvlzJ4BfAYCtrE01jHI43yciqzgqiGgRgE/i02VBEIThR6YJRYuh3FdcBaNSagOAIx67XAPgaWVQC+B0IpoE4PMA1imljiilOgGsgylgieg0GPXwHohn3wVBEIThSbK9UifDqLpt0WZu020HgB/CqEvX7XViIrqTiLYQ0ZZDhw7FrseCIAhC3Nm3bx++8pWvJOXayRaMgSCiCwCcqZR6cbB9lVKPKaVmK6VmT5jAZv0RBEEQUpQzzjgDzz33XFKunWzBuBfAFFu7xNym2z4HwGyzcOmfAJxtFkgVBEEQ0pSlS5fi4YcfDrfvu+8+/PSnP8XMmTMBAE899RQWLVqEBQsWYPr06fjnf/5nAEB/fz9uueUWzJw5E+eddx7+67/+Kyb9SbZgfAnAzaZ3ag2Ao2ZNuFcBXElEhabTzZUAXlVK/UopdYZSaiqASwF8qJSal6zOC4IgDFfqWzrx8PpdqG/pjPpcixcvxurVq8Pt1atXo7q62rHPtm3bsGrVKrz33ntYtWoV9uzZg23btmHv3r3Yvn073nvvPdx6661R9wWIcxwjEa0EMA/AeCJqg+FpmgsASqlHAKwFsBDALhhrhreanx0hoh8C2Gye6n6llJcTjyAIgpAg6ls68fUnatHTF0JeThZ+980aVJUVDn6ghgsvvBAHDx7Evn37cOjQIRQWFmLKlCmOfT73uc9h7NixAIBzzz0XLS0tqKysRFNTE/72b/8WX/jCF3DllVdGdV8WcRWMSqkbBvlcAbhb89lyAMs9jm0GMDOa/gmCIAjBqW3qQE9fCCEF9PaFUNvUEZVgBICvfvWreO6559De3o7FixdHfD5ixIjw39nZ2ejr60NhYSHeeecdvPrqq3jkkUewevVqLF+uFRu+kcw3acKKula8vH0/rpo5CUuqS5PdHUEQhjE15UXIy8lCb18IuTlZqCkvivqcixcvxh133IHDhw/jzTffxKlTpwY95vDhw8jLy8N1112HiooK3HjjjVH3AxDBmBasqGvF9158DwDw1s7DACDCURCEpFFVVojffbMGtU0dqCkvilpbBIDKykp0dXVh8uTJmDRpEpqbmwc9Zu/evbj11lsRCoUAAD/+8Y+j7gcAkGHNzGxmz56t0rlQ8U1P1oUFIgBcNn08nrm92uMIQRAE/+zYsQMzZsxIdjfiBnd/RFSvlJrN7Z9sr1TBB1fNnOTZFgRBEGKHmFLTAMtsKmuMgiAI8UcEY5qwpLpUBKIgCHFDKZWRicSHslwoplRBEIRhzsiRI9HR0TEkIZLKWPUYR44cGeg40RgFQRCGOSUlJWhra0MmFlwYOXIkSkpKAh0jglEQBGGYk5ubG6jCfaYjplRBEARBsCGCURAEQRBsiGAUBEEQBBsiGAUhRYhlGR9BEIaOON8IQoJZtnYHXmlox4LKYixdaKSpinUZH0EQho5ojIKQQJat3YFHNjShuaMbj2xowrK1OwDwZXwEQUgOIhgFIYG80tDOtq0yPtmEmJXxEQRhaIgpVRASyILKYjyyocnRBuJTxkcQhKEhglEQEoi1puheYwQM4SgCURCSj9RjFARBEIYdUo9REARBEHwignEYIXFygiAIgyNrjMMEiZMTBEHwh2iMwwSJkxMEQfCHCMZhgsTJCYIg+ENMqcMEiZMTBEHwhwjGYYTEyQmCIAyOmFIFQRAEwYYIxgxEwjIMZBwEQRgKYkrNMCQsw0DGQRCEoSIaY4YhYRkGMg6CIAwVEYwZhoRlGMg4CIIwVCSJeAZS39IpYRmQcRAEQY9XEnFZY0wiK+pa8fL2/bhq5iQsqS6N2XklLMNAxkEQhKEggjFJrKhrxfdefA8A8NbOwwAQU+EoCIIgDA1ZY0wSL2/f79kWBEEQkoMIxiRx1cxJnm1BEAQhOYgpNUlYZtN4rDEKgiAIQ0cEYxJZUl0qAhHxc0ISBEEYCiIYhaQiTkiCIKQassYoJBVxQhIEIdUQwSgkFXFCEmLJirpW3PRkHVbUtSa7K0IaEzdTKhEtB3A1gINKqZnM5wTg5wAWAugGcItSaqv52TcA/Ju56wNKqd8QUT6A3wM4E0A/gD8opZbGq/9CYhAnJCFWiFleiBXx1BifArDA4/OrAEw3f+4E8CsAIKJxAL4PoBrAxQC+T0RW+pKfKqXOAXAhgEuI6Kr4dF1IJEuqS/HM7dUyiQlRIWZ5IVbETTAqpTYAOOKxyzUAnlYGtQBOJ6JJAD4PYJ1S6ohSqhPAOgALlFLdSqn15rl7AGwFUBKv/guCkF6IWV6IFcn0Sp0MYI+t3WZu020PQ0SnA/giDFMsCxHdCUMTRWmpaCKCkOmIWV6IFWkXrkFEOQBWAviFUqpJt59S6jEAjwFGdY0EdU8QhCQiscFCLEimV+peAFNs7RJzm267xWMAdiqlHop7DwVBEIRhRzIF40sAbiaDGgBHlVL7AbwK4EoiKjSdbq40t4GIHgAwFsA9yeq0IAiCkNnEM1xjJYB5AMYTURsMT9NcAFBKPQJgLYxQjV0wwjVuNT87QkQ/BLDZPNX95rYSAP8K4AMAW41oD/xSKfVEvO5BEIThhxS4FkipzF9+mz17ttqyZUuyuyEIQopT39KJrz9Ri56+EPJysvC7b9aIcMxQiKheKTWb+0wy3wiCIJjUNnWgpy+EkAJ6+0KobepIdpeEJCCCURAEwaSmvAh5OVnIJiA3Jws15UXJ7pKQBNIuXEMQBCFeVJUV4nffrJE1xmGOCEZBEAQbVWWFIhCHOWJKFQRBEAQbIhgzECm9IwiCMHTElJphSOkdQRCE6BCNMcOQ0juCIAjRIYIxw/AqvVPf0omH1+9CfUvnoOcJsm+0pJvpN5Fjk6rIGAiZjJhSMwxd6Z0gGT0Smf0j3Uy/khlFxkDIfERjzECWVJfimdurHQImSEaPRGb/SDfTr2RGkTEQMh8RjMOEIBk9Epn9I92qrktmFBkDIfORJOLDiCBVAxJZYWBFXWtaVV2X6gsyBkL645VEXASjIAiCMOyQ6hqCIAiC4BMRjIIgCIJgQwSjIAiCINgQwSgIgiAINkQwZiC6rCSJzFYimVGCw41ZKoxjKvRBEBKJZL7JMHRZSRKZrUQyowSHGzMASR9HeZbCcEQ0xgxDl5UkkdlKJDNKcLgxS4VxTIU+CEKiEY0xw7CykvT2hRxZSXTbE9kHQY9uzJI9jvIsheGIBPhnILqsJInMViKZUYLDjVkqjGMq9EEQYo1kvomBYEz25JDs6wupj3xHBME/XoJRTKk+SLYDQrKvL6Q+8h0RhNghzjc+SLYDQrKvL6Q+8h0RhNghgtEHyS6zk+zrC6mPfEcEIXbIGqNPkr1+k+zrC6mPfEcEwT+yxhgDqsoKkzrZNLZ3obapA4X5eTHtRywm00z1dk03QZPs76ggZAoiGNOAFXWt+N6L7wEA3tp5GABiUtA3Fg4bmZpRR5xZBGH4ImuMacDL2/d7todKLBw2MjWjjjizCMLwRQRjGnDVzEme7aESC4eNRDp9ZOq1BEFILcT5Jk1YUdeKl7fvx1UzJ8XEjGoha4ypcS1BEBKLON8IgQkiiIM4fUQrbLhrxeulQZxZhifyQiSIYEwDEu18k8rOPm7i1VdheCJOVwIga4xpQaKdb1LZ2cdNvPoqDE/E6UoARDCmBYl2vkllZx838eprrFhR14qbnqzDirrWZHdF8IE4XQmAON+kDYl2von2ekFKX0W7phOvsYkWu5kXAB689ryU6p/AI2uMwwMpO5UBgjEWxEsAuc8bZJ0mldd0oq1redOTdeF1TwC4bPp4PHN7dVz77Eb3zFL1ZUIQEoV4pQpRCyCdkwt33tqmDpzsDQEATvUa6zS6a3FrOqkgGHXjFWQcr5o5ySEYE23m1T0zcVgSBG9kjXGYEK1Tgc7JhTtv14ne8H4KcLTdpOqajm68dNvrWzrx8PpdqG/pDJ9jSXUpHrz2PFw2fXxSzKi6ZyYOS4LgjQjGYUJQAeR2GtE5udSUFyEni0AAsrMINeVFaNh/zLGvu22nqqwQv/tmDb5zZUVKmVF148Vtt7TIn73WiK8/UesQjhXFBagpL0JFcUHC70H3zFLdYUkQkk1cTalEtBzA1QAOKqVmMp8TgJ8DWAigG8AtSqmt5mffAPBv5q4PKKV+Y26vAvAUgFEA1gL4ezUcFkoDwK0fWQLIz9qYl6mNXZciAqDM38FNiKkYSK8bL277w+t3sebgZK+f6p6Z57MUBCHua4xPAfglgKc1n18FYLr5Uw3gVwCqiWgcgO8DmA3DGldPRC8ppTrNfe4AUAdDMC4A8HIc7yEl8OvwEYv1I87UtqS6NPxjp7apA339ISgA/f2GULj78rPCx/mZeIM4BUW7b5DjdQLbvd3SInv7Qg7tMhXWT7ln5rVdEIQ4C0al1AYimuqxyzUAnjY1vloiOp2IJgGYB2CdUuoIABDROgALiOgNAGOUUrXm9qcBfBkZLhiDaB4Pr98Z0dY5yejOUTlpjEPjq5w0Rts3nVDwO/HGy4OV2xdAXDQ4nXapGxtBEFKbZHulTgawx9ZuM7d5bW9jtkdARHcCuBMASkvT+804iOZxwvQGdbeDnKNgVC5M4yjIbOsIYqKN9t6i3RdA3DQ4TruMdmwEQUgOyRaMcUMp9RiAxwAjjjHJ3YmKIJrH16pK8MiGJkc76DlqyoswIte/phPNGmHQfkW7b7w0OJ2JNhXXTwVB8CbuAf6mKfWPGuebRwG8oZRaabYbYZhR5wGYp5S6y76f+bNeKXWOuf0G+346MiHAP8ja2LK1O/BKQzsWVBZj6cIZQzpHqpZ3SuQaY5D+p2qSAkEQeFI5wP8lAN8momdhON8cVUrtJ6JXATxIRNbsciWA7yqljhDRMSKqgeF8czOA/05KzxNMEM1j6cIZDoFosa6hHa80tKPrRG9MBUUQAcRtD3Jv0e4bDw0uVk42ko1GEFKDeIdrrISh/Y0nojYYnqa5AKCUegSGV+lCALtghGvcan52hIh+CGCzear7LUccAH+DgXCNl5HhjjexYtnaHWETq/V7fmVxoOwuOgHo18klUzWrWDjZSDYaQUgd4u2VesMgnysAd2s+Ww5gObN9C4AIs6zgzSsN7RHtglG5rKajc1zhhJp9355BnFxSIXwhHlSVFeLeqyvD2t5Q7kkXIiMIQuKRzDfDhAWVxRHtINlddMKyMD8PIXOZOqSMdk15EXKys4xsONnO83Lbg8CVceLSsXltjzX1LZ24/48N+POuw7j/jw1Dup5koxGE1CHZa4xCgrDWHN1OOX6zuwC8R+f6xoOO66xvPGikP7OcutzOXbrtPuDMjRXFBVGbg6MlFpqwZKMRhNRBBOMwQueUw+F2UtEJy4PHTjqOO3jspJENJ6SMbDgh5TSl9hsCsbdfeQqQe559G298eAjzzp6Ah66/EABvbuzs7hnUbGs38d7w2Eb09ivkZhNW3jlnSE5I7n1jFchfUVyAzu6epORVFQRhABGMw5igzjCcR+fii0rxTtt7jnZFcQErKPxW3bjn2bexZts+AAj/fuj6C9kcrLprcSbe57e2hQVzT7/C81vbYlY/MtpA/kx1TBKEdEQE4zAmniZATlD4rbrxxoeH2HaQa3V294Sz92TZ2nasdiyy70QbBpKpjkmCkI6IYBzGxMoEyOVF5QSF36ob886eENYUrXbQa9WUFyE3m9Dbr5CTTeF7+319W/h+F80aWlageGTPkbyqgpA6xD3zTSqQCZlv4kUiM9wA/oPYuTXGINS3dOKGx2vDgmblHd7ON6mQFSjRz0IQhjNemW9EMAoZycPrd+FnrzUipIBsAr5zZUW4HJYgCIKXYJQ4Rp8kKiYunnD3wMUFAkamnHn/sR7L1u4YdN8gBIlDjOb4mvIi5GSRETOZNWBKjcVzvOfZt3HB/a/hnmffHtLxQfoQ5JllwndUEFIBWWP0QSZ4DHL30NjexaYh49LHlRaNjjplWdA4RLdZMcjxAAAy3W+ItGMQ9DnqPGb9Eq0HrO6ZZcJ3VBBSBdEYfaDL+pJOcPfAxQUCfPo43b6Af02FOwfXL2uS/9lrjfj6E7Xh8/o93rrfvv6QEUvZb2yPxXPUeczqcI9NkD4EeWaZ8B0VhFRBBKMPdKnT0gnuHionjXHsY7W59HG6lGU6IcbBnSNI+jmuv0HS2sXiOdo9ZO1t7uWAG5sgfeD21T2HTPiOCkKqIKZUH2RCJXbuHtxaRcGoXAD69HFAZAxhkPi7IHGIXOhCwajccGwimW3ds9Ftj/Y5WmZTu8eszozJjc3dl5/luw/cPVj7u8cwE76jgpAqiGD0SSZUYnffQ2F+nuNze7u0aDSmjMtHadHo8DYuhjBo/B13jsb2LtQ2daAwPy/cR26Srykvwohc/9eKVz1G95qi7uVANzbR1pTkxjDoeROJhKEI6YYIxihI93/4N1wJwN9oPIgl1aWBagNGq6norqUTarfMmRrWZFOlxqOXABzuWlwqPB9BCIoIxiGS6H/4eFR3bzr0CdvW1QbUvQhEo6norsXd74q6Voe3bGnRaG0ScR3xGEcvAZiqWlyikFR3QjoignGIJPIfPl7V3Xv7FdvmUrfF60WAu5bufjkhes8VZ/s25cZrHAERgDok1Z2QjohgHCKJ/IePV3X3U339bJtzknl4/a64vAhw17rpyTrHPtb9ckI0iLkyXuMIpL9ZPV6IOVlIR0QwDpFE/sP7Tb49GO7J+8sXTA6bJgHgyxdMDv/trg0YqxcBToC4nUl096vzanU77+gIOo5+hd1wXEcLYpIWbVpIN0QwRkGi/uFjUd2dm7x1YRnJrjnodb9uIRrEPBpkHIMIu+G2jhZPk7QgpAIiGNMEnYs+B/c2r5u8ly6c4YhT9No3kTUH/d5vUPOo3/MG6auXNp1IE2s8HIs44mmSFoRUQARjhqF7mw9aczCLjMr3REjpmoOxMjO7CdJXnTadSBNrIrW4eI25IKQKIhgzDN3bfBBTaGN7F/pCxt99IaMdiwk9HuuysTAzcwTtK6dNJ9LEmkgtLl5jLgipggjGBBEvk5rbfBYLB5MgsYVB7y1ac+yytTsi1kSDmJl1cPcQbV9ryotARIAyVO+haMh+xzbRWlwsxjxTiUUxbCG5iGBMAPEyqXHmsyB9AMD2q3LSGMf5KieN0ZrqEmku5MphuddHh0K87mFdQzv6Q0ZsaH9IYV1De6DzBumXaHGpge6ZDUfP5XRGqmskgHiVBOI0O6+yRKd6jT709A6UYbK2neod6JeVTNyiYFSu53lPMueIR9FcrhxWLNA9H65YcxCi7W/Q782S6lI8c3u1CMUk4lUGTcqCpQ8iGBNAvEoCcSWIdKWkCvPzYOW5CZntrhO94W0KQNeJXsD226LrRK+23JF9X+scQUpRBYErhxULuOdjaafNHd14ZEPTkIRjtP2VUlLpR5AyaELqIqbUBBCvZAC6DDUWVmkmAOjs7gl7mmaR0W7Yf8xxPqvNbbdMlm5THbdvwajcuDideJXD4vAbvsA9n39Yvc2xzysN7YHNtkH766dfQmoTtAyakJqIYEwQ8UoG4HaCqCkvQm42obdfISebHG+sOdlG+EFOtvHGWpifxzps6Bw5WjuOY8+RbrR2HA9/xq1HxiIsQ+eowMVdcvvq1kQ55x2OBZXFjqxAdm2Pu16Q/ga5Z+57EwsnjmjPIY4kenT/65IBKH0QwZhhNLZ3hZOB9/YrZ6iFUs7fGpZUl6K143hYgFgChXN8CVI82C9BHBV0+3Jroq0dx9l7iDYrEMA7McXjnmPhxBHtOcSRRMh0ZI0xw/BykukLKSgYHpK1TR3afetbOvHUxma0HunGUxubUd/SidVb9jj2tdpW8eBsAkbkOmsR3n35Wb4mTLejDucopEPn1MCtieqcYXTnmF9ZjK/OnoL5Nm2R29fLscKvE5Jf54xYOHFEew5xJBEyHdEYMwydGZQzb+pMqdzEl5+XjSPdA442+XnZAKJfO+G0D85RSIfObMutv9o1RmDAPMqdQ6cV6a7HbQuiWfk1P8fCTB3tOaSUlJDpiGDMMOwCoXLSGGzfdxT/+uJ7WDSrJEKA2QP67Q4qOiFqrdkBwN9cPj38dzRrJzrtw+0opMNLMLvXX3XmUe4cujJbuutx24JkvvH7ghELJ45ozyGOJEKmI4IxTQiSdaaiuADb9x3FE3/ejT5zvfH39W247TNT0bD/mKM8E+dQo5v4srOA/pDx2ypHpcOvc0ZNeRFysgxnoeysAWchK2MMuTLGcOMQRDDPryxGwajcQbUcL62Iux63Lahm5fc+YuHEEa1TjziSCJmMCMY0IEjWGcBwBDnVG4LdxaanLxQ2I1rn0DmjAJET3wtb29Bv5k/tDxntoA4x1mfuyVfZfgB9xpigibLd1wqalSTZmlkiEYcaQRhAnG/SAC+HGs4R5KRLKAJGlQz3Obwys6yoa8VNT9ZhRV0rAEScz8uvVWcerW/pxNce3Yj/eLURX3t0I+pbOvHC1jaHF+0LW9u0/dKNAweXZCBoVuvZjs4AACAASURBVJIgDkQ6YnGORCAONYIwgAjGNECXdYbLpuHOWjOjuABfry7FXZeVR5zjgimnO7ZZbUsze2vnYXzvxfewoq4V180qQV42gQDkZROum1Wi7a8uy8dPXt7h0AR/8vIO7DzQ5Th254EubcYY3ThwcBO9V1aSLPPFIZZlttIJycwiCAOIKTUN0CWI5kx1D73+oePY8QUj8KNrzwMAlBaNdpzD7dQyfWJB+Dp2rOoaK++c48ssqDMhth7pduzXeqQbE8eMdGw71RfC0oUz8P7+Y9jUfAQXTx3nqKLBjQMHt75XVVaIe6+uDB9v9SteZbbSiXQy+wpCvBHBmCb4LfPDZaKxqCguQGd3T9hxxnB8MYRBTtaAphSL0lXPbGzGGx8ews4DA0LmyxdMdoRLfPmCySgtGo132ga8XRdfZJS32mBef8POw1hR1xq+d7/jwAnB+pZO3PeHBvT2hVC3+wgqigu0yQCCrF2mCtH2SxxqBMFABGMawzlMNB0+7tjHanP76jSlTbud60ubdnegorgANzy2Eb39CrnZhJV3ztE6rjyzsRlrtu0DgPDvh66/EPMri/H4n5rCnq3zK4uxzrWe2NpxPCL/6lCK7ta3dOL+Pzagpy+Ezc2GEHxhaxt6zBvu6QuFHYiCvAjUt3Tiets4PGuOgw6/+VqjRZxnBCF2yBpjGsOtox04dtKxj9Xm9tU5s7y+44Bj++s7DuD5rW3o6Tcy5/T0Kzy/tU173jc+POQ43mrXNnUMZKNTRnvNtr2Ofdds2xtoLVEH1y+dA9GS6lJ867PlmFqUj299ttxTgD365kcOZ6FH3/xIuy+3VhsvxHlGEGKHCMY0hnOYWHyRc1K32ty+OgE0pTDfsX1KYT5cTq3hthWHSEA4DnHe2RMc+1rtmvIiZJleLmTu685qU5if5ymo/KZY4+5X50DEpcDToXvx4AjiRRst4jwjCLEjrqZUIloA4OcAsgE8oZRa5vq8DMByABMAHAFwo1KqzfzsJwC+YO76Q6XUKnP75wD8Bwyh/gmAW5RSuzAM4RwmGtu7fO8LADnZhD6zEoe19njTnKmOLDc3zZkacb7KM8YONMhMI27GhDx0/YUADE1x3tkTwu3G9q5wwoE+M8H5rLJC7LD1eZZpnn1qYzN6+kJ4amMz5lcWe8YbBrlfzoEoSIaaOeVFeKftqKOtI+habTSI84wgxI64aYxElA3gYQBXATgXwA1EdK5rt58CeFopdT6A+wH82Dz2CwBmAbgAQDWAfyQiy4vkVwC+rpS6AMAKAP8Wr3tIBxrbu1Db1BEWiEG0lNqmDvSbgirUr8LmtxffbnPs9+LbbREerFbbEioKxrqddY7iMSNx+qhcFNu8Trm+LZpVEg6VyCJg0awSX/GGPT7MhVwMoXu8gGDallXfEnDWu+RYUl2KB689D5dNH48Hrz0vrmuMmY47rlYQ4kk8NcaLAexSSjUBABE9C+AaAO/b9jkXwHfMv9cDWGPbvkEp1Qegj4jeBbAAwGoYS0OWkBwLYF8c7yGl4TLBuOMYrXaQZN3v7PnYcY539nyMqlKnBmKdt84lnOqaOtB1opfNqMNpUOsa2mGGNiKkjKw38yuL2TRxhfl5jn29kotz6DLnBNG2asqLMDLXf5o3v1600ZLJzjdBMx4JQrTEc41xMgB7raI2c5uddwAsMv++FkABERWZ2xcQUT4RjQdwOYAp5n7fBLCWiNoA3ARgGRiI6E4i2kJEWw4dOsTtkvZwGlizK1bQanNaWGd3j0Nbs7RAKwjfoj+ksNElAK32u3uPOra/u/eoNnMNp0Fps+8QOX/D6J/VyoJ3cnEgcj1y1WantmFv+81QYwnR71xZkVLCJ5OdbxK5VisIQPKdb/4RwFwiehvAXAB7AfQrpV4DsBbAXwCsBLARQL95zP8CsFApVQLg1wD+kzuxUuoxpdRspdTsCRMmcLukFZzTCec84+X44jYX1pQXISc7CwQgJ3tA+7nkrPGOc1xy1viIQHyrzV1Pl7mGg9u3tqkDvaZ51j7J22s/5uV6a2tcSjjdPWQCsXC+8evYlGhi4aUsCEGIpyl1Lwa0PAAoMbeFUUrtg6kxEtFpAK5TSn1sfvYjAD8yP1sB4EMimgDg00qpOvMUqwC8Esd7SAl0ZrKK4gJkwTCDZsEI4LdMTG7HF85cWN/SiVDIEEChUCh8vXMnjQkH2Fvt+ZXFWN94MBy/d9fcMwEYjjkvbdsX7oPlqOOOVwR4kxhH14le2KI6wmbbqrJC3DJnarhslJe2ZhU7Vhgodlw+frRjH3fbD6lqsoxHXcxUuC8gWMYjQYgF8dQYNwOYTkTTiCgPwPUAXrLvQETjicjqw3dheKiCiLJNkyqI6HwA5wN4DUAngLFEdLZ5zHwAO+J4DymBlRg8pICTtor2j7z5ESxxFjLbgCGc7risnPUmtfP81jZHgL8Vm8jFFlaVFeIHX5qJy6aPxw++NNPh0Wk3vFqJzN3xigBvEuNMqe4Af6u9oq4Vj2xoQnNHNx7Z0OTpiMGtn+rMwUEIarJMF6eRVDfFLqkuxTO3V4tQFBJC3DRGpVQfEX0bwKswwjWWK6UaiOh+AFuUUi8BmAfgx0SkAGwAcLd5eC6At8hYXzoGI4yjDwCI6A4AzxNRCIagvC1e95AqcIm2AeCgK4bu4LGTgUorrXF5n655uw0PXnseevtCju29fSE2k0xVWSErgCqKC9g6hJzzzSvb96O5Y2BdtHRcPhZowhyCpG5r2Hc0os2NV1CC1FhMpNNItBpf0NqRgpDJxDWOUSm1FsZaoX3bvba/nwPwHHPcSRieqdw5XwTwYmx7mtpsc3mJWu3FF5VG5BnVxeRxpsXuHqcAtNqn+p3bT/WHtOe1HHhCasCBR2fW40xibmGnNPsBweICuSw3Xaf6HNvcbT8EMVkGzcHqFy7NXJBYTA6JgxSEASRXahqwoLLYkXzbcljhBEh9S6c21MGt2ZWcPhJtHw9oTSWnG84oV8yYGM5xarUtR53evhCys50lmzhNQ5eQ2p3IXCfsuDCHJdWlaO04Hl5j9BIy180qwerNreEE6dfNKsHmpg7sPDSQS3bSEJ1v/CbbjkeAv04LjYXGJ0nEBcFABGMaYJVdsgSC1QY0cXKuTDQAWM3u5zfMwnW/+kt4n5/fMAsAcPG0IodgvHiaOclaC4dqQB8Lomlw5r4gjhW6jDg6srKyQKEQsrKMZexeVxiKux1rKooLkJtNYYcl62UgGnRaqGh8ghA7kh2uIfhk6cIZeOOfLncIRY7apg709Rsm075+Z6iDuWYLIkOTtJxtLKw2F+9X29ThSCI+mHMG5/pvmXNDCjjVG9zBI4iDCDcOXmEkQZxkuH1192vFhIZCg48Zh/u8XqELfmMxY0EqhHakQh+ExJOI5y4aY4ahyw6zrqE9PEn3hxTWNbTjj+84kwb98Z19ePDa83DUlT3n6IneiPJQ6xracfflZ7FaIADWEYQLwwjioKIz5/odh5ryIjz+VhP6FZBN3mEkuj5w+1YUF7D3G615M1oNO16kQmhHKvRBSDyJeu6iMWYYuuwwXFhE10mXM4rZPtnb79h+srcfH7g8Y602p8XpNDsuDCNwVhPGnMux3eWVun3fUdQ2dYSFpRokjEQHt6/ufqPNkqM7b7JDF1IhtCMV+iAknkQ9dxGMGYYuOwxnRjxrgjPA3Wp/+QJn5r4vXzAZF08d59hmtbmyUzXlReFUc0RwhGvYuWrmJFROGuPY5m7bqW3qQF/IMOf2D2Ka5Mpk6XLDBsmswu3rlXUmGvNmqpaSSoV+pUIfhMSTqOcuptQ0x+26r3PCKC1yCsHSotFY9pVPO5xvln3l0wCM9cz/2XEAHx0+jqLReWjYfwxXzZyEYyd6sX3fMcw8Ywyevr06fJwlrPpMdayxvcuROKCxvSucqScnC2FP0Yrigoh4Q68QiiCmyUWzSrB6y56w48uiWSV4wbWmal07iHmSu4d4Ob6kqkNNVVkh7r26MjxeyehXqo6NEF8S9dx9CUYi+iKA/6uUCg26sxAX6ls6I74MQdbGOBOgOwm3Fft2z7Nvh8MaDn3Sg0M7D+OtnYfD6ee27zuK+pZOVJUV4t/XvOdYy/v3Ne/hmGuN8v9bvxNLqktZUyYXb6hDNyFzYwMYWqL1AwAfuszB9rbfKhjcPVh1MGubOlCYnxfTf9ZUDKHQJXuwPkuUsErFsRHiTyKeu1+NcTGAh4joeRgZbD6IY58EF7oF5+V/3u3Yb/mfd6OiuAA3PLYxrCmtvHMOqsoKUTlpjCOmrnLSGKxxaVBrtrbh7svPwus7DrD9sN6K+kJG+rnHb56NXQc/ceyz6+AnyMl2WuiPdBuCUqfxPWfT7K6bVeI5Du4JGeAdfTiza2e3U2C7236wzMQhNWAmTuWySPEQVLpkAvUtnex3TxDSDV9rjEqpGwFcCOAjAE8R0UazrFP0gVnCoGgXnN0OKErh+a1tjrAKKwTDXVC3YFQumg4fd2yz2kWjRwzapx2mGXL0iGzH9tEjslGY77yW1baSgE8Zl49b5kwNv/nddsk0lBXl47ZLpvlKDB5SA9l7dGPDrUVMcyUNd7f9wJmJvZx3EhlS4A4j4SqMxALdOo/uuycI6YbvNUal1DEieg7AKAD3wKif+E9E9Aul1H/Hq4OCXtO67dLysKZitd9oPOg49nDXKQCRRX0L8/Nwen4uOo4PaE2nmwLs0unj0WKL0SseMwJ9IYXDnwyYXkfmGgLxoqlFeO39AQ3zoqlFyM/Lxl5bgoCLTEcdKwk4YBQwttY93dusDD5uTSdIXlZuLeLyik9hna2vl1d8SjPiejghqMtwk8iQAk5r7ezuCZQmjks1x6Fb5+EcnoDEmld1pEIfhPTB7xrjNQBuAXAWgKcBXKyUOkhE+QDeByCCMY4EyT3qFowWXFLt8gmnoeP4gBZRPuE0AEDlGWMd+/7d587Gpt0djmw4Mycb+9w198yIclR/t3Kr4/jNzUfC/bTz8vb92P/xCce25X9q0pqDg+Rl5fhtbXNEO6jJkzNJL6kuxabdHeFSX7HKXxoEbmzvueLsuCU859Z5Fs0qwe/r28LXWzSrJCXiDVOhD0J64VdjXATgv5RSG+wblVLdRHR77LsluFnX0G7EHp7o9fynHl8wgm1zTi49rioaVpuLAew47nTUsdpVZYV49s45DsF0zBUfabU5zcq9TgqisEkOGDDJWQHzVoB/ziAB/txkuNtlOna33XAaVMGoXJgJ90Bme0Vda/ilYc22fbh4WlE4f2l2FiHUr5Bly1sbBL+aDje2Xi8N7vPGIuF5VVkhVt7hvN7D63cl7OVARyJfUITMwK9gbHcLRSL6iVLqX5RS/xOHfgk2lq3d4TA3AkZIBfeW//5ep1Cz2mNGOB/1mBE5mFNehHfaBvafY07c21qda1HbWjuR53Ko6bJ5nrq1hymFo/D+/i5HGwBecU2+r2zfj9sumeY0B18yTWsOBhAR4F/f0onFj/4lHD6x6q7PhJ1v3JPhxDEjHSWuJnokEfdK1j0i16mF3f+HBsexqza3Ykl1KRrbu9BrCvjefhUOW/FLEE1HF3LCaXbceTlNeCi4r5cK5axSoQ9CeuE3wH8+s+2qWHZE0MMVDgZ485kuQw2XdcbukGNpPwDwkcvTdOeBrojzNh/pho4LSgvZ9ibTpGqxqfkIllSX4lufLcfUonx867PlWFJdqtV6OU/TR978yOEMYxVr5hxEPnPWeMd53W07OocaLpuNW8Ba7cBZfVwEzfLhNyMOd17ddyFaos3+kyl9ENILT42RiP4awN8AOJOI3rV9VADgz/HsmDBA6bh8tB875WgDvPmMAGywbbMy1HD7VhQXYGQu8yZtVecw6Q0BvSGn2fX8yQPrkG6TY7crSN9qnzOxANtsGuo5EwvYihkzXWucVtvKsmMvqfWaK9WdVXxYZ0bUhYa4TYteJaPcWtFdc8/E/3xwEP0ho193zT1TO+ZBiIWmw5lidedlvwsxuF4qxBumQh+E9GEwU+oKAC8D+DGApbbtXUqpI/whQqz5l6tm4KuP/CXsdPIvVxkVNriyRhXFBXhr5+HwGtjfX3G29rw64THhtDxHnUYOyyuVMznqCivPryx2CMb5lcUO7eVUbwj/sHobPuXSGB2OQ66SWlyxZvv92SfDqrJCrHSthwLBk3Vzk382GZ6y2TbXzGgTfkeb5UNnitWdN9qMIuLkImQKgwlGpZRqJqK73R8Q0TgRjomhsb3LkV3GWquqbepwrGFZpjZ7BQvL0UDnXPHz1z/EpuYjqGvqCKd5+6THmUSc44CpmXElqnSFlWvKi1itJCc7Cz19Romo5o5uxzqg/X7spaT6zVJSd19+lu/ixQCvOeicM7hsOFwQu/UcjBJXyuHc4S7MHBTO6cqvQ46X0wmXqSfa7D3i5OKNhIykD340xqsB1GPAEc9CASiPU78EGzqhttO17udu27dxzhU3P1kXNrtu2HkYNz9Zh6dvr8bUcfnY1j2gpU2fMBrTJpzmiFe0NLMROc5l6hE5WZhfWcyWd+I0lfqWTs9KGTlZCJs8ORNg0OLFHEFMlpzH7MwzxrLJyaPVoDinq/mVxb7PqbsvTssHEHX2HnFy0SPadHrhKRiVUlebv6clpjsCh26tSmey5LZxYQacMwwQGdqRPyIHj908mw1fOGtiATY1D3ixnjWxICIHql1zcGtslkONm+wsIBQCsrIGBC8nWB9evwuneg0t0ip+HHTCCWKy5ILYufAW696i0aC4UmEFo3J9n1N3X36cgoYariGJvXlEm04vfHmlEtElRDTa/PtGIvpPIkqNZJDDgCXVpXjw2vNw2fTxePDa88ITFldKSlelvqa8CFlmLSgrpq7AFcJhtXVelhXFBagpL3KYBa+bVYK8bKPsVJ7p0FJTXhSWrkrBU3Owl6jKAvDpkrGYf+5EKAWHyVQHV/zYwp0iDdCnaKsqiywPxe27aFYJ8nKyjPs1g9h1GV90qdO4fnFwzzJo2R3uvrjSWUFKbwW9niBlstINv3GMvwLwaSL6NIB/APAEgGcAzI1Xx4TBWbrQcMKx1teWLpyB+pZO1oy5rqEd/aZm1h9SWNfQjhOugsRW2/LstDh47KSnI4fboeWeZ98OJxwPAXhmY7N2orTnHg3BMNEaDkSHIkxyXB/cCc9f33FAG+NZUVygNWe513887/eOSK3InfEFGMgNaz2fqrLCQBlmuOcLRO8k4+UUNFRHIcEb0abTC7+CsU8ppczUcL9USj0pGW8Sh9dkunThjPCECUSWcrJMNpxZbkphPna02wPxjTAQu+eo1Q5iCnrjw0PatlsAcc47/+fbl7KTCBvXRy59zWzrymz5rQrhdb+stysjLLncsF4ZZjjnDPfz5a4/FDjHIr+lt4ShISEj6YNfwdhFRN8FcCOAzxJRFoDYRAALgxIkXRcX6weA9RSdX1nsKFT8wLXnaftgmWJD/QpkO299SyeutwmVZ++cg3lnT3DkVZ139oTwvm4t7FNjRgIYEMSfMs223CTCpVjrOtHrKH11xTlGYnBd3Ka7ZBTAO9RcZ5pM/TqScP0NmnD8hsdrw9dbeYc4Z9gRj04hkfjNfLMYwCkAtyul2gGUAPiPuPVKcBB0/UfZfizaXebR9mMn8UNXKjN3205jexf6TOHRZ6Y3A4BH3/zIETLy6Jsf4aY5U8NfrCwAN82ZCoDX+EbnucpWudruPrhTrHW5kglYbW5dlisZBfAONbHIluJOq2YlHHdn+gGAF7a2hUNWevpCeCGDSjZFW3orXuWzBEGH33qM7Uqp/1RKvWW2W5VST8e3a5lFNJNDa8dxbdt93he2tjmEhzXBcmtx77nyqrrbdnSejAdcAvfAsZNGlXuzbcVSArwDgh/PWq8+cMnRLdzOQrp7cFcTsdrROpJYnsDAgCewFV7SeqQbT21sDj+3g/Z8sEw7XYmFUAuaGk8QosWvV+oiItpJREeJ6BgRdRHRscGPFIDoJwdufVB33v953ykArfb401z5R08bEZFhxmqPcsUmjsrJ0mqtc1wmxjmmedPC7inKaWEXTDndcby7badodF5EW5c+jhsb3T1wJbmCwr342OtHKrOtm+R1nq3pTiyEmnh0ConGryn1fwP4klJqrFJqjFKqQCk1tPT7w5BoJwddCAZ33kOfODUNq32JK2H2JWeNxzUXTHZss9rXVpU4tl9bVYKK4gLkmPnOcsz0c0BksumCUblswnILtxY2faIzI4y7bYcrG2XVaAQGajQC/Njo7sFL6/SD7sWns7snLOCyzLZuktclTk8k0Zo8OWIh1CQJuJBo/ArGA0qpHXHtSQYT7eSwdOEMx7qU5aXInXfMKFd5KbPNmQt1AozTXmqbOtBvmmj7bennrCwvFoX5eZ5rou7Jlzue2w/g4yvtY5BnG1tubIyUcgPrpNY9XDerxCEwrUw7fuMNdS8+hsOSOYZZCDuO3Ht1JT5z1njce3VleJLn4kETSazW8dzPLVZCTeIjhUTi1yt1CxGtArAGhhMOAEAp9UJcepVhxCKGSee2f+/VlWFvx6qyQvzT52c46hv+0+eNYzhzod3kCQyYPLnA/50HuhxmQSvVnKWxWQnOO7t7IoSdBeeVamlVVkaezu4ebQzhvIpPOdLSzav4lHZsue3PbGx29MeeQi/LvL71pugVIuPOAKRLhWbEjhrn6w8ZbQC476Xt6O1XqDO1WF08aCKJRWYWr9hPEWhCOuFXMI4B0A3gSts2BUAEo0/iMTnUt3RGTLJLqkvZpNqcc4e7pqLV5hx13GnbLCcZTij83cqtjn0fXr8TS6pL2cnX7zpcVVmhQ4hapklAP7bu7Rtc8ZVWm6vz6DZ3WyEyOoG5oLIYb3x4CPPOnhC+Jrc2fOxUX0RoiC4+MijRhDTEIs9pUOEapL8SriEkEl+CUSl1a7w7IgSHi78DwCbV5hxtzp881lG70aqxeNSlSR490YsZk8Y4ql5YNSE5zazrpCuEwmxzk687LKFh39Fw2jX3JF1TXoQRAWoGuifT/LxsHOkeuLd8MzSE69c6l1CztGnOs7W143g4bnPNtn0oHjMSSxfOYGNH3eElsXKy0WlrfgVKLKwaQYRrkKTakoBbSDS+BCMRnQ0jLdxEpdRMIjofhjPOA3HtneCJbi2Qe2tfNKskIm1ZbVOHQzBWmxPZ2Pw8HPqkJ7x9rE2rs7C33ZrOOcXOxOLnmE4u3OT7yJsfOc57sOtUIPOoDm4yvfr8MxyC6urzz9CeV6dNcwH6j21w3sMrDe1YunAGSotGO7a720Dk2u9Q0a1zBkkaoNNYueTxuuP9Pp8g2qUk4BYSjV/nm8cBfBdALwAopd4FcH28OiX4g0torXP0qSorxH1frMSl08fjvi8aTh+6NcbbLnEWU7ntkmmeDjVuJxWrkLKFve12otCFjEQLN5lycYW6flnZeiysNhegr/Ma1qWlc3uqWkTjFco9d6+kAX6vZZmO39p5GN978b3wM442GXsQhzQJ1xASjd81xnyl1CZy5qXs0+0sJAZdjk7urb2+pRP3/7EBPX0hbG4+goriArz+wUHH+V7/4CCWLpyB1a78pas3t2LNty8FEJlkmltz27TbuT5nTyLuNu1x3rJeZsEgtQjJ1W5s74pYz9Tx0PUXAkB43dBqc/UfuaxCAK/R68zB0ZoLOW3teZeZ2rr3INfictl6JWN34+WQ41e7lATcQqLxKxgPE9GZMP+3iOgrACKLuAkJx6/DRm1TB072Gi6SJ826hSd6nO82Vnv7PmcYh9Xmkkw/vH5nRPt4j7Nqh5VEnJskuVqGnd094RqLPbYai/Z7GKz24rqGdpjLr+hXRttek9KtrS1buyOiioUlDO1wmqguaXqryxzbeqRbO8nHwlzo/i5cN6sEq7fsQV+/coSh2K/VM8i1Jrpy2U4cMzKwGZR7llx/g9ybIMQTv6bUuwE8CuAcItoL4B4A34pbr4QhY1WK+OmrjbjhsY1h85U9NMFq52Y7H7/VPm2EM1+pu23nRG8oom058VhYbW5C5bQqu6dqCAOanS6jDmeq4zxCLW0tm4C83AFtbdnaHXhkQxOaO7rxyIYmLFurD9nlzHq6+9Vl9eHMjfEyF7rDUABjPC0n45Dy1pznVXwqoh2kr7pnKQipjKfGSETfsTXXAlgP43/sOIDrAPxn/LomDAXOU7WqrJDNSXrSVY8x3NaUcuL4WlWJw6Hla1UlOObyvCwxPVjtE6iytTmnIHdsJAA2IYHOVFc6Lj/Ci1anrXFC1Krp6DYdc+ew7s99v27N2WpznqLxMBdyYSheYS8cXJxpkL5yca6CkOoMpjEWmD+zAfw1gEIAp8PQFmfFt2uCHb/OErtcmqHVLnVN3qXj8vFlV0o4q61zPOHgsvLo8n4+s7HZoalYa49upyBdNhvOAUjnjanzom1s70JtU0e4sgbAp9zTOZ0Ahln291v2hEM6dPfLpbDzyjDjN7uL3++CTrPTac4cXJwpwI/jYH3IE8cZIU3w1BiVUj8AACLaAGCWUqrLbN8H4P/GvXcCgGDOEqf6QmybExS6cIIjx51v9VZbFxPnzsqjq1bxaoMzccCrDQdYpyCdRlJRXICcLKNkVE4WwrlOudg5LqxCF5xv9d2+xnjNL//k6Ouqza1YUl0aNrsCCP9ucFUlsdq9rmdhCe5o1hKDfBeChr1wz5fT+LyyAvntgyCkMn6dbyYCsM+WPeY2IQEEmUznlBfhnbajjjZg1AK0C4rKSWO0BZA3NR9xbN/UfAT1LZ1Y/OhfwkJp1V2f0fbhp69+ENFeUl2K0SOyccJmvh09IjuwI0efLcVabVMH7r78LNwyZ2pYqFnHWhO13RR6xc/ecJxv+Z+awvu5hbuugDJndnV7pX5gaumn+pym1FN9/UYh6WxDkGdnB9egvMZLZ6L1kxVIJ3C5NmUEDgAAIABJREFUoP1/ee4dx7ns48ghjjNCuuHX+eZpAJuI6D5TW6wD8FS8OiU4CeLsoCvcy8Xw6WITuVypj7z5kaPIrz0w3x3HaM8uY29f6qrwcelZ4w1BkWUkz87OItSUF2nNjZzzzYq6VofjjN3kuaS6FM/cXj0waQdYO73c5XRitTmz68VTxzm2WW33cwq3lXL+DoDuuxBtEnCdSdrS+BxJwAOMoyCkI35Twv2IiF4GcJm56Val1NuDHUdECwD8HEA2gCeUUstcn5cBWA5gAoAjAG5USrWZn/0EwBfMXX+olFplbicADwD4KoB+AL9SSv3Cz32kK0HMUbq1NS5+zjqP28Gk15UXtTekcNClFVltzqw2KicLJ2xmRKu+I7fmZvXR+gH0WtFGV/7SjU0dEQ45ltbLcdsl0xwJ1t2JDOxwTicAWLMrANz8ZB02NR/BxVPH4enbqwHwJbV0DjF+qSorZDXkaE20QdK5BRlHQUhH/JpSoZTaCmDroDuaEFE2gIcBzAfQBmAzEb2klHrftttPATytlPoNEf0VgB8DuImIvgDDuecCACMAvEFELyuljgG4BcAUAOcopUJE5Hy1z1D8mqOum1WC1ZtbwyZPK3YtiHCdd/aEcO5Pq33xtCK80zYwGS6+aMBUaefl7fvx71+sdEyc//7FSgCR5snjPf149M2P0Gt60fb2K7ywtU2bK5WLqSsfPzrCRKyjorgAudmE3n6FXFs9RiDSDKlzOgH4SieWMLTDldSqKC4IlKzb3S9LQwaMNc7SotGeFT5068Lu7V7rjm4TK2emFoRMwrdgHAIXA9illGoCACJ6FsA1AOyC8VwAVkjIehhlraztG5RSfQD6iOhdAAsArIbhHbtEKRUCAKWUM32LgKysLFAohKwsp6XcLVx1ThQXTytyCMaLpxVpJ0POyUXnJPOtuWdi/QcHwibZpkOfoOnQJ44+euVKvWvumVjfeDAs2O6ae2ZEdhd3qIid2qYO9JvacMimrQ1WDmuwkAYd6xsPRrSXVJcGyvfqznW6/M+7Hfss//NuLKkuZccsaAYh7uVLp4lyyR4EIVPwu8Y4FCYD2GNrt5nb7LwDYJH597UACoioyNy+gIjyiWg8gMthaIkAcCaAxUS0hYheJqLp3MWJ6E5zny2HDh3idslIrInMyo9pL5/kdvNf/qcmx7FWm9MCAUPA1ZQXOTQtLndobVNHOCxDKTjWq+6/5jxMLcoHwfB0dC+zeeVKrSorxA++NBOXTR+PH3xpJqrKCrWhEkDk2qdufY7LBBMkpAHgQyh05me/YRlsrlP3gNna7vPq1g112zkkT6kwHImnxuiHfwTwSyK6BcAGAHsB9CulXiOiiwD8BcAhABthrCcChmn1pFJqNhEtgrFGeZn7xEqpxwA8BgCzZ88O7uWQptS5Jrk603OT0xJ0ThRFo50mwKLReZ7ahzt3qJdZ776XtocTEGQRQERhLQ4wHH10HrBcaIcuNESnDXPaGpcJxsv07DZD6sZm8UWlrPnZL9x68W2XljvX9y4t1x6vew5B1hODhlv4rcQhCKlMPAXjXgxoeQBQYm4Lo5TaB1NjJKLTAFynlPrY/OxHAH5kfrYCwIfmYW0YKJD8IoBfx6n/KYtXjb13XTF1VpvTEnROFJtd4Rqbm49g+sQC1qTGnffuy89iJ1N7Vh4AOG/yWBw/1YddhwaccjY2deCjw8cjPGAfv3m2VtPhTJ6cNqybqIMUQObMm17mRmDoa3EzXUJ/5hljA50zaByj13m4cXAfHyS+UYcUJBZSgXgKxs0AphPRNBgC8XoAS+w7mGbSI+Z64XdhaH+W487pSqkOs/bj+QBeMw9bA8O0uhvAXAwIzGHBYAHenOMMwGsJOq/UE65UZid6+j21DwuFyBAFO4e7TjnaE83YQLtgnDhmJA5oTJBWaEdvvwqHdgAIO9TkZA9s47Rhr1g9vwWQLfMmMGDeXDSrRBubWFFcgM7uHof5WYdbKOjSqQVZ3/MbxxgE3Tjq4mKjPW8sEIErBCFuglEp1UdE3wbwKoxwjeVKqQYiuh/AFqXUSwDmAfgxESkYptS7zcNzAbxllrk6BiOMw/KqWAbgd0T0vwB8AuCb8bqHVGQwt3zOcQbQawncJDtz8lhHAeOZk8dqj+fSvAH+C+TeNfdMvL7jQHjyv2vumXhmY7MjScG08QMZekIwBLAjpwyZ+p5NGHLasG7sYhEOw8UmepmEOe/PGx7bGHYsWnnnnEAmz0SiG0fOESsW540WEbhCUOK6xqiUWgsj+bh92722v58D8Bxz3EkYnqncOT/GQHzjsGOwyTLat3ZAP/lzWgZXcmn0iJwIrUo3aTS2dzkEa2N7lzbe8fmtbegzTbF9ZoL0yaePQl+/4aDS3+9txqxv6Yxa0Fw3qwTPbdkTFmDXmUnPe2whJ1YfuKQI35p7JjtJc8nfH7z2PCyoLA7XhPSTQzURk7TuO6jzRo72vNGSjgJXSC7Jdr4RAjKYdqN7a+c0Ep32EuTNnzPd6gQrt50T5Fy8IqAv/KubTN1mTF1wfND8oyvvnOMYs3W2NHH2clicV6puknabmQ93ncKytTvCY7tm2z4UjxkZET9pkchJWvcd5LyRgyYviEde1XQTuELyEcGYhnitD+ne2jmNBAArLL0C4d3cNGcqXtq2DyEYjis3zZkKAGyBXHcoxqcKRqBgRE5EgP78yuKIeEUAWDSrJKJEVRBh19jexQbHB53g3OPPlcMCEOGVOqe8CPs+PjFg+bWtk3IvDWu2OXzVsGbbXq1gjMUkHa3GGQsBFI+8qukmcIXkI4IxTfA7aene2jltS1e7URcIr7sebEt8Vh+5ArmLzIrylsCzai/aU68VjMpFVVkhnnVpZYAxwd33xcqwedQrE0xtUwdOmkWUT5qV493xepaZOegE534WOg3bbs6tnDQGT21sDlezBwxzcGN7F6rKCtmXhinj8tF+bECTnGKWDuNCIqKdpDlvW90z90oQkOxKGolc80uF+xXigwjGNCCImUw3QXLa1qO2RODAgNdoTXlR2BuSyNvTlLueVz5Qsv0Ag9f7s2IKrXFwxzHq1lR3uupS7jzQxcZnAsEmuPqWTlxv07KfvXMOllSXorXjeFhrta/pWubcvR+fCAfr27HKWXHPp7G9C5ubBxIGXHthiTYkoqqsEPde7XxpCALnbev1MqTTTuOh8fklaKafWJDM+xXihwjGNCBIqSGv2DUr5s7aPt6lpVjtxvYuh9OIpdXoyhpxEzInnDmBCUTGIeom/9qmjrDG1WNqgTptbduejx33tm3Px2GNy6LDVnfS7wTnzu366Jsf4a65Z0YkObDGy9LCcrIJOVnkiOMEBtZPuedT29QREa6h03p1dS39ovW2BbBs7Q5H0vRUNSHq/k9kLVAIigjGNMArk0yQN2G3FsYFkAO8Q0xFcYH2bZybkDlhqbsPdwzhQ69/GHH9JdWlDu0yBEO71AW8L6gsDptYrXZp0ehA4QScyZJbT7QL7FO9AxOvXQvr7Ve48lyjhOlr7w8UbJ5Xoc+Bz41XYX4eew/RTv6cty0AtjDz0oUzotJOLWJt9vSKtY2mBqYw/BDBmAZ4eQFymWA4AcZpYW+4kly/YSa55rSwIG/jAFhhqbsP9zauqLJXf7kg+qULZ6D92MlwqIPdacVP1hid1mqV0LIYlZOFrhO9DnNw2CvV5WmqAFww5XSse/9ARJYd3Rqfe2yqygqxaXdH+L5itcZYVVaI2y6ZFuHExBVmnl9ZHJV2at1vrM2bnibxKGpgCsOPeCYRF2JIVVlk4mkuwTOXEBvgtUB3hhmrbXm2AgOerbpk0tbbOAHht3GvJNXcfbi3vemKjbTaXH91BXrrWzrxSkM7jp3oxSsN7eHtEcWLNegSqbtzk952abnWK5VzqNElJ2cThjOsqGvFmm378HF3L9Zs2xdOkG5p6Z85azzuvboysJDRFXy+YMrpjv0umHJ6oCTkOmJxDg7u+6Uz4QuCDtEY0xjuDdkdMG85s3BaYGvHcUeGmTm2tUC3Z6su/2l4J9vvaLWXPZ3dbJtLyh10XemeZ98Oa1sPXX+htg86rVVnuuXMm7rwEm4cuTU+ztFH52wUdI3RbcbUnZcrtlxTXoSsLEKoXzlCTvxeC0hsqEOqrokKqYsIxjTH7TSiS4jNTegPr98VESoBBJtIuLdxTyHqgytmTHQkDbhixkTtPeiy2XD3cM+zbzsC5gFohWPBqFx2bKx++MkmVFVWiJpp47Cp+QgunjrO03OTW+/lHH10zkZB1hg5M6buvDXlRRjpWgNubO9yZCCynLP8XmsooR3RrEdKWIUQFBGMGYZXQmz3hK7bl5tIdGtgOiEajRu7LmkAdw86R5+qssjA/28sr3Nc5/UdB6DDaxz9alv3PPt2OOfshp2Hcc+zb2sFMfdCozN16/ob5GWGq4hi9d2uCXPfBZ1zlO5abk9irxcEXR5ZneOXX2EnYRVCEEQwZhhB3o6D7KuLc4s2fo6DSxrgpZFwJkQu8H9KYT52tA/EN04pzGfPCegFLveCoNO2uDyy1jk406JbEBfm50WYjnVCWPcsddfiqpR4jYV9/IOkDOQ8iXXoBGAQJzNBiAUiGDOQIG/Hurd296Sji3PzEkx+6xC6J+9otR+dFvfAtefhq7/6S1gTfeDa87R90N0X94LwI/M87vvl8sjqNO8gHqg6oeR+lp6en66KJEFqKXrVhHQ/d13pLG5f3bPUJZFI1dhEqbiR/ohgFCLgJh1dnBu3b2N7l+9JVjd5+9VkdUKU02qqygrx+7/+jC9TnW7i/dCVUcdqcyEjN82Zipfe2RcWCjfNmeqZYcYdZ2p5oALGmujF04oCFSoezDHJ6oNXujwd3DorJ1x1zyfIvrrvQyo61EjFjcxABKMQATdBVZVFVpXQ7Rt0DUpXI9HPhKKbNHUCxH5e683eStdm74Nuku7s7nVcv7O7V1t30S1saps6tIKVExQ6s6lf5x/dPdS5+lXnkUHIPk6DvaTo+ss9nyD7ApHacKo61KSyJiv4RwTjMMLvBBftOmWQNahYuNLrhKiXALG/2edkZyEni9AfUo4XAW4MysePxq6Dn4TPUz5+NFt38fGbZ6MwPy8idKbTloYOQLi9anOrY/uqza1YfFFpVJl6dPfw7t6jjuPe3XsUT99eDSDyRSKIBqR77tzzibaose68yUZCQzIDEYzDhKAmniDrVe59g5j7kvXmb3+z7+8P4fqLS3HG6aMi8sC6+zOv4lMRKd2W/3m3Yx+rsHLDPqcAath3FOUTTsOuQwOFmMsnnAYAbA3KIOPolVw84h6YtU8dQTSgIP3lEq9nghkyVTVZIRgiGIcJ0Zp4Em0iCuK8MxTcb/ZW8P1gfeCcSaa5tMhp40cD4IP275p7Jltr8q65Z+J/PjiI/pDhKWpt92s21ZkmOayQEXuiA51gDaoB+e1vfUtnROJ1r9AOv6SC44tOk02Fvgn+EMGYgcQj00iQ44N4OOoKCvs93gsv4ep+sweAh9fvCo9ZEEFRU16E9R8cCK8xfssUapzDUlVZIX7wpZlseEs2GSEN2e7imT7QZerR4Y6n5Ey5XuZYHUHqhrpftIKEduiunaoaZyr3TYhEBGOG4ZVphKt075cgE2QQ7YWbIF9zJa62Jukg+BHO1rjUt3TiBlvqtZUeqdd047Dqrkhv16qyQtznEoK6MJDapg709hsZhPr6vYtDc8LHnpmHaw8GZ8p1j9NgRFs3tLYpssxWEFLZ8SWV+yZEIoIxw9D9A+oq3QfB7wQZrfPNO3s+hm6S5uA0Q6+com6h8vzWtnCdxJ5+hee3tsXEOYQTgjpzoU5b4uIruThIq6KHhbs9GDpTbhCCTP7xCMFIZceXVO6bEIkIxgxD9w8YRIuLlmidb3TrcECkoNBphpxg02k0bssledwDdw6Az8ISxFzIldTiamDq4iA3ukIwrHaQda1oTLlA8Mk/SAiGLlWcOyFCqjq+pHLfhEhEMGYYun/AWGhAQfDrhAHwE+SzTMwkJ5S8Yv2stj1pOqfRLJpVgpWbWsMmvEVm8gLuHnTpyTgtMIi5kMuLar+WFYivy0DEmUKDmDZrmyKTwcfT3O51DvdxnJYM8C8jqRjCYZHKfROciGDMQLh/wCBaXCrA3QMnlLwEPpc0ndNontnY7Ig3fGZjc6C1scb2LlYLDGIu5EpqWf2xfhfm50U4pFhVOcpNT1iL8vGjWcEa5L6GQjwmf05LPuP0UbJmJ8QNEYzDiCBaXCqiy8gDRBczqUv2bcdutnOf4ycv73Dsu+btNjbTjlcfdBquBcHQLvd+fMJxre1mrCRnSl18USlbm1M3NrFOBh8rOC05qCCXUAkhCCIYhbgQj4nIS6gM1WwLDB7wzpkkrTJNANB6xFlY2d320wfuPuyCTJltwzFpgMNdpwDwplRdbU6O+pZOfP+l7eg1PWLthY79rO8NBb/n0IW9+DXbSqjEAPKC4A8RjELMicVEpItBjIepjgt4tzOYt+WXL5gc9vi12rGAc8jRcdfcM/H/Nx5EX79Cjs1hSVdT0g1XFPmxm2cHcjYKQpDvCBf2Ym33c10JlTCQFwT/iGAUYk7QicgtBIMkCIgVugLCwOBmu/mVxXj8T7vDoQ7zK4tj0ifOIady8ljHtvEFIwAYQmIV47Ck06rcY64risytUwKIWtAE+Y7Ut3Tivj80oLcvhLrdRxzarB8kVMJAXhD8I4JRiDk15UXIziKE+hWyBimEG6SqRLIYzGxX29QBpcyVMDU0j04OnUOOHcv5xuqn+7rcNm7MddfiEqFXFBdoBY1fU10QYeVVqssPEiphIC8I/hHBKMScxvYuh1musb1LOxnFoqpEIvAy28VqwnELFZ1Djt91Qx3ci8c9V5yN3GwKr+NZdSW3uxKhb993VFseKqh51K+w0oWoBEFCJeQFIQgiGAWWZWt3hNPHLV04I9CxQTS+aKtKJIN4BJbrhAoXcuJ33VAHF+JS29SBflM1tMcxcskPAP/hNF5j4VdY6YpkC8GRFwR/iGAUIli2docjfRyAQMIxSDIBXZabVA0t8cpFG82E41eoxEIIcy8eK+pa2dCORbNK8Pv6NkcVEh3xMtVVlfFFsgUhXohgFCJ4xZXE+5WG9kCCMWhKOC7LTaoSLwcGnVDh1uxi8dbvfvHQhXZUlRVi5R1DL1odK9Y1tOOVhnZ0nehN+e+IkP6IYBQiWFBZ7Ag/WDAEL8tU1fiiJZ5a0TkTC7B93zGcM9HwutQlDI9HDKGXiTaIII5WaHP3Fq0FQxCCIoJRiMCadIa6xhiEdIutipdWdPOTddjWZqy1bms7ipufrMOUcfkR3phA/GIIk535RtevaC0YghAUEYwCy9KFM+Iy+bg1gnSMrYqHA8Om5iMR7ZJx+Y5tCrEx5eoSoXN1ImNBNMWLq8oKY2LBEIQgiGAUEganEUhslcHFU8dhg81h6eKp47TemDnZxnhlZw9tvHRVP+LxghJt8WIgmAVDUp4JsUAEo5AwuMn37svPktgqAH9/xdl4a+dhKBghEX9/xdmsN2Z9SydgSyYwFHTm4Hi8oMSieDHgz4KRbmZ5IXURwSjEBe7NXacRSGyVIUCIDFlHhLAAcY9NbVMHeszkCT39Q8+y4z5vvNYYoy1eHIQgZbYA0S4FPSIYhZjjFesn2iEPl3oNiJy8dx7ochznbg+V+pbOuKwxJtKpRzeGQOQ4inYpeCGCUYg5XuYz0Q55TYWLI+Qm722uslPu9lCJ5xpjvJx63OhiMblxTEenLyFxZCW7A0LmYZnPsgnD2qGGw5qkf/ZaI77+RK2xZoiBVG/ZBOTl6h1i3B6ZsfLQDPrM6ls68fD6XeH+69B5wOpYUdeKm56sw4q6Vs/9dPfgHkNdH+Q7KngRV42RiBYA+DmAbABPKKWWuT4vA7AcwAQARwDcqJRqMz/7CYAvmLv+UCm1ynXsLwDcppQ6LZ73IARHTKZ6dJqKzuSYRYZZkAiOsfQbY+p3HS3IM4uFpylHtOXGdPfA9UG+o4IXcROMRJQN4GEA8wG0AdhMRC8ppd637fZTAE8rpX5DRH8F4McAbiKiLwCYBeACACMAvEFELyuljpnnng1AvslC2uGV+s1dc7CxvQtmfD/6QghXKfEbY+olwKJJNRcrT1M3sSg3xt2Drg9i1hd0xFNjvBjALqVUEwAQ0bMArgFgF4znAviO+fd6AGts2zcopfoA9BHRuwAWAFhtCtz/AP5fe3cfJEdd53H8/d1NIuYMEpMY0DzwIMYDKseFlYcrTx7uxPhwIomeGOTkPAhWyT0U53miV2BhpThKLetOOa0oXNAiAUXB1BVoLB5MqiAxGyQQwGAql4QEAjEJwhkh+/C9P7pn05ntnkzvdE93z3xeVansTM/0/n6zu/OZ30P/fiwCLs6x/DJGZZnYUIZZh/UbAie9ScftObhj34HDznWkoGh28YRWfz55zTRNs/h8WgpBSSPPYHwr8Gzk9k7grLrHbAQWEHS3XgxMMrMp4f3Xm9nXgInA+RwK1KuBle7+vFn9pjiHmNliYDHArFmdt2ZnmZVhYkMZwjmpazDuTTpuz8FTjzv6sKA49bijgfjAT7N4Qqs/n7y6IRedNYsde38/0k3ciWvtSjUUPfnms8C5ZvYr4FxgFzDk7quAe4GHgRXAI8CQmb0F+CjwjSOd2N2Xunufu/dNmzYttwrIaGWY2JB20kce4roGkyycN4Nx4V/juJ7g9qTXjx85bsCk149PnLyTFHa3X3E211w457APBln8fDbvfoW1W/eyeXc2l4tAEO7LHtnGjn0HWPbItsMm9sRN9ml2ApBIWnm2GHcBMyO3Z4T3jXD35whajJjZG4CF7v5SeGwJsCQ8thx4BvhT4G3AlrC1ONHMtrj723Ksh6RUhokNZVhqLm3XYE9PDzY8TE9PkJBnnziFo8Y3t3RbmsUTWv35tDpJJkmarl9ofTF1kSR5BuN64GQzO4EgEC8hGBccYWZTgX3uPgxcSzBDtTZx5xh332tmc4G5wKpwzPHYyPP/T6FYTkWP6SS9+bdz3DHNvpRrt+5lcGgYB4aGGi+XlxSAcbNak+rbys/nzvU7Rt3OIhjTdP0CqbqD68d6RRrJLRjdfdDMrgZ+RnC5xq3u/qSZ3QD0u/tK4DzgRjNzYDXwmfDp44E1YavwZYLLOAbzKqt0pvo3/yLGHeP2pYx7k262xdco8OsvpAf4+NJHRhYhX7H4nEzqO/3oo4Df1d1Orz6001xuAc2v7ZpXC1c6V67XMbr7vQRjhdH7rot8fRdwV8zzXiWYmXqk8+saRmlaGSYFNZqQ02z3ZlxrL65uu176w2Hrqv7o0Z2ZtKquOvckHtz84kjgXnXuSU3Xv6bRsoHNdv02+3qlbeGqdSlaEk66RhnGHRtdq9dK92Zc3WobG9ckz+FO16o6Y/Zk7qjb9SOttB9SkgKzme+dpoWr1qWAglG6SBkmBeV1rV5S3X64YedIWC4I93OM0yiwW1kMIEmjhQ6a/fk0+9g0LdwsFhmQ6lMwSldp96Sg+jfvNBNy0oobj1xxZXMfBJICe8P2/Xz8O2tHAmzFldmMy8YFeaPvVd+9mWa8OE0LN89FBqQ6FIwiOUl6846bkJP2vHFv8q207JICO25Fnrw+WCR9r7juzf0HDqbqiq1ddzl54oSGM3bz/OAi1aFgFMlJHpN9ksI27YzbpFCoD4K4FXmysGH7/lEzZpO+V9zkmev+6tSWZqXOOXZS4uvV6gcXqb6iV74R6Vh5rAC0duteXhsId6kfOHRNX5qVfpJWz4mzcN4MesN3id4eOO0tb8xktZkfPbqTg0OOc2jG7MJ5M5jQaxgwoddYGI6JThh3+NvUhHE9iav6xIkbNyzDykhSXmoxiuQkj8k+kydOGGlJDXNol/o0M27TtGQ3736FoXCHj6FhuH7lJoaGveXrQOtnyBrB6/WlD502apGCt0+fxPpth4L47dODazRbWZx8zrGTCp+hLOWlYJRYZdiZohNkPdln/4GDI3s09tihXeqTVr6JkyZE61tbA+F1ka12DS+YN2PUjNkN2/fzpZWbGBhy1m3dy5xjJ3HG7MksmDeDH/Q/O9Lt2mh2bZykccM0H1r099BdFIwyShl2pugUWb+hNrrMoX7lm0azNJsNhfrW1vheY3jYW25lxc2Y/cLdTyQuSGCRfzVpXtu4ccNmP7To76H7KBhllDKsENMJ8nhDTQq1tVv38upA0Of52sDYLphvZpbmnGMnZRb09WWI616t1W1wOBiPHBr2kfHAdoVVEX8PaqEWS8Eoo5RhhZhOkNcbalyovfKHgZGvve52MxqFeH1rK6836qQu07jfx3aGVbv/HtRCLZ6CUUYpwwoxnaCdb6hPPv9yw9v16lskWQVNqy2duC7TpN/Hdr227f57UI9N8RSMEqvdK8R0ona+oaZZsSWuRZJFiLfa0onrMk1aqCCL1zZNiLfz70E9NsVTMIrkqF1vqGn3fqxvkSTt/ZhG2pZO/TJvaQOh2XHSOGXurlSPTfEUjCIdIm7mZVxQNLv3Y1ppgi1pF4tWAiFN2JW9u1I9NsVSMIp0qEZ7HubRIklz3qRdLFoJhDRhp+5KaUTBKNKhGgVF0S2SPHaxSBN26q6URhSMIh2qzJcZ5LGLRdqwK/rDgZSXglGkQ5X9MoM8drFQ2EkWFIzSVbptRZEyXGaQxWvebT83KZaCUbpGmafod4K4FmoWr3lW51CwSrMUjNI1yj5FvxPUt1CzeM1bPUcWmzhLd1EwStfQFP32y+I1b/Uctc2dnSMvsK5eBQEFo3QRTdFvvyxe81bP8cofBkY2dz7SAuvqVRBQMEqX0azF9sviNW/lHGkWWFevgoCCUURyVvSYXZrFBNSrIKBgFJEclWHMLmkxgaTAVq+CKBhFJDdlGbOrX0ygDIEt5dWTpfwJAAAONElEQVRTdAFEpHPVxux6jZbG7Jav28Flt6xj+bodmZRr7da9vDoQBHZtpqpIjVqMIpKbLMbskraoakV0ZuqRZqqmVfSYqrROwSgiuWp1zC5pi6pWpJmpmoa6aDuDulJFpNTqZ5FmsUVVHueE+DFVqR61GEWk1LLYomr5uh2HPX/RWbP45f/u5aFn9nDe26eNmpgz1q5QXQfZGRSM0rU0FlQdrWxRFTdGCXDPY8+N/H/mCVNYdNaslrtCdR1kZ1AwSlfSWFD3iBujjHvMorNmJV5ekuZDlK6DrD6NMUpX0lhQ94gbT0waY4y7vKT2IeprqzZz6XfXsmH7/raVXYqhFqN0JY0FdY9GY5T198V1hd784JZSLFIg7WPufuRHVVxfX5/39/cXXQwpmU4bY6xafapS3lqLsfYhSt3uncHMNrh7X+wxBaNI9VVtzLSK5a1CiEvzGgWjulJFOkBZ1iRtVtXKqwk13UWTb0Q6QFZrkrZLu8u7Yft+bn5wiybOSFNy7Uo1s/nAfwC9wHfd/d/rjs8GbgWmAfuAT7j7zvDYTcAHwod+2d3vDO+/HegDBoBfAle5e8OFDtWVKt2gat197Spv1bptpT0K6Uo1s17gZuA9wE5gvZmtdPenIg/7KvA9d7/NzC4AbgQuM7MPAPOA04HXAQ+Z2X3u/jJwO/CJ8PnLgSuAb+VVD5GqqFp3X7vKW7VuWylenl2pZwJb3H2rux8E7gAuqnvMKcAD4dcPRo6fAqx290F3/z3wODAfwN3v9RBBi3FGjnUQkYqrWjezFC/PYHwr8Gzk9s7wvqiNwILw64uBSWY2Jbx/vplNNLOpwPnAzOgTzWw8cBnw07hvbmaLzazfzPr37NnTcmVEpJpq1yZec+EcdaNKU4qelfpZ4JtmdjmwGtgFDLn7KjN7J/AwsAd4BBiqe+5/EbQq18Sd2N2XAkshGGPMp/giciRlGPusWjezFCvPYNzF4a28GeF9I9z9OcIWo5m9AVjo7i+Fx5YAS8Jjy4Fnas8zs+sJJuxclWP5RaRFmvgiVZRnMK4HTjazEwgC8RJgUfQBYTfpPncfBq4lmKFam7hzjLvvNbO5wFxgVXjsCuC9wF+EzxORktLEl3RqrevJEyew/8DBysww7jS5BaO7D5rZ1cDPCC7XuNXdnzSzG4B+d18JnAfcaGZO0JX6mfDp44E1ZgbwMsFlHIPhsW8D24FHwuM/dvcb8qqHiIyd1qRtXq11/drAMA70GGplFyTXMUZ3vxe4t+6+6yJf3wXcFfO8Vwlmpsads+hxURFpkvYnbF6tdV2bEKFWdnEUMiKSK018aU6tdX1wYJhhghZj1q3sMkyEqgIFo4hICURb13mMMWoiVPMUjCLSlcrYesqzda2JUM1TMIpI1yl76ymP0D77xCn09hjDQ05Pj2kiVAMKRhHpOmVuPeUV2pt3v8LAUDC1Z2DI2bz7ldLUuWy07ZSIdJ2yrJ8atx1WXGhn4c71OxrelkPUYhSRrlOGy0iSWoZ5Xfs5/eijgN/V3ZY4CkYR6UpFX0aS1J2bV2hfde5JPLj5RQaGnPG9xlXnnpTJeTuRglFEpACNWoZ5hPYZsydzx+JzSjcTt4ws2Naws/X19Xl/f3/RxRAROUwZLxnpFma2wd374o6pxSgiUpCiu3MlnmalioiIRCgYRUREIhSMItJQ3LV2Ip1MY4wikqjsS6eJ5EEtRhFJlNcqLCJlpmAUkURlWTpNpJ3UlSoiicqwdJpIuykYRaQhXWsn3UZdqSIiIhEKRhERkQgFo4iISISCUUSkS2ixhuZo8o2ISBfYsH0/H//O2pFtrlZcqcUakqjFKCLSBX786E4ODg7jwMHBYX786M6ii1RaCkYRkS5Qv/Nu5+/EO3YKRhGRLrBw3gwm9BoGTOg1Fs6bUXSRSktjjCJdaPm6Hdy36Xned9pxLDprVtHFkTY4Y/ZkViw+R6sYNUHBKNJllq/bwRfufgKANb/5LYDCsUtoFaPmqCtVpMvct+n5hrdFup2CUaTLvO+04xreFul26koV6TK1blONMYrEUzCKdKFFZ81SIIokUFeqiIhIhIJRREQkQsEoIiISoWAUERGJUDCKiIhEKBhFREpG+yYWS5driIiUyIbt+7n0u2s5ODjMhHE93H6F9k1sN7UYRURKZO3WvRwcHGbYYWBwmLVb9xZdpK6jYBQRKZGzT5zChHE99BqMH9fD2SdOKbpIXSfXYDSz+Wa22cy2mNnnY47PNrP7zexxM3vIzGZEjt1kZpvCfx+L3H+Cma0Lz3mnmU3Isw4iUh3L1+3gslvWsXzdjqKLMmZnzJ7M7VeczTUXzlE3akFyG2M0s17gZuA9wE5gvZmtdPenIg/7KvA9d7/NzC4AbgQuM7MPAPOA04HXAQ+Z2X3u/jJwE/B1d7/DzL4N/B3wrbzqISLV0EnbaWl7qGLl2WI8E9ji7lvd/SBwB3BR3WNOAR4Iv34wcvwUYLW7D7r774HHgflmZsAFwF3h424DPpxjHUSkIrSdlmQlz2B8K/Bs5PbO8L6ojcCC8OuLgUlmNiW8f76ZTTSzqcD5wExgCvCSuw82OCcAZrbYzPrNrH/Pnj2ZVEhEykvbaUlWir5c47PAN83scmA1sAsYcvdVZvZO4GFgD/AIMJTmxO6+FFgK0NfX51kWWkTKR9tpSVbyDMZdBK28mhnhfSPc/TnCFqOZvQFY6O4vhceWAEvCY8uBZ4C9wDFmNi5sNY46p4h0L22nJVnIsyt1PXByOIt0AnAJsDL6ADObama1MlwL3Bre3xt2qWJmc4G5wCp3d4KxyI+Ez/kk8JMc6yAiIl0mt2AMW3RXAz8DngZ+4O5PmtkNZvah8GHnAZvN7BlgOmELERgPrDGzpwi6Qz8RGVf8V+AaM9tCMOZ4S151EBGR7mNBI6yz9fX1eX9/f9HFEBGRkjCzDe7eF3dMK9+IiIhEKBhFREQiFIwiIiIRCkYREZEIBaOIiEiEglFERCRCwSgiIhKhYBQREYlQMIqIiEQoGEVERCK6Ykk4M9sDbC+6HBmYCvy26ELkRHWrnk6tF6huVZS2XrPdfVrcga4Ixk5hZv1Ja/tVnepWPZ1aL1DdqijLeqkrVUREJELBKCIiEqFgrJalRRcgR6pb9XRqvUB1q6LM6qUxRhERkQi1GEVERCIUjCIiIhEKxoows380s01m9qSZ/VPR5WmFmd1qZi+a2abIfW8ys5+b2W/C/ycXWcaxSKjXR8Of2bCZVXaKfELdvmJmvzazx83sbjM7psgyjlVC3b4c1usxM1tlZm8psoxjEVevyLF/NjM3s6lFlK1VCT+zL5nZrvBn9piZvX+s51cwVoCZnQZcCZwJ/AnwQTN7W7GlaskyYH7dfZ8H7nf3k4H7w9tVs4zR9doELABWt7002VrG6Lr9HDjN3ecCzwDXtrtQGVnG6Lp9xd3nuvvpwP8A17W9VK1bxuh6YWYzgQuBHe0uUIaWEVM34Ovufnr4796xnlzBWA1/DKxz9wPuPgj8guDNtpLcfTWwr+7ui4Dbwq9vAz7c1kJlIK5e7v60u28uqEiZSajbqvD3EWAtMKPtBctAQt1ejtz8I6BysxQT/s4Avg58jgrWqaZB3TKhYKyGTcCfm9kUM5sIvB+YWXCZsjbd3Z8Pv94NTC+yMJLap4D7ii5ElsxsiZk9C1xKNVuMo5jZRcAud99YdFlycnXYBX5rK8MxCsYKcPengZuAVcBPgceAoUILlSMPriGq7KfZbmNmXwQGgduLLkuW3P2L7j6ToF5XF12eVoUfqr9Ah4R8jG8BJwGnA88DXxvriRSMFeHut7j7Ge7+bmA/wZhOJ3nBzI4DCP9/seDySBPM7HLgg8Cl3rkXRd8OLCy6EBk4CTgB2Ghm2wi6vh81s2MLLVVG3P0Fdx9y92HgOwRzMsZEwVgRZvbm8P9ZBOOLy4stUeZWAp8Mv/4k8JMCyyJNMLP5BGNVH3L3A0WXJ0tmdnLk5kXAr4sqS1bc/Ql3f7O7H+/uxwM7gXnuvrvgomWi9sE6dDHBENTYztW5H/I6i5mtAaYAA8A17n5/wUUaMzNbAZxHsE3MC8D1wD3AD4BZBFuE/bW75za4noeEeu0DvgFMA14CHnP39xZVxrFKqNu1wOuAveHD1rr7pwspYAsS6vZ+YA4wTPD7+Gl331VUGccirl7ufkvk+Dagz90rtwVVws/sPIJuVAe2AVdF5i2kO7+CUURE5BB1pYqIiEQoGEVERCIUjCIiIhEKRhERkQgFo4iISISCUaTizGzbWHZJMLNlZvaRFI8/Pm6nBpFOo2AUERGJUDCKVIiZ3WNmG8I9HhfHHP+bcBHljWb2/fC+483sgfD++8PVk2rebWYPm9nWWuvRAl8J9/98wsw+1qbqiZTCuKILICKpfMrd95nZ64H1Zvaj2gEzOxX4N+DP3P23Zvam8NA3gNvc/TYz+xTwnxza1us44F3AOwiW5buLYMnB0wn2/pwafp+q7ycp0jS1GEWq5R/MbCPB/oczgeianhcAP6wt8RVZUu8cDq2t+32CIKy5x92H3f0pDm319S5gRbgg8wsE+3++M5faiJSQWowiFWFm5wF/CZzj7gfM7CHgqBZP+1r0W7R4LpGOoBajSHW8EdgfhuI7gLPrjj8AfNTMpgBEulIfBi4Jv74UWHOE77MG+JiZ9ZrZNODdwC+zqIBIFajFKFIdPwU+bWZPA5sJulNHuPuTZrYE+IWZDQG/Ai4H/h74bzP7F2AP8LdH+D53E3S/biTYqeBz7r7bzI7Prioi5aXdNURERCLUlSoiIhKhYBQREYlQMIqIiEQoGEVERCIUjCIiIhEKRhERkQgFo4iISMT/A/kfWUeC3QQfAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.savefig('alcohol_density.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "abwCzqnkGp07",
        "outputId": "004a1285-a1f1-4eaa-bbe4-3a619756a68d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def goodQuality(ligne):\n",
        "  if ligne.quality>5:\n",
        "    return 1\n",
        "  return 0\n",
        "\n",
        "data['label'] = data.apply(goodQuality, axis = 1)"
      ],
      "metadata": {
        "id": "57Td3dhPHdj5"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# on vérifie que tout s'est bien passé\n",
        "data[data.quality==0].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "3DkfpygeHpCJ",
        "outputId": "8d687cac-ff5e-4c8e-f5f0-6b6ee9efd2fc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates, alcohol, quality, label]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9379bada-51da-4d38-9d1a-12fa8e5c55b1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9379bada-51da-4d38-9d1a-12fa8e5c55b1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9379bada-51da-4d38-9d1a-12fa8e5c55b1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9379bada-51da-4d38-9d1a-12fa8e5c55b1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# on vérifie que tout s'est bien passé\n",
        "data[data.quality==1].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "RJJNAx1dH1XA",
        "outputId": "59b805b6-d380-420b-ebf4-4b4bbd9f9777"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates, alcohol, quality, label]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8937daf5-7326-419b-9d0d-b7fe08d9bd0c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8937daf5-7326-419b-9d0d-b7fe08d9bd0c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8937daf5-7326-419b-9d0d-b7fe08d9bd0c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8937daf5-7326-419b-9d0d-b7fe08d9bd0c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# on vérifie que tout s'est bien passé\n",
        "data[data.quality==2].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "-zu1Il-IICw5",
        "outputId": "30625a79-3ad8-42e3-860f-7ba9e5deb8b5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates, alcohol, quality, label]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-939e1716-094f-4c1f-8f9c-e9bf9bf58da0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-939e1716-094f-4c1f-8f9c-e9bf9bf58da0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-939e1716-094f-4c1f-8f9c-e9bf9bf58da0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-939e1716-094f-4c1f-8f9c-e9bf9bf58da0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# on vérifie que tout s'est bien passé\n",
        "data[data.quality==3].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "poORtD36IEsB",
        "outputId": "2dd5a28c-058c-4e7e-c821-6e9647833ead"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "459           11.6             0.580         0.66            2.20      0.074   \n",
              "517           10.4             0.610         0.49            2.10      0.200   \n",
              "690            7.4             1.185         0.00            4.25      0.097   \n",
              "832           10.4             0.440         0.42            1.50      0.145   \n",
              "899            8.3             1.020         0.02            3.40      0.084   \n",
              "\n",
              "     free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "459                 10.0                  47.0  1.00080  3.25       0.57   \n",
              "517                  5.0                  16.0  0.99940  3.16       0.63   \n",
              "690                  5.0                  14.0  0.99660  3.63       0.54   \n",
              "832                 34.0                  48.0  0.99832  3.38       0.86   \n",
              "899                  6.0                  11.0  0.99892  3.48       0.49   \n",
              "\n",
              "     alcohol  quality  label  \n",
              "459      9.0        3      0  \n",
              "517      8.4        3      0  \n",
              "690     10.7        3      0  \n",
              "832      9.9        3      0  \n",
              "899     11.0        3      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af665b56-9041-4603-8f5f-54d3693c2628\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>11.6</td>\n",
              "      <td>0.580</td>\n",
              "      <td>0.66</td>\n",
              "      <td>2.20</td>\n",
              "      <td>0.074</td>\n",
              "      <td>10.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1.00080</td>\n",
              "      <td>3.25</td>\n",
              "      <td>0.57</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>10.4</td>\n",
              "      <td>0.610</td>\n",
              "      <td>0.49</td>\n",
              "      <td>2.10</td>\n",
              "      <td>0.200</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.99940</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.63</td>\n",
              "      <td>8.4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>690</th>\n",
              "      <td>7.4</td>\n",
              "      <td>1.185</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.25</td>\n",
              "      <td>0.097</td>\n",
              "      <td>5.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.99660</td>\n",
              "      <td>3.63</td>\n",
              "      <td>0.54</td>\n",
              "      <td>10.7</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>832</th>\n",
              "      <td>10.4</td>\n",
              "      <td>0.440</td>\n",
              "      <td>0.42</td>\n",
              "      <td>1.50</td>\n",
              "      <td>0.145</td>\n",
              "      <td>34.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>0.99832</td>\n",
              "      <td>3.38</td>\n",
              "      <td>0.86</td>\n",
              "      <td>9.9</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>899</th>\n",
              "      <td>8.3</td>\n",
              "      <td>1.020</td>\n",
              "      <td>0.02</td>\n",
              "      <td>3.40</td>\n",
              "      <td>0.084</td>\n",
              "      <td>6.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.99892</td>\n",
              "      <td>3.48</td>\n",
              "      <td>0.49</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af665b56-9041-4603-8f5f-54d3693c2628')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af665b56-9041-4603-8f5f-54d3693c2628 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af665b56-9041-4603-8f5f-54d3693c2628');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# on vérifie que tout s'est bien passé\n",
        "data[data.quality==4].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "tuyXvSDAIkLk",
        "outputId": "ac75190e-fd17-4d5e-e7a1-661ca309085e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "18            7.4             0.590         0.08             4.4      0.086   \n",
              "38            5.7             1.130         0.09             1.5      0.172   \n",
              "41            8.8             0.610         0.30             2.8      0.088   \n",
              "45            4.6             0.520         0.15             2.1      0.054   \n",
              "73            8.3             0.675         0.26             2.1      0.084   \n",
              "\n",
              "    free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "18                  6.0                  29.0   0.9974  3.38       0.50   \n",
              "38                  7.0                  19.0   0.9940  3.50       0.48   \n",
              "41                 17.0                  46.0   0.9976  3.26       0.51   \n",
              "45                  8.0                  65.0   0.9934  3.90       0.56   \n",
              "73                 11.0                  43.0   0.9976  3.31       0.53   \n",
              "\n",
              "    alcohol  quality  label  \n",
              "18      9.0        4      0  \n",
              "38      9.8        4      0  \n",
              "41      9.3        4      0  \n",
              "45     13.1        4      0  \n",
              "73      9.2        4      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc4be8d8-2c3a-41dc-a435-72d3ab4b9417\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.590</td>\n",
              "      <td>0.08</td>\n",
              "      <td>4.4</td>\n",
              "      <td>0.086</td>\n",
              "      <td>6.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.9974</td>\n",
              "      <td>3.38</td>\n",
              "      <td>0.50</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>5.7</td>\n",
              "      <td>1.130</td>\n",
              "      <td>0.09</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.172</td>\n",
              "      <td>7.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.9940</td>\n",
              "      <td>3.50</td>\n",
              "      <td>0.48</td>\n",
              "      <td>9.8</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>8.8</td>\n",
              "      <td>0.610</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.8</td>\n",
              "      <td>0.088</td>\n",
              "      <td>17.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>0.9976</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.51</td>\n",
              "      <td>9.3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>4.6</td>\n",
              "      <td>0.520</td>\n",
              "      <td>0.15</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.054</td>\n",
              "      <td>8.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.9934</td>\n",
              "      <td>3.90</td>\n",
              "      <td>0.56</td>\n",
              "      <td>13.1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>8.3</td>\n",
              "      <td>0.675</td>\n",
              "      <td>0.26</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.084</td>\n",
              "      <td>11.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.9976</td>\n",
              "      <td>3.31</td>\n",
              "      <td>0.53</td>\n",
              "      <td>9.2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc4be8d8-2c3a-41dc-a435-72d3ab4b9417')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fc4be8d8-2c3a-41dc-a435-72d3ab4b9417 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fc4be8d8-2c3a-41dc-a435-72d3ab4b9417');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# on vérifie que tout s'est bien passé\n",
        "data[data.quality==5].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "QcTmzO9GIQfc",
        "outputId": "873553d2-a4eb-46ea-8653-dc3d9b2f566c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "0            7.4              0.70         0.00             1.9      0.076   \n",
              "1            7.8              0.88         0.00             2.6      0.098   \n",
              "2            7.8              0.76         0.04             2.3      0.092   \n",
              "4            7.4              0.70         0.00             1.9      0.076   \n",
              "5            7.4              0.66         0.00             1.8      0.075   \n",
              "\n",
              "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
              "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
              "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
              "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
              "5                 13.0                  40.0   0.9978  3.51       0.56   \n",
              "\n",
              "   alcohol  quality  label  \n",
              "0      9.4        5      0  \n",
              "1      9.8        5      0  \n",
              "2      9.8        5      0  \n",
              "4      9.4        5      0  \n",
              "5      9.4        5      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-15eb26c5-f3b8-4903-8b17-111eb46ccd59\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.075</td>\n",
              "      <td>13.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15eb26c5-f3b8-4903-8b17-111eb46ccd59')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-15eb26c5-f3b8-4903-8b17-111eb46ccd59 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-15eb26c5-f3b8-4903-8b17-111eb46ccd59');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# on vérifie que tout s'est bien passé\n",
        "data[data.quality==6].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "Jkg56RBGIbJS",
        "outputId": "fcded057-498e-43d0-9f3d-b573fa3dc7c8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "3            11.2             0.280         0.56             1.9      0.075   \n",
              "19            7.9             0.320         0.51             1.8      0.341   \n",
              "20            8.9             0.220         0.48             1.8      0.077   \n",
              "24            6.9             0.400         0.14             2.4      0.085   \n",
              "29            7.8             0.645         0.00             2.0      0.082   \n",
              "\n",
              "    free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "3                  17.0                  60.0   0.9980  3.16       0.58   \n",
              "19                 17.0                  56.0   0.9969  3.04       1.08   \n",
              "20                 29.0                  60.0   0.9968  3.39       0.53   \n",
              "24                 21.0                  40.0   0.9968  3.43       0.63   \n",
              "29                  8.0                  16.0   0.9964  3.38       0.59   \n",
              "\n",
              "    alcohol  quality  label  \n",
              "3       9.8        6      1  \n",
              "19      9.2        6      1  \n",
              "20      9.4        6      1  \n",
              "24      9.7        6      1  \n",
              "29      9.8        6      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02f9dd79-0438-47c1-93b7-925e9faa4cff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>7.9</td>\n",
              "      <td>0.320</td>\n",
              "      <td>0.51</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.341</td>\n",
              "      <td>17.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>0.9969</td>\n",
              "      <td>3.04</td>\n",
              "      <td>1.08</td>\n",
              "      <td>9.2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>8.9</td>\n",
              "      <td>0.220</td>\n",
              "      <td>0.48</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.077</td>\n",
              "      <td>29.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.53</td>\n",
              "      <td>9.4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>6.9</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.14</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.085</td>\n",
              "      <td>21.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.43</td>\n",
              "      <td>0.63</td>\n",
              "      <td>9.7</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.645</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.082</td>\n",
              "      <td>8.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.9964</td>\n",
              "      <td>3.38</td>\n",
              "      <td>0.59</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02f9dd79-0438-47c1-93b7-925e9faa4cff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02f9dd79-0438-47c1-93b7-925e9faa4cff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02f9dd79-0438-47c1-93b7-925e9faa4cff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# on vérifie que tout s'est bien passé\n",
        "data[data.quality==7].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "SAm5fOXCIdQ9",
        "outputId": "ce9ab5dc-e992-4b1a-b5e6-8390ca53f47f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "7             7.3              0.65         0.00             1.2      0.065   \n",
              "8             7.8              0.58         0.02             2.0      0.073   \n",
              "16            8.5              0.28         0.56             1.8      0.092   \n",
              "37            8.1              0.38         0.28             2.1      0.066   \n",
              "62            7.5              0.52         0.16             1.9      0.085   \n",
              "\n",
              "    free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "7                  15.0                  21.0   0.9946  3.39       0.47   \n",
              "8                   9.0                  18.0   0.9968  3.36       0.57   \n",
              "16                 35.0                 103.0   0.9969  3.30       0.75   \n",
              "37                 13.0                  30.0   0.9968  3.23       0.73   \n",
              "62                 12.0                  35.0   0.9968  3.38       0.62   \n",
              "\n",
              "    alcohol  quality  label  \n",
              "7      10.0        7      1  \n",
              "8       9.5        7      1  \n",
              "16     10.5        7      1  \n",
              "37      9.7        7      1  \n",
              "62      9.5        7      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-febf2d19-f4cf-44b5-8eda-d305aadfd829\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7.3</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.065</td>\n",
              "      <td>15.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.9946</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.47</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.02</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.073</td>\n",
              "      <td>9.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.36</td>\n",
              "      <td>0.57</td>\n",
              "      <td>9.5</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>8.5</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.092</td>\n",
              "      <td>35.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>0.9969</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.75</td>\n",
              "      <td>10.5</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>8.1</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.066</td>\n",
              "      <td>13.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.23</td>\n",
              "      <td>0.73</td>\n",
              "      <td>9.7</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>7.5</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.16</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.085</td>\n",
              "      <td>12.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.38</td>\n",
              "      <td>0.62</td>\n",
              "      <td>9.5</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-febf2d19-f4cf-44b5-8eda-d305aadfd829')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-febf2d19-f4cf-44b5-8eda-d305aadfd829 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-febf2d19-f4cf-44b5-8eda-d305aadfd829');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# on vérifie que tout s'est bien passé\n",
        "data[data.quality==8].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "uT8Clr40IfDh",
        "outputId": "af1707a3-a2e1-489d-d658-23deb7e2299b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "267            7.9              0.35         0.46             3.6      0.078   \n",
              "278           10.3              0.32         0.45             6.4      0.073   \n",
              "390            5.6              0.85         0.05             1.4      0.045   \n",
              "440           12.6              0.31         0.72             2.2      0.072   \n",
              "455           11.3              0.62         0.67             5.2      0.086   \n",
              "\n",
              "     free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "267                 15.0                  37.0   0.9973  3.35       0.86   \n",
              "278                  5.0                  13.0   0.9976  3.23       0.82   \n",
              "390                 12.0                  88.0   0.9924  3.56       0.82   \n",
              "440                  6.0                  29.0   0.9987  2.88       0.82   \n",
              "455                  6.0                  19.0   0.9988  3.22       0.69   \n",
              "\n",
              "     alcohol  quality  label  \n",
              "267     12.8        8      1  \n",
              "278     12.6        8      1  \n",
              "390     12.9        8      1  \n",
              "440      9.8        8      1  \n",
              "455     13.4        8      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca0721ce-c287-4794-ba3d-3b31fa219ad9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>7.9</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.46</td>\n",
              "      <td>3.6</td>\n",
              "      <td>0.078</td>\n",
              "      <td>15.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>0.9973</td>\n",
              "      <td>3.35</td>\n",
              "      <td>0.86</td>\n",
              "      <td>12.8</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>10.3</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.45</td>\n",
              "      <td>6.4</td>\n",
              "      <td>0.073</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.9976</td>\n",
              "      <td>3.23</td>\n",
              "      <td>0.82</td>\n",
              "      <td>12.6</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>5.6</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.05</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.045</td>\n",
              "      <td>12.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>0.9924</td>\n",
              "      <td>3.56</td>\n",
              "      <td>0.82</td>\n",
              "      <td>12.9</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>12.6</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.72</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.072</td>\n",
              "      <td>6.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.9987</td>\n",
              "      <td>2.88</td>\n",
              "      <td>0.82</td>\n",
              "      <td>9.8</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455</th>\n",
              "      <td>11.3</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.67</td>\n",
              "      <td>5.2</td>\n",
              "      <td>0.086</td>\n",
              "      <td>6.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.9988</td>\n",
              "      <td>3.22</td>\n",
              "      <td>0.69</td>\n",
              "      <td>13.4</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca0721ce-c287-4794-ba3d-3b31fa219ad9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ca0721ce-c287-4794-ba3d-3b31fa219ad9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ca0721ce-c287-4794-ba3d-3b31fa219ad9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# on vérifie que tout s'est bien passé\n",
        "data[data.quality==9].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "Mnw8Yg0LIgb1",
        "outputId": "1bce802f-9c5f-4f06-99de-0609d53a2116"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates, alcohol, quality, label]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-207e4fc5-cd21-417f-8988-5c3128394eea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-207e4fc5-cd21-417f-8988-5c3128394eea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-207e4fc5-cd21-417f-8988-5c3128394eea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-207e4fc5-cd21-417f-8988-5c3128394eea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# on vérifie que tout s'est bien passé\n",
        "data[data.quality==10].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "krOan8jYIS6I",
        "outputId": "a001f93a-0ed8-4d39-d45a-813e65293db3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates, alcohol, quality, label]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d82ef118-4ef9-4a7a-a2f9-1122fece0196\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d82ef118-4ef9-4a7a-a2f9-1122fece0196')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d82ef118-4ef9-4a7a-a2f9-1122fece0196 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d82ef118-4ef9-4a7a-a2f9-1122fece0196');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(3,3))  # Create a figure and an axes.\n",
        "ax.scatter(data.quality,np.zeros_like(data.quality), marker='.',  label='vins')\n",
        "# Plot some data on the axes.\n",
        "ax.set_xlabel('vins')  # Add an x-label to the axes.\n",
        "ax.set_title(\"nuage de point de la qualité\")  # Add a title to the axes.\n",
        "ax.legend();  # Add a legend."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "K04xOBZQIx20",
        "outputId": "70b22386-3adf-4e25-8847-083d9b598bdf"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts, bins = np.histogram(data.quality)\n",
        "plt.hist(bins[:-1], bins, weights=counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "RdIhF7gsJDzQ",
        "outputId": "1089a0b9-cc28-4b58-b34b-48ed9c52c9d6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 10.,   0.,  53.,   0., 681.,   0., 638.,   0., 199.,  18.]),\n",
              " array([3. , 3.5, 4. , 4.5, 5. , 5.5, 6. , 6.5, 7. , 7.5, 8. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# on garde les qualités comme labels..\n",
        "y=data.label\n",
        "print(y.head())\n",
        "\n",
        "# on les dégage des caractéristiques (et les labels aussi)\n",
        "x=data.drop(['quality','label'],axis=1)\n",
        "\n",
        "x.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "y1WrnE_kKB56",
        "outputId": "388881c3-59b9-4e34-b21f-b4f0dccf81ff"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    0\n",
            "1    0\n",
            "2    0\n",
            "3    1\n",
            "4    0\n",
            "Name: label, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "0            7.4              0.70         0.00             1.9      0.076   \n",
              "1            7.8              0.88         0.00             2.6      0.098   \n",
              "2            7.8              0.76         0.04             2.3      0.092   \n",
              "3           11.2              0.28         0.56             1.9      0.075   \n",
              "4            7.4              0.70         0.00             1.9      0.076   \n",
              "\n",
              "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
              "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
              "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
              "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
              "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
              "\n",
              "   alcohol  \n",
              "0      9.4  \n",
              "1      9.8  \n",
              "2      9.8  \n",
              "3      9.8  \n",
              "4      9.4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0eeaf5b-7bba-418e-adec-dc658557c49b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0eeaf5b-7bba-418e-adec-dc658557c49b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a0eeaf5b-7bba-418e-adec-dc658557c49b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a0eeaf5b-7bba-418e-adec-dc658557c49b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Le split en lui meme \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Je fixe la graine aléatoire à 42 pour etre sur que vous aurez la meme chose\n",
        "# que moi\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)\n",
        "\n",
        "print (x_train.shape)\n",
        "print (x_test.shape)\n",
        "\n",
        "print(type(x_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZYCJ39WKNBN",
        "outputId": "2345d132-bac0-481a-ebde-736767b3c0fd"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1119, 11)\n",
            "(480, 11)\n",
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Création de l'algo...\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=1)\n",
        "neigh.fit(x_train, y_train)\n",
        "\n",
        "# Utilisation de l'algo sur l'exemple 21 de la base de test\n",
        "aResu= neigh.predict([x_test.iloc[15]])\n",
        "print(\"Resultat prédit :\",aResu, \"Resultat Attendu \",y_test.iloc[15])\n",
        "\n",
        "# Mesure de performances \n",
        "train_accuracy = neigh.score(x_train, y_train)\n",
        "print(\"Perf en apprentissage\", train_accuracy)\n",
        "\n",
        "test_accuracy = neigh.score(x_test, y_test)\n",
        "print(\"Perf en validation\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atsjhjwtKYGK",
        "outputId": "35dee3fc-0ffa-48d4-b82f-d41180ba6699"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultat prédit : [0] Resultat Attendu  1\n",
            "Perf en apprentissage 1.0\n",
            "Perf en validation 0.6791666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "52% de succès"
      ],
      "metadata": {
        "id": "8qrBWbK_KiQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Création de l'algo...\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(x_train, y_train)\n",
        "\n",
        "# Mesure de performances \n",
        "train_accuracy = neigh.score(x_train, y_train)\n",
        "print(\"Perf en apprentissage\", train_accuracy)\n",
        "\n",
        "test_accuracy = neigh.score(x_test, y_test)\n",
        "print(\"Perf en validation\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojUNyucEKp6z",
        "outputId": "f9ad52f1-5529-48c6-dc90-f3b4f8dc2e47"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perf en apprentissage 0.8364611260053619\n",
            "Perf en validation 0.64375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "# On calcule les parametres de la normalisation\n",
        "scaler = preprocessing.StandardScaler().fit(x_train)\n",
        "\n",
        "# Et on normalise les 2 bases\n",
        "x_train_norm = scaler.transform(x_train)\n",
        "x_test_norm = scaler.transform(x_test)\n",
        "\n",
        "# On a perdu les dataFrames dans la bataille,\n",
        "#   x_test_norm est maintenant un ndarray...\n",
        "print (x_train_norm)\n",
        "print(x_test_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WD4Lg1tJK77Q",
        "outputId": "c83eddda-3b25-4fc9-af93-a7681b8be08c"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.28659319  0.39016751 -1.00152597 ...  0.43962378 -0.70985154\n",
            "   0.54908041]\n",
            " [-0.60034201 -0.43834304  0.44441503 ...  0.11813704  1.09599608\n",
            "   0.0821242 ]\n",
            " [-0.37159162  0.27969944 -1.36301122 ...  0.05383969 -0.58531032\n",
            "   0.0821242 ]\n",
            " ...\n",
            " [-0.77190481  0.66633769 -1.31137047 ...  1.0182999   0.09966636\n",
            "  -0.85178822]\n",
            " [-0.42877922  0.85965682 -0.22691472 ... -0.65343113 -0.27395728\n",
            "  -1.0385707 ]\n",
            " [-0.9434676   0.05876329 -0.74332222 ...  1.91846277 -0.08714546\n",
            "  -0.57161449]]\n",
            "[[ 0.14309676  1.49484824 -0.84660372 ...  0.56821847 -1.08347518\n",
            "  -0.47822325]\n",
            " [ 0.65778514 -0.383109   -0.17527397 ... -1.23210726  0.53556061\n",
            "  -0.38483201]\n",
            " [ 1.40122392 -1.32208763  0.75425953 ... -0.2033497   0.47329001\n",
            "   1.38960159]\n",
            " ...\n",
            " [-0.20002883  0.27969944  0.03128903 ... -0.58913378 -0.70985154\n",
            "  -0.94517946]\n",
            " [-0.54315442  0.11399733 -0.43347772 ...  1.1468946   0.16193697\n",
            "   0.0821242 ]\n",
            " [ 2.08747509 -0.16217286  1.63215229 ... -2.51805421  0.16193697\n",
            "   0.0821242 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Création de l'algo...\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(x_train_norm, y_train)\n",
        "\n",
        "# Mesure de performances \n",
        "train_accuracy = neigh.score(x_train_norm, y_train)\n",
        "print(\"Perf en apprentissage\", train_accuracy)\n",
        "\n",
        "test_accuracy = neigh.score(x_test_norm, y_test)\n",
        "print(\"Perf en validation\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-cATOE-K_a_",
        "outputId": "f8e449fa-5ec2-42fc-a66d-c14094d3165c"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perf en apprentissage 0.8525469168900804\n",
            "Perf en validation 0.7041666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "\n",
        "# J'ai oublié pourquoi gamma, faudrait regarder... \"C\" a un rapport\n",
        "# avec le fait que les données ne sont pas linéairement séparables...\n",
        "algoSVM = svm.SVC(gamma=0.001, C=100.)\n",
        "\n",
        "algoSVM.fit(x_train_norm,y_train)\n",
        "\n",
        "train_accuracy = algoSVM.score(x_train_norm, y_train)\n",
        "print(\"Perf en apprentissage\", train_accuracy)\n",
        "\n",
        "test_accuracy = algoSVM.score(x_test_norm, y_test)\n",
        "print(\"Perf en validation\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH4NP1qWLHYM",
        "outputId": "1ef1b9af-5249-45dd-9cfb-f29241a75311"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perf en apprentissage 0.7515638963360143\n",
            "Perf en validation 0.7416666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.Input(shape=(11)),\n",
        "  tf.keras.layers.Dense(5, activation='relu'),\n",
        "  tf.keras.layers.Dense(5, activation='relu'),\n",
        "  tf.keras.layers.Dense(2)\n",
        "])\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Easy isn't it ?\n",
        "\n",
        "# On vérifie en regardant le résumé de ce réseau :\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXWJckmlLTYY",
        "outputId": "6dd3b841-ae66-4afe-f927-8633e7e92e2b"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_15 (Dense)            (None, 5)                 60        \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 2)                 12        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 102\n",
            "Trainable params: 102\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 100\n",
        "\n",
        "# La base d'apprentissage\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x_train_norm,y_train))\n",
        "dataset = dataset.shuffle(x_train_norm.shape[0])\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "\n",
        "train_dataset = dataset\n",
        "\n",
        "# La base de validation\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x_test_norm,y_test))\n",
        "dataset = dataset.shuffle(x_test_norm.shape[0])\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "\n",
        "test_dataset = dataset"
      ],
      "metadata": {
        "id": "CE7TUCwpLmxY"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(dataset, validation_data=test_dataset, epochs=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rCGfxLMLxjB",
        "outputId": "484f11ba-0ead-43fa-8606-3c10288f9e61"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "5/5 [==============================] - 1s 42ms/step - loss: 0.7085 - accuracy: 0.6479 - val_loss: 0.7017 - val_accuracy: 0.6667\n",
            "Epoch 2/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6985 - accuracy: 0.6708 - val_loss: 0.6926 - val_accuracy: 0.6750\n",
            "Epoch 3/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6896 - accuracy: 0.6750 - val_loss: 0.6843 - val_accuracy: 0.6750\n",
            "Epoch 4/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6812 - accuracy: 0.6750 - val_loss: 0.6766 - val_accuracy: 0.6833\n",
            "Epoch 5/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6740 - accuracy: 0.6875 - val_loss: 0.6694 - val_accuracy: 0.7000\n",
            "Epoch 6/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6668 - accuracy: 0.6979 - val_loss: 0.6624 - val_accuracy: 0.6979\n",
            "Epoch 7/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6602 - accuracy: 0.7000 - val_loss: 0.6557 - val_accuracy: 0.7063\n",
            "Epoch 8/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6533 - accuracy: 0.7021 - val_loss: 0.6494 - val_accuracy: 0.7104\n",
            "Epoch 9/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6469 - accuracy: 0.7104 - val_loss: 0.6436 - val_accuracy: 0.7188\n",
            "Epoch 10/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6417 - accuracy: 0.7146 - val_loss: 0.6384 - val_accuracy: 0.7104\n",
            "Epoch 11/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6364 - accuracy: 0.7125 - val_loss: 0.6334 - val_accuracy: 0.7104\n",
            "Epoch 12/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6317 - accuracy: 0.7104 - val_loss: 0.6286 - val_accuracy: 0.7125\n",
            "Epoch 13/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6272 - accuracy: 0.7146 - val_loss: 0.6241 - val_accuracy: 0.7104\n",
            "Epoch 14/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6223 - accuracy: 0.7083 - val_loss: 0.6200 - val_accuracy: 0.7104\n",
            "Epoch 15/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6183 - accuracy: 0.7104 - val_loss: 0.6159 - val_accuracy: 0.7104\n",
            "Epoch 16/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6144 - accuracy: 0.7104 - val_loss: 0.6120 - val_accuracy: 0.7104\n",
            "Epoch 17/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6109 - accuracy: 0.7104 - val_loss: 0.6082 - val_accuracy: 0.7125\n",
            "Epoch 18/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6070 - accuracy: 0.7125 - val_loss: 0.6046 - val_accuracy: 0.7125\n",
            "Epoch 19/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6034 - accuracy: 0.7125 - val_loss: 0.6012 - val_accuracy: 0.7146\n",
            "Epoch 20/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6000 - accuracy: 0.7146 - val_loss: 0.5980 - val_accuracy: 0.7146\n",
            "Epoch 21/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5967 - accuracy: 0.7167 - val_loss: 0.5948 - val_accuracy: 0.7208\n",
            "Epoch 22/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5935 - accuracy: 0.7208 - val_loss: 0.5918 - val_accuracy: 0.7208\n",
            "Epoch 23/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5908 - accuracy: 0.7208 - val_loss: 0.5887 - val_accuracy: 0.7250\n",
            "Epoch 24/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5876 - accuracy: 0.7250 - val_loss: 0.5859 - val_accuracy: 0.7271\n",
            "Epoch 25/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5851 - accuracy: 0.7250 - val_loss: 0.5832 - val_accuracy: 0.7250\n",
            "Epoch 26/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5823 - accuracy: 0.7250 - val_loss: 0.5807 - val_accuracy: 0.7292\n",
            "Epoch 27/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5799 - accuracy: 0.7271 - val_loss: 0.5783 - val_accuracy: 0.7271\n",
            "Epoch 28/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5776 - accuracy: 0.7292 - val_loss: 0.5760 - val_accuracy: 0.7312\n",
            "Epoch 29/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5752 - accuracy: 0.7312 - val_loss: 0.5739 - val_accuracy: 0.7312\n",
            "Epoch 30/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5731 - accuracy: 0.7312 - val_loss: 0.5719 - val_accuracy: 0.7312\n",
            "Epoch 31/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5714 - accuracy: 0.7312 - val_loss: 0.5699 - val_accuracy: 0.7312\n",
            "Epoch 32/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5695 - accuracy: 0.7333 - val_loss: 0.5681 - val_accuracy: 0.7354\n",
            "Epoch 33/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5675 - accuracy: 0.7354 - val_loss: 0.5664 - val_accuracy: 0.7354\n",
            "Epoch 34/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5658 - accuracy: 0.7354 - val_loss: 0.5648 - val_accuracy: 0.7354\n",
            "Epoch 35/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5643 - accuracy: 0.7375 - val_loss: 0.5631 - val_accuracy: 0.7375\n",
            "Epoch 36/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5627 - accuracy: 0.7375 - val_loss: 0.5614 - val_accuracy: 0.7396\n",
            "Epoch 37/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5609 - accuracy: 0.7396 - val_loss: 0.5598 - val_accuracy: 0.7417\n",
            "Epoch 38/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5593 - accuracy: 0.7417 - val_loss: 0.5582 - val_accuracy: 0.7396\n",
            "Epoch 39/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5579 - accuracy: 0.7396 - val_loss: 0.5568 - val_accuracy: 0.7396\n",
            "Epoch 40/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5563 - accuracy: 0.7396 - val_loss: 0.5553 - val_accuracy: 0.7396\n",
            "Epoch 41/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5550 - accuracy: 0.7396 - val_loss: 0.5539 - val_accuracy: 0.7396\n",
            "Epoch 42/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5535 - accuracy: 0.7396 - val_loss: 0.5526 - val_accuracy: 0.7396\n",
            "Epoch 43/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5522 - accuracy: 0.7354 - val_loss: 0.5513 - val_accuracy: 0.7354\n",
            "Epoch 44/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5508 - accuracy: 0.7354 - val_loss: 0.5501 - val_accuracy: 0.7354\n",
            "Epoch 45/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5497 - accuracy: 0.7333 - val_loss: 0.5488 - val_accuracy: 0.7333\n",
            "Epoch 46/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5486 - accuracy: 0.7333 - val_loss: 0.5476 - val_accuracy: 0.7333\n",
            "Epoch 47/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5474 - accuracy: 0.7333 - val_loss: 0.5465 - val_accuracy: 0.7333\n",
            "Epoch 48/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5462 - accuracy: 0.7354 - val_loss: 0.5454 - val_accuracy: 0.7354\n",
            "Epoch 49/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5451 - accuracy: 0.7375 - val_loss: 0.5443 - val_accuracy: 0.7396\n",
            "Epoch 50/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5440 - accuracy: 0.7396 - val_loss: 0.5433 - val_accuracy: 0.7417\n",
            "Epoch 51/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5429 - accuracy: 0.7396 - val_loss: 0.5422 - val_accuracy: 0.7396\n",
            "Epoch 52/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5419 - accuracy: 0.7417 - val_loss: 0.5411 - val_accuracy: 0.7417\n",
            "Epoch 53/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5408 - accuracy: 0.7417 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
            "Epoch 54/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5398 - accuracy: 0.7396 - val_loss: 0.5392 - val_accuracy: 0.7417\n",
            "Epoch 55/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5389 - accuracy: 0.7396 - val_loss: 0.5382 - val_accuracy: 0.7396\n",
            "Epoch 56/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5379 - accuracy: 0.7396 - val_loss: 0.5372 - val_accuracy: 0.7396\n",
            "Epoch 57/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5370 - accuracy: 0.7375 - val_loss: 0.5363 - val_accuracy: 0.7375\n",
            "Epoch 58/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5360 - accuracy: 0.7375 - val_loss: 0.5354 - val_accuracy: 0.7375\n",
            "Epoch 59/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5352 - accuracy: 0.7375 - val_loss: 0.5345 - val_accuracy: 0.7375\n",
            "Epoch 60/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5342 - accuracy: 0.7354 - val_loss: 0.5336 - val_accuracy: 0.7354\n",
            "Epoch 61/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5334 - accuracy: 0.7354 - val_loss: 0.5327 - val_accuracy: 0.7375\n",
            "Epoch 62/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5325 - accuracy: 0.7375 - val_loss: 0.5320 - val_accuracy: 0.7375\n",
            "Epoch 63/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5318 - accuracy: 0.7375 - val_loss: 0.5312 - val_accuracy: 0.7375\n",
            "Epoch 64/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5311 - accuracy: 0.7375 - val_loss: 0.5305 - val_accuracy: 0.7375\n",
            "Epoch 65/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5303 - accuracy: 0.7375 - val_loss: 0.5298 - val_accuracy: 0.7333\n",
            "Epoch 66/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5296 - accuracy: 0.7333 - val_loss: 0.5291 - val_accuracy: 0.7333\n",
            "Epoch 67/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5289 - accuracy: 0.7333 - val_loss: 0.5284 - val_accuracy: 0.7333\n",
            "Epoch 68/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5282 - accuracy: 0.7333 - val_loss: 0.5277 - val_accuracy: 0.7396\n",
            "Epoch 69/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5275 - accuracy: 0.7396 - val_loss: 0.5270 - val_accuracy: 0.7417\n",
            "Epoch 70/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5269 - accuracy: 0.7417 - val_loss: 0.5264 - val_accuracy: 0.7417\n",
            "Epoch 71/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5262 - accuracy: 0.7417 - val_loss: 0.5257 - val_accuracy: 0.7417\n",
            "Epoch 72/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5256 - accuracy: 0.7417 - val_loss: 0.5251 - val_accuracy: 0.7396\n",
            "Epoch 73/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5249 - accuracy: 0.7396 - val_loss: 0.5244 - val_accuracy: 0.7396\n",
            "Epoch 74/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5243 - accuracy: 0.7396 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
            "Epoch 75/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5236 - accuracy: 0.7417 - val_loss: 0.5230 - val_accuracy: 0.7417\n",
            "Epoch 76/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5229 - accuracy: 0.7417 - val_loss: 0.5223 - val_accuracy: 0.7437\n",
            "Epoch 77/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5223 - accuracy: 0.7417 - val_loss: 0.5217 - val_accuracy: 0.7437\n",
            "Epoch 78/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5216 - accuracy: 0.7437 - val_loss: 0.5210 - val_accuracy: 0.7437\n",
            "Epoch 79/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5209 - accuracy: 0.7437 - val_loss: 0.5204 - val_accuracy: 0.7437\n",
            "Epoch 80/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5203 - accuracy: 0.7437 - val_loss: 0.5198 - val_accuracy: 0.7437\n",
            "Epoch 81/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5196 - accuracy: 0.7437 - val_loss: 0.5191 - val_accuracy: 0.7437\n",
            "Epoch 82/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5190 - accuracy: 0.7437 - val_loss: 0.5185 - val_accuracy: 0.7437\n",
            "Epoch 83/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5183 - accuracy: 0.7437 - val_loss: 0.5179 - val_accuracy: 0.7458\n",
            "Epoch 84/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5178 - accuracy: 0.7458 - val_loss: 0.5172 - val_accuracy: 0.7437\n",
            "Epoch 85/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5172 - accuracy: 0.7437 - val_loss: 0.5166 - val_accuracy: 0.7437\n",
            "Epoch 86/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5164 - accuracy: 0.7437 - val_loss: 0.5159 - val_accuracy: 0.7437\n",
            "Epoch 87/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5159 - accuracy: 0.7437 - val_loss: 0.5153 - val_accuracy: 0.7458\n",
            "Epoch 88/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5152 - accuracy: 0.7458 - val_loss: 0.5147 - val_accuracy: 0.7458\n",
            "Epoch 89/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5147 - accuracy: 0.7458 - val_loss: 0.5141 - val_accuracy: 0.7437\n",
            "Epoch 90/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5141 - accuracy: 0.7437 - val_loss: 0.5136 - val_accuracy: 0.7437\n",
            "Epoch 91/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5135 - accuracy: 0.7437 - val_loss: 0.5130 - val_accuracy: 0.7437\n",
            "Epoch 92/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5129 - accuracy: 0.7437 - val_loss: 0.5124 - val_accuracy: 0.7437\n",
            "Epoch 93/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5124 - accuracy: 0.7479 - val_loss: 0.5118 - val_accuracy: 0.7479\n",
            "Epoch 94/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5117 - accuracy: 0.7437 - val_loss: 0.5113 - val_accuracy: 0.7437\n",
            "Epoch 95/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5113 - accuracy: 0.7437 - val_loss: 0.5107 - val_accuracy: 0.7437\n",
            "Epoch 96/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5106 - accuracy: 0.7437 - val_loss: 0.5101 - val_accuracy: 0.7437\n",
            "Epoch 97/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5100 - accuracy: 0.7437 - val_loss: 0.5096 - val_accuracy: 0.7458\n",
            "Epoch 98/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5095 - accuracy: 0.7458 - val_loss: 0.5090 - val_accuracy: 0.7458\n",
            "Epoch 99/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5090 - accuracy: 0.7458 - val_loss: 0.5084 - val_accuracy: 0.7458\n",
            "Epoch 100/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5084 - accuracy: 0.7417 - val_loss: 0.5079 - val_accuracy: 0.7417\n",
            "Epoch 101/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5080 - accuracy: 0.7417 - val_loss: 0.5073 - val_accuracy: 0.7437\n",
            "Epoch 102/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5072 - accuracy: 0.7437 - val_loss: 0.5067 - val_accuracy: 0.7437\n",
            "Epoch 103/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5066 - accuracy: 0.7437 - val_loss: 0.5062 - val_accuracy: 0.7437\n",
            "Epoch 104/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5062 - accuracy: 0.7437 - val_loss: 0.5056 - val_accuracy: 0.7437\n",
            "Epoch 105/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5056 - accuracy: 0.7437 - val_loss: 0.5051 - val_accuracy: 0.7458\n",
            "Epoch 106/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5050 - accuracy: 0.7437 - val_loss: 0.5045 - val_accuracy: 0.7437\n",
            "Epoch 107/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5045 - accuracy: 0.7458 - val_loss: 0.5040 - val_accuracy: 0.7437\n",
            "Epoch 108/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5040 - accuracy: 0.7437 - val_loss: 0.5034 - val_accuracy: 0.7479\n",
            "Epoch 109/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5033 - accuracy: 0.7479 - val_loss: 0.5028 - val_accuracy: 0.7479\n",
            "Epoch 110/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.7479 - val_loss: 0.5022 - val_accuracy: 0.7479\n",
            "Epoch 111/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5021 - accuracy: 0.7479 - val_loss: 0.5016 - val_accuracy: 0.7479\n",
            "Epoch 112/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5015 - accuracy: 0.7500 - val_loss: 0.5011 - val_accuracy: 0.7500\n",
            "Epoch 113/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5010 - accuracy: 0.7500 - val_loss: 0.5005 - val_accuracy: 0.7521\n",
            "Epoch 114/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5005 - accuracy: 0.7500 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
            "Epoch 115/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.7500 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
            "Epoch 116/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4994 - accuracy: 0.7500 - val_loss: 0.4990 - val_accuracy: 0.7479\n",
            "Epoch 117/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4990 - accuracy: 0.7479 - val_loss: 0.4985 - val_accuracy: 0.7479\n",
            "Epoch 118/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4984 - accuracy: 0.7479 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
            "Epoch 119/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4982 - accuracy: 0.7479 - val_loss: 0.4976 - val_accuracy: 0.7479\n",
            "Epoch 120/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4976 - accuracy: 0.7479 - val_loss: 0.4972 - val_accuracy: 0.7479\n",
            "Epoch 121/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4971 - accuracy: 0.7479 - val_loss: 0.4968 - val_accuracy: 0.7479\n",
            "Epoch 122/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4967 - accuracy: 0.7500 - val_loss: 0.4963 - val_accuracy: 0.7521\n",
            "Epoch 123/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4963 - accuracy: 0.7521 - val_loss: 0.4959 - val_accuracy: 0.7542\n",
            "Epoch 124/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4959 - accuracy: 0.7542 - val_loss: 0.4955 - val_accuracy: 0.7521\n",
            "Epoch 125/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4956 - accuracy: 0.7542 - val_loss: 0.4951 - val_accuracy: 0.7542\n",
            "Epoch 126/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4951 - accuracy: 0.7542 - val_loss: 0.4947 - val_accuracy: 0.7542\n",
            "Epoch 127/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4947 - accuracy: 0.7542 - val_loss: 0.4943 - val_accuracy: 0.7542\n",
            "Epoch 128/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4943 - accuracy: 0.7542 - val_loss: 0.4939 - val_accuracy: 0.7542\n",
            "Epoch 129/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4939 - accuracy: 0.7542 - val_loss: 0.4935 - val_accuracy: 0.7542\n",
            "Epoch 130/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4935 - accuracy: 0.7563 - val_loss: 0.4931 - val_accuracy: 0.7563\n",
            "Epoch 131/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4931 - accuracy: 0.7563 - val_loss: 0.4927 - val_accuracy: 0.7563\n",
            "Epoch 132/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4926 - accuracy: 0.7563 - val_loss: 0.4923 - val_accuracy: 0.7563\n",
            "Epoch 133/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4923 - accuracy: 0.7563 - val_loss: 0.4919 - val_accuracy: 0.7563\n",
            "Epoch 134/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4919 - accuracy: 0.7563 - val_loss: 0.4915 - val_accuracy: 0.7563\n",
            "Epoch 135/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4915 - accuracy: 0.7521 - val_loss: 0.4912 - val_accuracy: 0.7521\n",
            "Epoch 136/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4912 - accuracy: 0.7563 - val_loss: 0.4908 - val_accuracy: 0.7583\n",
            "Epoch 137/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4907 - accuracy: 0.7583 - val_loss: 0.4904 - val_accuracy: 0.7563\n",
            "Epoch 138/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4904 - accuracy: 0.7563 - val_loss: 0.4900 - val_accuracy: 0.7563\n",
            "Epoch 139/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4899 - accuracy: 0.7563 - val_loss: 0.4896 - val_accuracy: 0.7583\n",
            "Epoch 140/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4896 - accuracy: 0.7583 - val_loss: 0.4892 - val_accuracy: 0.7563\n",
            "Epoch 141/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4892 - accuracy: 0.7563 - val_loss: 0.4888 - val_accuracy: 0.7563\n",
            "Epoch 142/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4889 - accuracy: 0.7563 - val_loss: 0.4885 - val_accuracy: 0.7563\n",
            "Epoch 143/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4885 - accuracy: 0.7563 - val_loss: 0.4881 - val_accuracy: 0.7563\n",
            "Epoch 144/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4881 - accuracy: 0.7563 - val_loss: 0.4877 - val_accuracy: 0.7563\n",
            "Epoch 145/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4877 - accuracy: 0.7563 - val_loss: 0.4874 - val_accuracy: 0.7583\n",
            "Epoch 146/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4874 - accuracy: 0.7583 - val_loss: 0.4870 - val_accuracy: 0.7583\n",
            "Epoch 147/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4870 - accuracy: 0.7583 - val_loss: 0.4867 - val_accuracy: 0.7583\n",
            "Epoch 148/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4867 - accuracy: 0.7583 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
            "Epoch 149/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4863 - accuracy: 0.7604 - val_loss: 0.4860 - val_accuracy: 0.7604\n",
            "Epoch 150/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4860 - accuracy: 0.7604 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
            "Epoch 151/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4858 - accuracy: 0.7604 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
            "Epoch 152/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4853 - accuracy: 0.7604 - val_loss: 0.4849 - val_accuracy: 0.7604\n",
            "Epoch 153/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4848 - accuracy: 0.7604 - val_loss: 0.4845 - val_accuracy: 0.7604\n",
            "Epoch 154/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4846 - accuracy: 0.7604 - val_loss: 0.4842 - val_accuracy: 0.7604\n",
            "Epoch 155/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4842 - accuracy: 0.7604 - val_loss: 0.4838 - val_accuracy: 0.7604\n",
            "Epoch 156/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4838 - accuracy: 0.7604 - val_loss: 0.4835 - val_accuracy: 0.7583\n",
            "Epoch 157/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4835 - accuracy: 0.7583 - val_loss: 0.4831 - val_accuracy: 0.7583\n",
            "Epoch 158/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4832 - accuracy: 0.7583 - val_loss: 0.4828 - val_accuracy: 0.7583\n",
            "Epoch 159/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4828 - accuracy: 0.7583 - val_loss: 0.4825 - val_accuracy: 0.7583\n",
            "Epoch 160/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4825 - accuracy: 0.7583 - val_loss: 0.4822 - val_accuracy: 0.7583\n",
            "Epoch 161/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4822 - accuracy: 0.7583 - val_loss: 0.4818 - val_accuracy: 0.7583\n",
            "Epoch 162/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4819 - accuracy: 0.7583 - val_loss: 0.4815 - val_accuracy: 0.7583\n",
            "Epoch 163/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4816 - accuracy: 0.7583 - val_loss: 0.4812 - val_accuracy: 0.7583\n",
            "Epoch 164/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4812 - accuracy: 0.7583 - val_loss: 0.4808 - val_accuracy: 0.7583\n",
            "Epoch 165/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4809 - accuracy: 0.7583 - val_loss: 0.4805 - val_accuracy: 0.7583\n",
            "Epoch 166/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4806 - accuracy: 0.7563 - val_loss: 0.4802 - val_accuracy: 0.7563\n",
            "Epoch 167/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4803 - accuracy: 0.7563 - val_loss: 0.4799 - val_accuracy: 0.7563\n",
            "Epoch 168/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4800 - accuracy: 0.7563 - val_loss: 0.4796 - val_accuracy: 0.7563\n",
            "Epoch 169/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4797 - accuracy: 0.7563 - val_loss: 0.4794 - val_accuracy: 0.7563\n",
            "Epoch 170/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4794 - accuracy: 0.7563 - val_loss: 0.4791 - val_accuracy: 0.7563\n",
            "Epoch 171/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4791 - accuracy: 0.7563 - val_loss: 0.4788 - val_accuracy: 0.7563\n",
            "Epoch 172/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4787 - accuracy: 0.7563 - val_loss: 0.4785 - val_accuracy: 0.7563\n",
            "Epoch 173/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4785 - accuracy: 0.7563 - val_loss: 0.4782 - val_accuracy: 0.7563\n",
            "Epoch 174/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4782 - accuracy: 0.7563 - val_loss: 0.4779 - val_accuracy: 0.7583\n",
            "Epoch 175/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4779 - accuracy: 0.7583 - val_loss: 0.4776 - val_accuracy: 0.7583\n",
            "Epoch 176/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4777 - accuracy: 0.7583 - val_loss: 0.4773 - val_accuracy: 0.7583\n",
            "Epoch 177/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4774 - accuracy: 0.7583 - val_loss: 0.4770 - val_accuracy: 0.7583\n",
            "Epoch 178/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4771 - accuracy: 0.7583 - val_loss: 0.4768 - val_accuracy: 0.7604\n",
            "Epoch 179/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4769 - accuracy: 0.7604 - val_loss: 0.4765 - val_accuracy: 0.7604\n",
            "Epoch 180/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4765 - accuracy: 0.7583 - val_loss: 0.4763 - val_accuracy: 0.7583\n",
            "Epoch 181/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4763 - accuracy: 0.7583 - val_loss: 0.4760 - val_accuracy: 0.7604\n",
            "Epoch 182/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4761 - accuracy: 0.7604 - val_loss: 0.4758 - val_accuracy: 0.7604\n",
            "Epoch 183/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4758 - accuracy: 0.7604 - val_loss: 0.4755 - val_accuracy: 0.7604\n",
            "Epoch 184/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4755 - accuracy: 0.7604 - val_loss: 0.4752 - val_accuracy: 0.7625\n",
            "Epoch 185/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4752 - accuracy: 0.7604 - val_loss: 0.4750 - val_accuracy: 0.7625\n",
            "Epoch 186/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4750 - accuracy: 0.7625 - val_loss: 0.4747 - val_accuracy: 0.7625\n",
            "Epoch 187/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4748 - accuracy: 0.7625 - val_loss: 0.4744 - val_accuracy: 0.7625\n",
            "Epoch 188/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4745 - accuracy: 0.7625 - val_loss: 0.4741 - val_accuracy: 0.7625\n",
            "Epoch 189/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4742 - accuracy: 0.7625 - val_loss: 0.4739 - val_accuracy: 0.7625\n",
            "Epoch 190/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4739 - accuracy: 0.7625 - val_loss: 0.4736 - val_accuracy: 0.7625\n",
            "Epoch 191/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4737 - accuracy: 0.7646 - val_loss: 0.4733 - val_accuracy: 0.7646\n",
            "Epoch 192/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4734 - accuracy: 0.7646 - val_loss: 0.4731 - val_accuracy: 0.7646\n",
            "Epoch 193/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4731 - accuracy: 0.7646 - val_loss: 0.4729 - val_accuracy: 0.7646\n",
            "Epoch 194/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4729 - accuracy: 0.7646 - val_loss: 0.4726 - val_accuracy: 0.7646\n",
            "Epoch 195/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4728 - accuracy: 0.7646 - val_loss: 0.4724 - val_accuracy: 0.7646\n",
            "Epoch 196/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4725 - accuracy: 0.7646 - val_loss: 0.4722 - val_accuracy: 0.7646\n",
            "Epoch 197/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4722 - accuracy: 0.7625 - val_loss: 0.4719 - val_accuracy: 0.7625\n",
            "Epoch 198/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4721 - accuracy: 0.7667 - val_loss: 0.4717 - val_accuracy: 0.7667\n",
            "Epoch 199/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4718 - accuracy: 0.7667 - val_loss: 0.4714 - val_accuracy: 0.7688\n",
            "Epoch 200/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4716 - accuracy: 0.7688 - val_loss: 0.4712 - val_accuracy: 0.7667\n",
            "Epoch 201/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4713 - accuracy: 0.7646 - val_loss: 0.4710 - val_accuracy: 0.7688\n",
            "Epoch 202/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4710 - accuracy: 0.7667 - val_loss: 0.4708 - val_accuracy: 0.7688\n",
            "Epoch 203/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4708 - accuracy: 0.7688 - val_loss: 0.4705 - val_accuracy: 0.7729\n",
            "Epoch 204/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4706 - accuracy: 0.7729 - val_loss: 0.4703 - val_accuracy: 0.7729\n",
            "Epoch 205/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4704 - accuracy: 0.7729 - val_loss: 0.4700 - val_accuracy: 0.7729\n",
            "Epoch 206/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4701 - accuracy: 0.7729 - val_loss: 0.4698 - val_accuracy: 0.7729\n",
            "Epoch 207/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4700 - accuracy: 0.7729 - val_loss: 0.4696 - val_accuracy: 0.7729\n",
            "Epoch 208/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4697 - accuracy: 0.7729 - val_loss: 0.4694 - val_accuracy: 0.7729\n",
            "Epoch 209/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4696 - accuracy: 0.7771 - val_loss: 0.4692 - val_accuracy: 0.7771\n",
            "Epoch 210/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4693 - accuracy: 0.7771 - val_loss: 0.4690 - val_accuracy: 0.7771\n",
            "Epoch 211/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4691 - accuracy: 0.7771 - val_loss: 0.4688 - val_accuracy: 0.7792\n",
            "Epoch 212/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4689 - accuracy: 0.7792 - val_loss: 0.4686 - val_accuracy: 0.7792\n",
            "Epoch 213/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4687 - accuracy: 0.7792 - val_loss: 0.4684 - val_accuracy: 0.7792\n",
            "Epoch 214/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4684 - accuracy: 0.7792 - val_loss: 0.4681 - val_accuracy: 0.7792\n",
            "Epoch 215/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4682 - accuracy: 0.7792 - val_loss: 0.4679 - val_accuracy: 0.7792\n",
            "Epoch 216/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4679 - accuracy: 0.7792 - val_loss: 0.4677 - val_accuracy: 0.7792\n",
            "Epoch 217/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4678 - accuracy: 0.7792 - val_loss: 0.4674 - val_accuracy: 0.7792\n",
            "Epoch 218/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4675 - accuracy: 0.7792 - val_loss: 0.4672 - val_accuracy: 0.7792\n",
            "Epoch 219/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4673 - accuracy: 0.7792 - val_loss: 0.4670 - val_accuracy: 0.7792\n",
            "Epoch 220/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4670 - accuracy: 0.7792 - val_loss: 0.4668 - val_accuracy: 0.7771\n",
            "Epoch 221/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4668 - accuracy: 0.7792 - val_loss: 0.4666 - val_accuracy: 0.7812\n",
            "Epoch 222/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4666 - accuracy: 0.7812 - val_loss: 0.4663 - val_accuracy: 0.7833\n",
            "Epoch 223/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4665 - accuracy: 0.7812 - val_loss: 0.4661 - val_accuracy: 0.7854\n",
            "Epoch 224/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4661 - accuracy: 0.7854 - val_loss: 0.4658 - val_accuracy: 0.7812\n",
            "Epoch 225/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4659 - accuracy: 0.7812 - val_loss: 0.4656 - val_accuracy: 0.7812\n",
            "Epoch 226/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7854 - val_loss: 0.4654 - val_accuracy: 0.7854\n",
            "Epoch 227/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4655 - accuracy: 0.7854 - val_loss: 0.4652 - val_accuracy: 0.7854\n",
            "Epoch 228/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4652 - accuracy: 0.7833 - val_loss: 0.4650 - val_accuracy: 0.7833\n",
            "Epoch 229/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4650 - accuracy: 0.7833 - val_loss: 0.4647 - val_accuracy: 0.7833\n",
            "Epoch 230/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4648 - accuracy: 0.7833 - val_loss: 0.4645 - val_accuracy: 0.7833\n",
            "Epoch 231/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4646 - accuracy: 0.7833 - val_loss: 0.4643 - val_accuracy: 0.7833\n",
            "Epoch 232/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4644 - accuracy: 0.7833 - val_loss: 0.4642 - val_accuracy: 0.7833\n",
            "Epoch 233/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4643 - accuracy: 0.7833 - val_loss: 0.4640 - val_accuracy: 0.7833\n",
            "Epoch 234/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4641 - accuracy: 0.7833 - val_loss: 0.4637 - val_accuracy: 0.7833\n",
            "Epoch 235/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4638 - accuracy: 0.7833 - val_loss: 0.4635 - val_accuracy: 0.7833\n",
            "Epoch 236/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4636 - accuracy: 0.7833 - val_loss: 0.4633 - val_accuracy: 0.7833\n",
            "Epoch 237/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4635 - accuracy: 0.7833 - val_loss: 0.4632 - val_accuracy: 0.7833\n",
            "Epoch 238/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4633 - accuracy: 0.7833 - val_loss: 0.4630 - val_accuracy: 0.7833\n",
            "Epoch 239/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4631 - accuracy: 0.7833 - val_loss: 0.4628 - val_accuracy: 0.7833\n",
            "Epoch 240/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4628 - accuracy: 0.7854 - val_loss: 0.4626 - val_accuracy: 0.7854\n",
            "Epoch 241/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4626 - accuracy: 0.7854 - val_loss: 0.4624 - val_accuracy: 0.7896\n",
            "Epoch 242/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4625 - accuracy: 0.7875 - val_loss: 0.4622 - val_accuracy: 0.7833\n",
            "Epoch 243/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4624 - accuracy: 0.7875 - val_loss: 0.4620 - val_accuracy: 0.7896\n",
            "Epoch 244/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4621 - accuracy: 0.7875 - val_loss: 0.4618 - val_accuracy: 0.7875\n",
            "Epoch 245/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4619 - accuracy: 0.7854 - val_loss: 0.4617 - val_accuracy: 0.7875\n",
            "Epoch 246/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4617 - accuracy: 0.7896 - val_loss: 0.4615 - val_accuracy: 0.7917\n",
            "Epoch 247/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4617 - accuracy: 0.7917 - val_loss: 0.4613 - val_accuracy: 0.7917\n",
            "Epoch 248/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4613 - accuracy: 0.7896 - val_loss: 0.4611 - val_accuracy: 0.7896\n",
            "Epoch 249/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4613 - accuracy: 0.7896 - val_loss: 0.4610 - val_accuracy: 0.7896\n",
            "Epoch 250/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4610 - accuracy: 0.7896 - val_loss: 0.4607 - val_accuracy: 0.7896\n",
            "Epoch 251/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4608 - accuracy: 0.7896 - val_loss: 0.4606 - val_accuracy: 0.7896\n",
            "Epoch 252/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4607 - accuracy: 0.7917 - val_loss: 0.4604 - val_accuracy: 0.7917\n",
            "Epoch 253/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4604 - accuracy: 0.7917 - val_loss: 0.4602 - val_accuracy: 0.7917\n",
            "Epoch 254/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4603 - accuracy: 0.7917 - val_loss: 0.4600 - val_accuracy: 0.7917\n",
            "Epoch 255/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4602 - accuracy: 0.7917 - val_loss: 0.4598 - val_accuracy: 0.7917\n",
            "Epoch 256/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4600 - accuracy: 0.7917 - val_loss: 0.4596 - val_accuracy: 0.7917\n",
            "Epoch 257/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4599 - accuracy: 0.7875 - val_loss: 0.4595 - val_accuracy: 0.7875\n",
            "Epoch 258/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4595 - accuracy: 0.7875 - val_loss: 0.4593 - val_accuracy: 0.7917\n",
            "Epoch 259/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4593 - accuracy: 0.7917 - val_loss: 0.4591 - val_accuracy: 0.7896\n",
            "Epoch 260/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4593 - accuracy: 0.7896 - val_loss: 0.4589 - val_accuracy: 0.7896\n",
            "Epoch 261/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4591 - accuracy: 0.7896 - val_loss: 0.4587 - val_accuracy: 0.7917\n",
            "Epoch 262/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4588 - accuracy: 0.7917 - val_loss: 0.4586 - val_accuracy: 0.7917\n",
            "Epoch 263/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4587 - accuracy: 0.7896 - val_loss: 0.4584 - val_accuracy: 0.7896\n",
            "Epoch 264/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4585 - accuracy: 0.7896 - val_loss: 0.4582 - val_accuracy: 0.7896\n",
            "Epoch 265/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4583 - accuracy: 0.7896 - val_loss: 0.4581 - val_accuracy: 0.7896\n",
            "Epoch 266/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4581 - accuracy: 0.7896 - val_loss: 0.4578 - val_accuracy: 0.7896\n",
            "Epoch 267/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4580 - accuracy: 0.7896 - val_loss: 0.4577 - val_accuracy: 0.7896\n",
            "Epoch 268/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4577 - accuracy: 0.7917 - val_loss: 0.4575 - val_accuracy: 0.7896\n",
            "Epoch 269/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4576 - accuracy: 0.7896 - val_loss: 0.4573 - val_accuracy: 0.7896\n",
            "Epoch 270/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4574 - accuracy: 0.7896 - val_loss: 0.4571 - val_accuracy: 0.7896\n",
            "Epoch 271/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4572 - accuracy: 0.7896 - val_loss: 0.4569 - val_accuracy: 0.7896\n",
            "Epoch 272/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4571 - accuracy: 0.7875 - val_loss: 0.4567 - val_accuracy: 0.7875\n",
            "Epoch 273/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4569 - accuracy: 0.7875 - val_loss: 0.4566 - val_accuracy: 0.7875\n",
            "Epoch 274/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4566 - accuracy: 0.7875 - val_loss: 0.4564 - val_accuracy: 0.7875\n",
            "Epoch 275/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4565 - accuracy: 0.7875 - val_loss: 0.4562 - val_accuracy: 0.7896\n",
            "Epoch 276/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4563 - accuracy: 0.7896 - val_loss: 0.4560 - val_accuracy: 0.7875\n",
            "Epoch 277/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.7875 - val_loss: 0.4557 - val_accuracy: 0.7875\n",
            "Epoch 278/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4558 - accuracy: 0.7875 - val_loss: 0.4555 - val_accuracy: 0.7875\n",
            "Epoch 279/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4557 - accuracy: 0.7875 - val_loss: 0.4553 - val_accuracy: 0.7875\n",
            "Epoch 280/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4555 - accuracy: 0.7896 - val_loss: 0.4552 - val_accuracy: 0.7896\n",
            "Epoch 281/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4553 - accuracy: 0.7896 - val_loss: 0.4550 - val_accuracy: 0.7917\n",
            "Epoch 282/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4551 - accuracy: 0.7875 - val_loss: 0.4548 - val_accuracy: 0.7854\n",
            "Epoch 283/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4549 - accuracy: 0.7833 - val_loss: 0.4546 - val_accuracy: 0.7833\n",
            "Epoch 284/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4550 - accuracy: 0.7896 - val_loss: 0.4544 - val_accuracy: 0.7896\n",
            "Epoch 285/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4545 - accuracy: 0.7896 - val_loss: 0.4543 - val_accuracy: 0.7896\n",
            "Epoch 286/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4544 - accuracy: 0.7896 - val_loss: 0.4541 - val_accuracy: 0.7896\n",
            "Epoch 287/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4542 - accuracy: 0.7896 - val_loss: 0.4539 - val_accuracy: 0.7854\n",
            "Epoch 288/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4540 - accuracy: 0.7854 - val_loss: 0.4537 - val_accuracy: 0.7875\n",
            "Epoch 289/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4538 - accuracy: 0.7875 - val_loss: 0.4536 - val_accuracy: 0.7875\n",
            "Epoch 290/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4537 - accuracy: 0.7875 - val_loss: 0.4534 - val_accuracy: 0.7875\n",
            "Epoch 291/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4534 - accuracy: 0.7875 - val_loss: 0.4532 - val_accuracy: 0.7875\n",
            "Epoch 292/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4534 - accuracy: 0.7875 - val_loss: 0.4530 - val_accuracy: 0.7875\n",
            "Epoch 293/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4531 - accuracy: 0.7875 - val_loss: 0.4528 - val_accuracy: 0.7875\n",
            "Epoch 294/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4530 - accuracy: 0.7875 - val_loss: 0.4526 - val_accuracy: 0.7875\n",
            "Epoch 295/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4528 - accuracy: 0.7875 - val_loss: 0.4525 - val_accuracy: 0.7875\n",
            "Epoch 296/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4526 - accuracy: 0.7875 - val_loss: 0.4523 - val_accuracy: 0.7917\n",
            "Epoch 297/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4524 - accuracy: 0.7937 - val_loss: 0.4521 - val_accuracy: 0.7937\n",
            "Epoch 298/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4522 - accuracy: 0.7937 - val_loss: 0.4519 - val_accuracy: 0.7937\n",
            "Epoch 299/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4521 - accuracy: 0.7937 - val_loss: 0.4518 - val_accuracy: 0.7958\n",
            "Epoch 300/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4519 - accuracy: 0.7958 - val_loss: 0.4516 - val_accuracy: 0.7958\n",
            "Epoch 301/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4517 - accuracy: 0.7958 - val_loss: 0.4514 - val_accuracy: 0.7937\n",
            "Epoch 302/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4516 - accuracy: 0.7937 - val_loss: 0.4512 - val_accuracy: 0.7958\n",
            "Epoch 303/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4513 - accuracy: 0.7937 - val_loss: 0.4510 - val_accuracy: 0.7937\n",
            "Epoch 304/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4513 - accuracy: 0.7958 - val_loss: 0.4509 - val_accuracy: 0.7958\n",
            "Epoch 305/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4509 - accuracy: 0.7958 - val_loss: 0.4507 - val_accuracy: 0.7958\n",
            "Epoch 306/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4508 - accuracy: 0.7958 - val_loss: 0.4505 - val_accuracy: 0.7979\n",
            "Epoch 307/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4506 - accuracy: 0.8000 - val_loss: 0.4503 - val_accuracy: 0.8000\n",
            "Epoch 308/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4504 - accuracy: 0.8000 - val_loss: 0.4501 - val_accuracy: 0.8000\n",
            "Epoch 309/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4502 - accuracy: 0.7979 - val_loss: 0.4499 - val_accuracy: 0.7979\n",
            "Epoch 310/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4501 - accuracy: 0.7979 - val_loss: 0.4497 - val_accuracy: 0.7979\n",
            "Epoch 311/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4498 - accuracy: 0.7979 - val_loss: 0.4496 - val_accuracy: 0.7979\n",
            "Epoch 312/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4496 - accuracy: 0.7979 - val_loss: 0.4494 - val_accuracy: 0.8000\n",
            "Epoch 313/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4496 - accuracy: 0.8000 - val_loss: 0.4492 - val_accuracy: 0.8021\n",
            "Epoch 314/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4492 - accuracy: 0.8021 - val_loss: 0.4490 - val_accuracy: 0.8021\n",
            "Epoch 315/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4491 - accuracy: 0.8021 - val_loss: 0.4488 - val_accuracy: 0.8021\n",
            "Epoch 316/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4489 - accuracy: 0.8021 - val_loss: 0.4486 - val_accuracy: 0.8021\n",
            "Epoch 317/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4488 - accuracy: 0.8021 - val_loss: 0.4485 - val_accuracy: 0.8021\n",
            "Epoch 318/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4486 - accuracy: 0.8021 - val_loss: 0.4483 - val_accuracy: 0.8021\n",
            "Epoch 319/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4485 - accuracy: 0.8042 - val_loss: 0.4481 - val_accuracy: 0.8042\n",
            "Epoch 320/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4483 - accuracy: 0.8021 - val_loss: 0.4480 - val_accuracy: 0.8021\n",
            "Epoch 321/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4481 - accuracy: 0.8021 - val_loss: 0.4478 - val_accuracy: 0.8021\n",
            "Epoch 322/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4480 - accuracy: 0.8021 - val_loss: 0.4476 - val_accuracy: 0.8021\n",
            "Epoch 323/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4476 - accuracy: 0.8021 - val_loss: 0.4474 - val_accuracy: 0.8042\n",
            "Epoch 324/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4477 - accuracy: 0.8042 - val_loss: 0.4473 - val_accuracy: 0.8042\n",
            "Epoch 325/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4476 - accuracy: 0.8042 - val_loss: 0.4471 - val_accuracy: 0.8042\n",
            "Epoch 326/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4473 - accuracy: 0.8021 - val_loss: 0.4469 - val_accuracy: 0.8021\n",
            "Epoch 327/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4471 - accuracy: 0.8042 - val_loss: 0.4468 - val_accuracy: 0.8000\n",
            "Epoch 328/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4469 - accuracy: 0.8021 - val_loss: 0.4466 - val_accuracy: 0.8021\n",
            "Epoch 329/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4467 - accuracy: 0.8021 - val_loss: 0.4465 - val_accuracy: 0.8021\n",
            "Epoch 330/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4466 - accuracy: 0.8021 - val_loss: 0.4463 - val_accuracy: 0.8062\n",
            "Epoch 331/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4465 - accuracy: 0.8062 - val_loss: 0.4461 - val_accuracy: 0.8021\n",
            "Epoch 332/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4464 - accuracy: 0.8042 - val_loss: 0.4460 - val_accuracy: 0.8062\n",
            "Epoch 333/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4460 - accuracy: 0.8062 - val_loss: 0.4458 - val_accuracy: 0.8062\n",
            "Epoch 334/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4459 - accuracy: 0.8042 - val_loss: 0.4456 - val_accuracy: 0.8021\n",
            "Epoch 335/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4457 - accuracy: 0.8021 - val_loss: 0.4455 - val_accuracy: 0.8021\n",
            "Epoch 336/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4456 - accuracy: 0.8021 - val_loss: 0.4453 - val_accuracy: 0.8021\n",
            "Epoch 337/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4454 - accuracy: 0.8062 - val_loss: 0.4451 - val_accuracy: 0.8062\n",
            "Epoch 338/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4454 - accuracy: 0.8062 - val_loss: 0.4450 - val_accuracy: 0.8062\n",
            "Epoch 339/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4452 - accuracy: 0.8062 - val_loss: 0.4448 - val_accuracy: 0.8062\n",
            "Epoch 340/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4449 - accuracy: 0.8062 - val_loss: 0.4446 - val_accuracy: 0.8062\n",
            "Epoch 341/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4447 - accuracy: 0.8062 - val_loss: 0.4444 - val_accuracy: 0.8104\n",
            "Epoch 342/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4445 - accuracy: 0.8104 - val_loss: 0.4443 - val_accuracy: 0.8104\n",
            "Epoch 343/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4444 - accuracy: 0.8104 - val_loss: 0.4441 - val_accuracy: 0.8104\n",
            "Epoch 344/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4442 - accuracy: 0.8104 - val_loss: 0.4440 - val_accuracy: 0.8104\n",
            "Epoch 345/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4441 - accuracy: 0.8104 - val_loss: 0.4438 - val_accuracy: 0.8104\n",
            "Epoch 346/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4439 - accuracy: 0.8062 - val_loss: 0.4437 - val_accuracy: 0.8083\n",
            "Epoch 347/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4439 - accuracy: 0.8083 - val_loss: 0.4435 - val_accuracy: 0.8104\n",
            "Epoch 348/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4438 - accuracy: 0.8083 - val_loss: 0.4434 - val_accuracy: 0.8083\n",
            "Epoch 349/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4435 - accuracy: 0.8083 - val_loss: 0.4432 - val_accuracy: 0.8083\n",
            "Epoch 350/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4434 - accuracy: 0.8062 - val_loss: 0.4431 - val_accuracy: 0.8104\n",
            "Epoch 351/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4432 - accuracy: 0.8104 - val_loss: 0.4429 - val_accuracy: 0.8104\n",
            "Epoch 352/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4431 - accuracy: 0.8083 - val_loss: 0.4428 - val_accuracy: 0.8083\n",
            "Epoch 353/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4429 - accuracy: 0.8104 - val_loss: 0.4427 - val_accuracy: 0.8104\n",
            "Epoch 354/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4430 - accuracy: 0.8104 - val_loss: 0.4426 - val_accuracy: 0.8083\n",
            "Epoch 355/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4427 - accuracy: 0.8083 - val_loss: 0.4424 - val_accuracy: 0.8083\n",
            "Epoch 356/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4425 - accuracy: 0.8083 - val_loss: 0.4422 - val_accuracy: 0.8104\n",
            "Epoch 357/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4424 - accuracy: 0.8104 - val_loss: 0.4421 - val_accuracy: 0.8104\n",
            "Epoch 358/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4423 - accuracy: 0.8146 - val_loss: 0.4419 - val_accuracy: 0.8146\n",
            "Epoch 359/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4420 - accuracy: 0.8146 - val_loss: 0.4418 - val_accuracy: 0.8146\n",
            "Epoch 360/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4420 - accuracy: 0.8167 - val_loss: 0.4416 - val_accuracy: 0.8167\n",
            "Epoch 361/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4418 - accuracy: 0.8167 - val_loss: 0.4415 - val_accuracy: 0.8146\n",
            "Epoch 362/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4416 - accuracy: 0.8146 - val_loss: 0.4414 - val_accuracy: 0.8146\n",
            "Epoch 363/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4416 - accuracy: 0.8146 - val_loss: 0.4413 - val_accuracy: 0.8167\n",
            "Epoch 364/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4415 - accuracy: 0.8146 - val_loss: 0.4411 - val_accuracy: 0.8146\n",
            "Epoch 365/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4412 - accuracy: 0.8167 - val_loss: 0.4410 - val_accuracy: 0.8167\n",
            "Epoch 366/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4411 - accuracy: 0.8146 - val_loss: 0.4408 - val_accuracy: 0.8146\n",
            "Epoch 367/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4409 - accuracy: 0.8146 - val_loss: 0.4407 - val_accuracy: 0.8146\n",
            "Epoch 368/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4409 - accuracy: 0.8146 - val_loss: 0.4406 - val_accuracy: 0.8125\n",
            "Epoch 369/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4407 - accuracy: 0.8125 - val_loss: 0.4404 - val_accuracy: 0.8125\n",
            "Epoch 370/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4406 - accuracy: 0.8125 - val_loss: 0.4403 - val_accuracy: 0.8146\n",
            "Epoch 371/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4405 - accuracy: 0.8146 - val_loss: 0.4401 - val_accuracy: 0.8146\n",
            "Epoch 372/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4403 - accuracy: 0.8146 - val_loss: 0.4400 - val_accuracy: 0.8146\n",
            "Epoch 373/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4402 - accuracy: 0.8146 - val_loss: 0.4399 - val_accuracy: 0.8146\n",
            "Epoch 374/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4402 - accuracy: 0.8146 - val_loss: 0.4398 - val_accuracy: 0.8125\n",
            "Epoch 375/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4399 - accuracy: 0.8125 - val_loss: 0.4397 - val_accuracy: 0.8125\n",
            "Epoch 376/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4398 - accuracy: 0.8125 - val_loss: 0.4395 - val_accuracy: 0.8104\n",
            "Epoch 377/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4398 - accuracy: 0.8104 - val_loss: 0.4394 - val_accuracy: 0.8167\n",
            "Epoch 378/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4396 - accuracy: 0.8167 - val_loss: 0.4393 - val_accuracy: 0.8146\n",
            "Epoch 379/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4394 - accuracy: 0.8146 - val_loss: 0.4391 - val_accuracy: 0.8125\n",
            "Epoch 380/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4393 - accuracy: 0.8104 - val_loss: 0.4390 - val_accuracy: 0.8104\n",
            "Epoch 381/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4391 - accuracy: 0.8125 - val_loss: 0.4389 - val_accuracy: 0.8125\n",
            "Epoch 382/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4390 - accuracy: 0.8125 - val_loss: 0.4387 - val_accuracy: 0.8125\n",
            "Epoch 383/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4389 - accuracy: 0.8104 - val_loss: 0.4386 - val_accuracy: 0.8104\n",
            "Epoch 384/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4388 - accuracy: 0.8104 - val_loss: 0.4385 - val_accuracy: 0.8104\n",
            "Epoch 385/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4387 - accuracy: 0.8104 - val_loss: 0.4384 - val_accuracy: 0.8125\n",
            "Epoch 386/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4385 - accuracy: 0.8125 - val_loss: 0.4383 - val_accuracy: 0.8125\n",
            "Epoch 387/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4384 - accuracy: 0.8125 - val_loss: 0.4381 - val_accuracy: 0.8104\n",
            "Epoch 388/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4383 - accuracy: 0.8104 - val_loss: 0.4380 - val_accuracy: 0.8083\n",
            "Epoch 389/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4382 - accuracy: 0.8083 - val_loss: 0.4379 - val_accuracy: 0.8062\n",
            "Epoch 390/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4379 - accuracy: 0.8083 - val_loss: 0.4377 - val_accuracy: 0.8125\n",
            "Epoch 391/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4378 - accuracy: 0.8125 - val_loss: 0.4376 - val_accuracy: 0.8125\n",
            "Epoch 392/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4378 - accuracy: 0.8125 - val_loss: 0.4374 - val_accuracy: 0.8125\n",
            "Epoch 393/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4376 - accuracy: 0.8104 - val_loss: 0.4373 - val_accuracy: 0.8125\n",
            "Epoch 394/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4375 - accuracy: 0.8125 - val_loss: 0.4372 - val_accuracy: 0.8125\n",
            "Epoch 395/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4374 - accuracy: 0.8104 - val_loss: 0.4371 - val_accuracy: 0.8062\n",
            "Epoch 396/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4373 - accuracy: 0.8083 - val_loss: 0.4369 - val_accuracy: 0.8125\n",
            "Epoch 397/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4370 - accuracy: 0.8125 - val_loss: 0.4368 - val_accuracy: 0.8125\n",
            "Epoch 398/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4370 - accuracy: 0.8104 - val_loss: 0.4367 - val_accuracy: 0.8083\n",
            "Epoch 399/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4369 - accuracy: 0.8125 - val_loss: 0.4366 - val_accuracy: 0.8125\n",
            "Epoch 400/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4367 - accuracy: 0.8104 - val_loss: 0.4365 - val_accuracy: 0.8062\n",
            "Epoch 401/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4366 - accuracy: 0.8062 - val_loss: 0.4363 - val_accuracy: 0.8062\n",
            "Epoch 402/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4365 - accuracy: 0.8083 - val_loss: 0.4362 - val_accuracy: 0.8062\n",
            "Epoch 403/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4363 - accuracy: 0.8062 - val_loss: 0.4360 - val_accuracy: 0.8062\n",
            "Epoch 404/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4361 - accuracy: 0.8062 - val_loss: 0.4359 - val_accuracy: 0.8062\n",
            "Epoch 405/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4360 - accuracy: 0.8083 - val_loss: 0.4358 - val_accuracy: 0.8083\n",
            "Epoch 406/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4359 - accuracy: 0.8062 - val_loss: 0.4356 - val_accuracy: 0.8062\n",
            "Epoch 407/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4358 - accuracy: 0.8062 - val_loss: 0.4355 - val_accuracy: 0.8062\n",
            "Epoch 408/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4358 - accuracy: 0.8062 - val_loss: 0.4354 - val_accuracy: 0.8062\n",
            "Epoch 409/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4355 - accuracy: 0.8062 - val_loss: 0.4352 - val_accuracy: 0.8083\n",
            "Epoch 410/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4353 - accuracy: 0.8083 - val_loss: 0.4351 - val_accuracy: 0.8083\n",
            "Epoch 411/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4353 - accuracy: 0.8083 - val_loss: 0.4349 - val_accuracy: 0.8083\n",
            "Epoch 412/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4350 - accuracy: 0.8083 - val_loss: 0.4348 - val_accuracy: 0.8083\n",
            "Epoch 413/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4350 - accuracy: 0.8062 - val_loss: 0.4347 - val_accuracy: 0.8083\n",
            "Epoch 414/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4350 - accuracy: 0.8083 - val_loss: 0.4346 - val_accuracy: 0.8104\n",
            "Epoch 415/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4347 - accuracy: 0.8083 - val_loss: 0.4345 - val_accuracy: 0.8083\n",
            "Epoch 416/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4346 - accuracy: 0.8104 - val_loss: 0.4344 - val_accuracy: 0.8104\n",
            "Epoch 417/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4345 - accuracy: 0.8104 - val_loss: 0.4342 - val_accuracy: 0.8104\n",
            "Epoch 418/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4344 - accuracy: 0.8104 - val_loss: 0.4341 - val_accuracy: 0.8104\n",
            "Epoch 419/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4343 - accuracy: 0.8083 - val_loss: 0.4340 - val_accuracy: 0.8104\n",
            "Epoch 420/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4341 - accuracy: 0.8104 - val_loss: 0.4338 - val_accuracy: 0.8125\n",
            "Epoch 421/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4340 - accuracy: 0.8104 - val_loss: 0.4337 - val_accuracy: 0.8083\n",
            "Epoch 422/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4339 - accuracy: 0.8083 - val_loss: 0.4336 - val_accuracy: 0.8083\n",
            "Epoch 423/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4337 - accuracy: 0.8083 - val_loss: 0.4334 - val_accuracy: 0.8104\n",
            "Epoch 424/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4335 - accuracy: 0.8104 - val_loss: 0.4333 - val_accuracy: 0.8104\n",
            "Epoch 425/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4334 - accuracy: 0.8104 - val_loss: 0.4331 - val_accuracy: 0.8104\n",
            "Epoch 426/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4332 - accuracy: 0.8104 - val_loss: 0.4329 - val_accuracy: 0.8104\n",
            "Epoch 427/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4329 - accuracy: 0.8125 - val_loss: 0.4327 - val_accuracy: 0.8125\n",
            "Epoch 428/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4327 - accuracy: 0.8104 - val_loss: 0.4325 - val_accuracy: 0.8104\n",
            "Epoch 429/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4326 - accuracy: 0.8083 - val_loss: 0.4322 - val_accuracy: 0.8083\n",
            "Epoch 430/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4324 - accuracy: 0.8083 - val_loss: 0.4320 - val_accuracy: 0.8125\n",
            "Epoch 431/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4322 - accuracy: 0.8104 - val_loss: 0.4319 - val_accuracy: 0.8083\n",
            "Epoch 432/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4320 - accuracy: 0.8083 - val_loss: 0.4318 - val_accuracy: 0.8083\n",
            "Epoch 433/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4319 - accuracy: 0.8083 - val_loss: 0.4317 - val_accuracy: 0.8083\n",
            "Epoch 434/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4319 - accuracy: 0.8104 - val_loss: 0.4316 - val_accuracy: 0.8104\n",
            "Epoch 435/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4317 - accuracy: 0.8104 - val_loss: 0.4315 - val_accuracy: 0.8125\n",
            "Epoch 436/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4316 - accuracy: 0.8146 - val_loss: 0.4314 - val_accuracy: 0.8146\n",
            "Epoch 437/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4315 - accuracy: 0.8104 - val_loss: 0.4313 - val_accuracy: 0.8104\n",
            "Epoch 438/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4314 - accuracy: 0.8104 - val_loss: 0.4312 - val_accuracy: 0.8104\n",
            "Epoch 439/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4313 - accuracy: 0.8125 - val_loss: 0.4311 - val_accuracy: 0.8125\n",
            "Epoch 440/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4313 - accuracy: 0.8125 - val_loss: 0.4310 - val_accuracy: 0.8125\n",
            "Epoch 441/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4312 - accuracy: 0.8125 - val_loss: 0.4309 - val_accuracy: 0.8146\n",
            "Epoch 442/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4311 - accuracy: 0.8146 - val_loss: 0.4308 - val_accuracy: 0.8146\n",
            "Epoch 443/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4309 - accuracy: 0.8125 - val_loss: 0.4307 - val_accuracy: 0.8146\n",
            "Epoch 444/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4309 - accuracy: 0.8146 - val_loss: 0.4307 - val_accuracy: 0.8146\n",
            "Epoch 445/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4310 - accuracy: 0.8104 - val_loss: 0.4306 - val_accuracy: 0.8104\n",
            "Epoch 446/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4308 - accuracy: 0.8104 - val_loss: 0.4305 - val_accuracy: 0.8104\n",
            "Epoch 447/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4310 - accuracy: 0.8083 - val_loss: 0.4304 - val_accuracy: 0.8104\n",
            "Epoch 448/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4305 - accuracy: 0.8104 - val_loss: 0.4303 - val_accuracy: 0.8125\n",
            "Epoch 449/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4304 - accuracy: 0.8104 - val_loss: 0.4302 - val_accuracy: 0.8104\n",
            "Epoch 450/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4304 - accuracy: 0.8104 - val_loss: 0.4301 - val_accuracy: 0.8125\n",
            "Epoch 451/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4303 - accuracy: 0.8125 - val_loss: 0.4300 - val_accuracy: 0.8104\n",
            "Epoch 452/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4303 - accuracy: 0.8083 - val_loss: 0.4299 - val_accuracy: 0.8104\n",
            "Epoch 453/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4301 - accuracy: 0.8083 - val_loss: 0.4298 - val_accuracy: 0.8083\n",
            "Epoch 454/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4301 - accuracy: 0.8083 - val_loss: 0.4298 - val_accuracy: 0.8104\n",
            "Epoch 455/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4299 - accuracy: 0.8083 - val_loss: 0.4297 - val_accuracy: 0.8062\n",
            "Epoch 456/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4298 - accuracy: 0.8083 - val_loss: 0.4296 - val_accuracy: 0.8104\n",
            "Epoch 457/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4297 - accuracy: 0.8104 - val_loss: 0.4295 - val_accuracy: 0.8104\n",
            "Epoch 458/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4297 - accuracy: 0.8083 - val_loss: 0.4294 - val_accuracy: 0.8104\n",
            "Epoch 459/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4297 - accuracy: 0.8083 - val_loss: 0.4293 - val_accuracy: 0.8083\n",
            "Epoch 460/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4295 - accuracy: 0.8062 - val_loss: 0.4293 - val_accuracy: 0.8062\n",
            "Epoch 461/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4295 - accuracy: 0.8083 - val_loss: 0.4292 - val_accuracy: 0.8083\n",
            "Epoch 462/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4294 - accuracy: 0.8083 - val_loss: 0.4291 - val_accuracy: 0.8104\n",
            "Epoch 463/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4294 - accuracy: 0.8083 - val_loss: 0.4291 - val_accuracy: 0.8104\n",
            "Epoch 464/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4292 - accuracy: 0.8104 - val_loss: 0.4290 - val_accuracy: 0.8104\n",
            "Epoch 465/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4292 - accuracy: 0.8083 - val_loss: 0.4290 - val_accuracy: 0.8083\n",
            "Epoch 466/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4290 - accuracy: 0.8062 - val_loss: 0.4289 - val_accuracy: 0.8083\n",
            "Epoch 467/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4291 - accuracy: 0.8042 - val_loss: 0.4288 - val_accuracy: 0.8062\n",
            "Epoch 468/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4289 - accuracy: 0.8042 - val_loss: 0.4287 - val_accuracy: 0.8062\n",
            "Epoch 469/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4290 - accuracy: 0.8062 - val_loss: 0.4286 - val_accuracy: 0.8062\n",
            "Epoch 470/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4288 - accuracy: 0.8062 - val_loss: 0.4286 - val_accuracy: 0.8062\n",
            "Epoch 471/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4288 - accuracy: 0.8062 - val_loss: 0.4285 - val_accuracy: 0.8062\n",
            "Epoch 472/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4286 - accuracy: 0.8083 - val_loss: 0.4284 - val_accuracy: 0.8083\n",
            "Epoch 473/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4287 - accuracy: 0.8083 - val_loss: 0.4283 - val_accuracy: 0.8062\n",
            "Epoch 474/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4286 - accuracy: 0.8083 - val_loss: 0.4283 - val_accuracy: 0.8083\n",
            "Epoch 475/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4285 - accuracy: 0.8083 - val_loss: 0.4282 - val_accuracy: 0.8083\n",
            "Epoch 476/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4283 - accuracy: 0.8083 - val_loss: 0.4281 - val_accuracy: 0.8083\n",
            "Epoch 477/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4283 - accuracy: 0.8083 - val_loss: 0.4281 - val_accuracy: 0.8083\n",
            "Epoch 478/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4283 - accuracy: 0.8083 - val_loss: 0.4280 - val_accuracy: 0.8062\n",
            "Epoch 479/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4284 - accuracy: 0.8062 - val_loss: 0.4279 - val_accuracy: 0.8062\n",
            "Epoch 480/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4283 - accuracy: 0.8042 - val_loss: 0.4279 - val_accuracy: 0.8021\n",
            "Epoch 481/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4281 - accuracy: 0.8021 - val_loss: 0.4278 - val_accuracy: 0.8042\n",
            "Epoch 482/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4280 - accuracy: 0.8042 - val_loss: 0.4278 - val_accuracy: 0.8042\n",
            "Epoch 483/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4279 - accuracy: 0.8042 - val_loss: 0.4277 - val_accuracy: 0.8042\n",
            "Epoch 484/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4278 - accuracy: 0.8042 - val_loss: 0.4276 - val_accuracy: 0.8042\n",
            "Epoch 485/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4278 - accuracy: 0.8042 - val_loss: 0.4275 - val_accuracy: 0.8042\n",
            "Epoch 486/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4277 - accuracy: 0.8042 - val_loss: 0.4274 - val_accuracy: 0.8042\n",
            "Epoch 487/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4278 - accuracy: 0.8042 - val_loss: 0.4274 - val_accuracy: 0.8042\n",
            "Epoch 488/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4277 - accuracy: 0.8042 - val_loss: 0.4273 - val_accuracy: 0.8042\n",
            "Epoch 489/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4274 - accuracy: 0.8042 - val_loss: 0.4273 - val_accuracy: 0.8042\n",
            "Epoch 490/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4275 - accuracy: 0.8042 - val_loss: 0.4272 - val_accuracy: 0.8042\n",
            "Epoch 491/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4274 - accuracy: 0.8042 - val_loss: 0.4271 - val_accuracy: 0.8042\n",
            "Epoch 492/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4274 - accuracy: 0.8062 - val_loss: 0.4271 - val_accuracy: 0.8062\n",
            "Epoch 493/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4272 - accuracy: 0.8042 - val_loss: 0.4270 - val_accuracy: 0.8021\n",
            "Epoch 494/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4274 - accuracy: 0.8000 - val_loss: 0.4269 - val_accuracy: 0.8042\n",
            "Epoch 495/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4272 - accuracy: 0.8042 - val_loss: 0.4268 - val_accuracy: 0.8042\n",
            "Epoch 496/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4270 - accuracy: 0.8042 - val_loss: 0.4268 - val_accuracy: 0.8042\n",
            "Epoch 497/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4270 - accuracy: 0.8042 - val_loss: 0.4267 - val_accuracy: 0.8042\n",
            "Epoch 498/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4269 - accuracy: 0.8042 - val_loss: 0.4266 - val_accuracy: 0.8042\n",
            "Epoch 499/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4269 - accuracy: 0.8021 - val_loss: 0.4265 - val_accuracy: 0.8021\n",
            "Epoch 500/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4267 - accuracy: 0.8021 - val_loss: 0.4264 - val_accuracy: 0.8021\n",
            "Epoch 501/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4267 - accuracy: 0.8021 - val_loss: 0.4264 - val_accuracy: 0.8021\n",
            "Epoch 502/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4266 - accuracy: 0.8021 - val_loss: 0.4264 - val_accuracy: 0.8021\n",
            "Epoch 503/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4265 - accuracy: 0.8000 - val_loss: 0.4263 - val_accuracy: 0.8000\n",
            "Epoch 504/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4266 - accuracy: 0.8000 - val_loss: 0.4262 - val_accuracy: 0.8021\n",
            "Epoch 505/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4265 - accuracy: 0.8000 - val_loss: 0.4262 - val_accuracy: 0.8021\n",
            "Epoch 506/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4263 - accuracy: 0.8000 - val_loss: 0.4261 - val_accuracy: 0.8000\n",
            "Epoch 507/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4263 - accuracy: 0.8000 - val_loss: 0.4260 - val_accuracy: 0.8021\n",
            "Epoch 508/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4262 - accuracy: 0.8042 - val_loss: 0.4260 - val_accuracy: 0.8042\n",
            "Epoch 509/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4262 - accuracy: 0.8042 - val_loss: 0.4259 - val_accuracy: 0.8042\n",
            "Epoch 510/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4262 - accuracy: 0.8021 - val_loss: 0.4258 - val_accuracy: 0.8021\n",
            "Epoch 511/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4260 - accuracy: 0.8021 - val_loss: 0.4257 - val_accuracy: 0.8021\n",
            "Epoch 512/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4259 - accuracy: 0.8021 - val_loss: 0.4257 - val_accuracy: 0.8021\n",
            "Epoch 513/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4259 - accuracy: 0.8021 - val_loss: 0.4256 - val_accuracy: 0.8021\n",
            "Epoch 514/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4258 - accuracy: 0.8021 - val_loss: 0.4256 - val_accuracy: 0.8021\n",
            "Epoch 515/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4257 - accuracy: 0.8021 - val_loss: 0.4255 - val_accuracy: 0.8021\n",
            "Epoch 516/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4257 - accuracy: 0.8021 - val_loss: 0.4254 - val_accuracy: 0.8042\n",
            "Epoch 517/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4256 - accuracy: 0.8042 - val_loss: 0.4254 - val_accuracy: 0.8042\n",
            "Epoch 518/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4256 - accuracy: 0.8042 - val_loss: 0.4254 - val_accuracy: 0.8042\n",
            "Epoch 519/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4256 - accuracy: 0.8042 - val_loss: 0.4253 - val_accuracy: 0.8021\n",
            "Epoch 520/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4255 - accuracy: 0.8021 - val_loss: 0.4253 - val_accuracy: 0.8021\n",
            "Epoch 521/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4254 - accuracy: 0.8021 - val_loss: 0.4252 - val_accuracy: 0.8021\n",
            "Epoch 522/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4256 - accuracy: 0.8021 - val_loss: 0.4251 - val_accuracy: 0.8042\n",
            "Epoch 523/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4253 - accuracy: 0.8042 - val_loss: 0.4251 - val_accuracy: 0.8042\n",
            "Epoch 524/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4252 - accuracy: 0.8042 - val_loss: 0.4250 - val_accuracy: 0.8021\n",
            "Epoch 525/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4252 - accuracy: 0.8021 - val_loss: 0.4249 - val_accuracy: 0.8021\n",
            "Epoch 526/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4253 - accuracy: 0.8021 - val_loss: 0.4249 - val_accuracy: 0.8021\n",
            "Epoch 527/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4251 - accuracy: 0.8021 - val_loss: 0.4248 - val_accuracy: 0.8042\n",
            "Epoch 528/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4251 - accuracy: 0.8042 - val_loss: 0.4248 - val_accuracy: 0.8042\n",
            "Epoch 529/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4251 - accuracy: 0.8042 - val_loss: 0.4247 - val_accuracy: 0.8042\n",
            "Epoch 530/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4249 - accuracy: 0.8042 - val_loss: 0.4246 - val_accuracy: 0.8042\n",
            "Epoch 531/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4248 - accuracy: 0.8042 - val_loss: 0.4245 - val_accuracy: 0.8042\n",
            "Epoch 532/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4247 - accuracy: 0.8042 - val_loss: 0.4245 - val_accuracy: 0.8042\n",
            "Epoch 533/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4246 - accuracy: 0.8042 - val_loss: 0.4243 - val_accuracy: 0.8042\n",
            "Epoch 534/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4245 - accuracy: 0.8042 - val_loss: 0.4242 - val_accuracy: 0.8042\n",
            "Epoch 535/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4244 - accuracy: 0.8021 - val_loss: 0.4241 - val_accuracy: 0.8000\n",
            "Epoch 536/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4243 - accuracy: 0.8021 - val_loss: 0.4241 - val_accuracy: 0.8000\n",
            "Epoch 537/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4242 - accuracy: 0.8000 - val_loss: 0.4240 - val_accuracy: 0.8000\n",
            "Epoch 538/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4243 - accuracy: 0.8000 - val_loss: 0.4240 - val_accuracy: 0.8000\n",
            "Epoch 539/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4242 - accuracy: 0.8000 - val_loss: 0.4240 - val_accuracy: 0.8000\n",
            "Epoch 540/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4242 - accuracy: 0.8000 - val_loss: 0.4239 - val_accuracy: 0.8021\n",
            "Epoch 541/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4241 - accuracy: 0.8021 - val_loss: 0.4237 - val_accuracy: 0.8021\n",
            "Epoch 542/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4240 - accuracy: 0.8021 - val_loss: 0.4236 - val_accuracy: 0.8021\n",
            "Epoch 543/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4237 - accuracy: 0.8021 - val_loss: 0.4235 - val_accuracy: 0.8021\n",
            "Epoch 544/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4238 - accuracy: 0.8000 - val_loss: 0.4235 - val_accuracy: 0.8000\n",
            "Epoch 545/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4236 - accuracy: 0.8000 - val_loss: 0.4234 - val_accuracy: 0.8000\n",
            "Epoch 546/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4236 - accuracy: 0.8000 - val_loss: 0.4234 - val_accuracy: 0.8000\n",
            "Epoch 547/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4236 - accuracy: 0.8000 - val_loss: 0.4233 - val_accuracy: 0.8000\n",
            "Epoch 548/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4235 - accuracy: 0.8000 - val_loss: 0.4232 - val_accuracy: 0.8000\n",
            "Epoch 549/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4234 - accuracy: 0.8000 - val_loss: 0.4231 - val_accuracy: 0.8000\n",
            "Epoch 550/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4232 - accuracy: 0.8000 - val_loss: 0.4230 - val_accuracy: 0.8000\n",
            "Epoch 551/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4232 - accuracy: 0.8000 - val_loss: 0.4230 - val_accuracy: 0.8000\n",
            "Epoch 552/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4231 - accuracy: 0.8000 - val_loss: 0.4229 - val_accuracy: 0.8000\n",
            "Epoch 553/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4232 - accuracy: 0.8000 - val_loss: 0.4228 - val_accuracy: 0.8000\n",
            "Epoch 554/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4229 - accuracy: 0.8000 - val_loss: 0.4227 - val_accuracy: 0.8000\n",
            "Epoch 555/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4229 - accuracy: 0.8000 - val_loss: 0.4227 - val_accuracy: 0.8000\n",
            "Epoch 556/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4229 - accuracy: 0.8000 - val_loss: 0.4226 - val_accuracy: 0.8000\n",
            "Epoch 557/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4227 - accuracy: 0.8000 - val_loss: 0.4225 - val_accuracy: 0.8021\n",
            "Epoch 558/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4228 - accuracy: 0.8000 - val_loss: 0.4225 - val_accuracy: 0.8000\n",
            "Epoch 559/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4226 - accuracy: 0.8000 - val_loss: 0.4224 - val_accuracy: 0.8000\n",
            "Epoch 560/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4225 - accuracy: 0.8000 - val_loss: 0.4223 - val_accuracy: 0.8000\n",
            "Epoch 561/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4224 - accuracy: 0.8000 - val_loss: 0.4222 - val_accuracy: 0.8000\n",
            "Epoch 562/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4224 - accuracy: 0.8000 - val_loss: 0.4221 - val_accuracy: 0.8000\n",
            "Epoch 563/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4224 - accuracy: 0.8000 - val_loss: 0.4221 - val_accuracy: 0.8000\n",
            "Epoch 564/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4224 - accuracy: 0.8000 - val_loss: 0.4221 - val_accuracy: 0.8000\n",
            "Epoch 565/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4223 - accuracy: 0.8000 - val_loss: 0.4220 - val_accuracy: 0.8000\n",
            "Epoch 566/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4222 - accuracy: 0.8000 - val_loss: 0.4219 - val_accuracy: 0.8021\n",
            "Epoch 567/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4220 - accuracy: 0.8021 - val_loss: 0.4218 - val_accuracy: 0.8042\n",
            "Epoch 568/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4220 - accuracy: 0.8042 - val_loss: 0.4217 - val_accuracy: 0.8062\n",
            "Epoch 569/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4220 - accuracy: 0.8021 - val_loss: 0.4217 - val_accuracy: 0.8021\n",
            "Epoch 570/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4218 - accuracy: 0.8000 - val_loss: 0.4216 - val_accuracy: 0.8021\n",
            "Epoch 571/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4218 - accuracy: 0.8042 - val_loss: 0.4215 - val_accuracy: 0.8062\n",
            "Epoch 572/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4217 - accuracy: 0.8062 - val_loss: 0.4215 - val_accuracy: 0.8042\n",
            "Epoch 573/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4216 - accuracy: 0.8000 - val_loss: 0.4214 - val_accuracy: 0.8000\n",
            "Epoch 574/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4216 - accuracy: 0.8000 - val_loss: 0.4213 - val_accuracy: 0.8000\n",
            "Epoch 575/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4216 - accuracy: 0.8062 - val_loss: 0.4213 - val_accuracy: 0.8062\n",
            "Epoch 576/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4215 - accuracy: 0.8062 - val_loss: 0.4212 - val_accuracy: 0.8062\n",
            "Epoch 577/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4213 - accuracy: 0.8062 - val_loss: 0.4211 - val_accuracy: 0.8062\n",
            "Epoch 578/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4213 - accuracy: 0.8042 - val_loss: 0.4211 - val_accuracy: 0.8042\n",
            "Epoch 579/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4213 - accuracy: 0.8042 - val_loss: 0.4210 - val_accuracy: 0.8062\n",
            "Epoch 580/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4213 - accuracy: 0.8062 - val_loss: 0.4210 - val_accuracy: 0.8062\n",
            "Epoch 581/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4212 - accuracy: 0.8062 - val_loss: 0.4209 - val_accuracy: 0.8062\n",
            "Epoch 582/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4211 - accuracy: 0.8062 - val_loss: 0.4208 - val_accuracy: 0.8062\n",
            "Epoch 583/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4210 - accuracy: 0.8062 - val_loss: 0.4208 - val_accuracy: 0.8042\n",
            "Epoch 584/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4210 - accuracy: 0.8021 - val_loss: 0.4207 - val_accuracy: 0.8042\n",
            "Epoch 585/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4209 - accuracy: 0.8062 - val_loss: 0.4207 - val_accuracy: 0.8062\n",
            "Epoch 586/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4208 - accuracy: 0.8062 - val_loss: 0.4206 - val_accuracy: 0.8062\n",
            "Epoch 587/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4208 - accuracy: 0.8062 - val_loss: 0.4206 - val_accuracy: 0.8042\n",
            "Epoch 588/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4211 - accuracy: 0.8042 - val_loss: 0.4205 - val_accuracy: 0.8062\n",
            "Epoch 589/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4207 - accuracy: 0.8062 - val_loss: 0.4204 - val_accuracy: 0.8062\n",
            "Epoch 590/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4205 - accuracy: 0.8062 - val_loss: 0.4204 - val_accuracy: 0.8042\n",
            "Epoch 591/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4205 - accuracy: 0.8042 - val_loss: 0.4203 - val_accuracy: 0.8042\n",
            "Epoch 592/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4204 - accuracy: 0.8042 - val_loss: 0.4202 - val_accuracy: 0.8042\n",
            "Epoch 593/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4206 - accuracy: 0.8042 - val_loss: 0.4202 - val_accuracy: 0.8042\n",
            "Epoch 594/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4204 - accuracy: 0.8042 - val_loss: 0.4202 - val_accuracy: 0.8042\n",
            "Epoch 595/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4204 - accuracy: 0.8042 - val_loss: 0.4200 - val_accuracy: 0.8042\n",
            "Epoch 596/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4202 - accuracy: 0.8042 - val_loss: 0.4200 - val_accuracy: 0.8042\n",
            "Epoch 597/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4202 - accuracy: 0.8042 - val_loss: 0.4199 - val_accuracy: 0.8042\n",
            "Epoch 598/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4202 - accuracy: 0.8042 - val_loss: 0.4199 - val_accuracy: 0.8042\n",
            "Epoch 599/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4202 - accuracy: 0.8042 - val_loss: 0.4198 - val_accuracy: 0.8042\n",
            "Epoch 600/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4200 - accuracy: 0.8042 - val_loss: 0.4198 - val_accuracy: 0.8042\n",
            "Epoch 601/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4200 - accuracy: 0.8042 - val_loss: 0.4197 - val_accuracy: 0.8042\n",
            "Epoch 602/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4200 - accuracy: 0.8042 - val_loss: 0.4197 - val_accuracy: 0.8042\n",
            "Epoch 603/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4198 - accuracy: 0.8042 - val_loss: 0.4196 - val_accuracy: 0.8042\n",
            "Epoch 604/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4198 - accuracy: 0.8042 - val_loss: 0.4195 - val_accuracy: 0.8042\n",
            "Epoch 605/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4197 - accuracy: 0.8042 - val_loss: 0.4195 - val_accuracy: 0.8083\n",
            "Epoch 606/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4197 - accuracy: 0.8083 - val_loss: 0.4194 - val_accuracy: 0.8083\n",
            "Epoch 607/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4196 - accuracy: 0.8083 - val_loss: 0.4194 - val_accuracy: 0.8083\n",
            "Epoch 608/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4196 - accuracy: 0.8062 - val_loss: 0.4194 - val_accuracy: 0.8062\n",
            "Epoch 609/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4196 - accuracy: 0.8083 - val_loss: 0.4193 - val_accuracy: 0.8062\n",
            "Epoch 610/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4196 - accuracy: 0.8062 - val_loss: 0.4193 - val_accuracy: 0.8062\n",
            "Epoch 611/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4194 - accuracy: 0.8062 - val_loss: 0.4192 - val_accuracy: 0.8062\n",
            "Epoch 612/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4193 - accuracy: 0.8083 - val_loss: 0.4192 - val_accuracy: 0.8062\n",
            "Epoch 613/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4195 - accuracy: 0.8062 - val_loss: 0.4191 - val_accuracy: 0.8062\n",
            "Epoch 614/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4193 - accuracy: 0.8062 - val_loss: 0.4191 - val_accuracy: 0.8062\n",
            "Epoch 615/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4193 - accuracy: 0.8062 - val_loss: 0.4189 - val_accuracy: 0.8062\n",
            "Epoch 616/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4194 - accuracy: 0.8042 - val_loss: 0.4190 - val_accuracy: 0.8062\n",
            "Epoch 617/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4192 - accuracy: 0.8062 - val_loss: 0.4189 - val_accuracy: 0.8062\n",
            "Epoch 618/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4190 - accuracy: 0.8062 - val_loss: 0.4188 - val_accuracy: 0.8042\n",
            "Epoch 619/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4190 - accuracy: 0.8062 - val_loss: 0.4188 - val_accuracy: 0.8042\n",
            "Epoch 620/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4189 - accuracy: 0.8042 - val_loss: 0.4187 - val_accuracy: 0.8042\n",
            "Epoch 621/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4191 - accuracy: 0.8021 - val_loss: 0.4187 - val_accuracy: 0.8042\n",
            "Epoch 622/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4188 - accuracy: 0.8042 - val_loss: 0.4186 - val_accuracy: 0.8042\n",
            "Epoch 623/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4188 - accuracy: 0.8042 - val_loss: 0.4185 - val_accuracy: 0.8042\n",
            "Epoch 624/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4186 - accuracy: 0.8042 - val_loss: 0.4184 - val_accuracy: 0.8042\n",
            "Epoch 625/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4186 - accuracy: 0.8042 - val_loss: 0.4183 - val_accuracy: 0.8042\n",
            "Epoch 626/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4186 - accuracy: 0.8042 - val_loss: 0.4183 - val_accuracy: 0.8062\n",
            "Epoch 627/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4186 - accuracy: 0.8042 - val_loss: 0.4182 - val_accuracy: 0.8042\n",
            "Epoch 628/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4184 - accuracy: 0.8042 - val_loss: 0.4181 - val_accuracy: 0.8042\n",
            "Epoch 629/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4184 - accuracy: 0.8042 - val_loss: 0.4181 - val_accuracy: 0.8062\n",
            "Epoch 630/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4182 - accuracy: 0.8042 - val_loss: 0.4180 - val_accuracy: 0.8021\n",
            "Epoch 631/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4182 - accuracy: 0.8062 - val_loss: 0.4179 - val_accuracy: 0.8062\n",
            "Epoch 632/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4181 - accuracy: 0.8062 - val_loss: 0.4179 - val_accuracy: 0.8021\n",
            "Epoch 633/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4180 - accuracy: 0.8021 - val_loss: 0.4178 - val_accuracy: 0.8042\n",
            "Epoch 634/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4180 - accuracy: 0.8021 - val_loss: 0.4177 - val_accuracy: 0.8042\n",
            "Epoch 635/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4179 - accuracy: 0.8042 - val_loss: 0.4176 - val_accuracy: 0.8062\n",
            "Epoch 636/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4179 - accuracy: 0.8062 - val_loss: 0.4176 - val_accuracy: 0.8062\n",
            "Epoch 637/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4178 - accuracy: 0.8042 - val_loss: 0.4176 - val_accuracy: 0.8062\n",
            "Epoch 638/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4178 - accuracy: 0.8042 - val_loss: 0.4175 - val_accuracy: 0.8021\n",
            "Epoch 639/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4176 - accuracy: 0.8021 - val_loss: 0.4174 - val_accuracy: 0.8021\n",
            "Epoch 640/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4176 - accuracy: 0.8021 - val_loss: 0.4174 - val_accuracy: 0.8021\n",
            "Epoch 641/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4175 - accuracy: 0.8021 - val_loss: 0.4173 - val_accuracy: 0.8021\n",
            "Epoch 642/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4175 - accuracy: 0.8042 - val_loss: 0.4172 - val_accuracy: 0.8042\n",
            "Epoch 643/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4174 - accuracy: 0.8042 - val_loss: 0.4171 - val_accuracy: 0.8042\n",
            "Epoch 644/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4173 - accuracy: 0.8021 - val_loss: 0.4171 - val_accuracy: 0.8042\n",
            "Epoch 645/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4174 - accuracy: 0.8021 - val_loss: 0.4170 - val_accuracy: 0.8021\n",
            "Epoch 646/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4172 - accuracy: 0.8021 - val_loss: 0.4169 - val_accuracy: 0.8021\n",
            "Epoch 647/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4171 - accuracy: 0.8021 - val_loss: 0.4169 - val_accuracy: 0.8021\n",
            "Epoch 648/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4171 - accuracy: 0.8021 - val_loss: 0.4168 - val_accuracy: 0.8021\n",
            "Epoch 649/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4170 - accuracy: 0.8021 - val_loss: 0.4168 - val_accuracy: 0.8021\n",
            "Epoch 650/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4169 - accuracy: 0.8021 - val_loss: 0.4167 - val_accuracy: 0.8021\n",
            "Epoch 651/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4169 - accuracy: 0.8021 - val_loss: 0.4167 - val_accuracy: 0.8021\n",
            "Epoch 652/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4170 - accuracy: 0.8042 - val_loss: 0.4167 - val_accuracy: 0.8042\n",
            "Epoch 653/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4170 - accuracy: 0.8021 - val_loss: 0.4166 - val_accuracy: 0.8021\n",
            "Epoch 654/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4168 - accuracy: 0.8021 - val_loss: 0.4164 - val_accuracy: 0.8021\n",
            "Epoch 655/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4167 - accuracy: 0.8021 - val_loss: 0.4164 - val_accuracy: 0.8021\n",
            "Epoch 656/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4166 - accuracy: 0.8021 - val_loss: 0.4163 - val_accuracy: 0.8021\n",
            "Epoch 657/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4166 - accuracy: 0.8021 - val_loss: 0.4162 - val_accuracy: 0.8021\n",
            "Epoch 658/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4166 - accuracy: 0.8021 - val_loss: 0.4162 - val_accuracy: 0.8021\n",
            "Epoch 659/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4164 - accuracy: 0.8021 - val_loss: 0.4161 - val_accuracy: 0.8000\n",
            "Epoch 660/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4163 - accuracy: 0.8000 - val_loss: 0.4160 - val_accuracy: 0.8000\n",
            "Epoch 661/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4162 - accuracy: 0.8000 - val_loss: 0.4159 - val_accuracy: 0.8000\n",
            "Epoch 662/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4161 - accuracy: 0.8000 - val_loss: 0.4158 - val_accuracy: 0.8000\n",
            "Epoch 663/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4161 - accuracy: 0.8000 - val_loss: 0.4158 - val_accuracy: 0.8021\n",
            "Epoch 664/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4160 - accuracy: 0.8021 - val_loss: 0.4157 - val_accuracy: 0.8021\n",
            "Epoch 665/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4159 - accuracy: 0.8021 - val_loss: 0.4156 - val_accuracy: 0.8021\n",
            "Epoch 666/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4158 - accuracy: 0.8021 - val_loss: 0.4156 - val_accuracy: 0.8021\n",
            "Epoch 667/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4160 - accuracy: 0.8021 - val_loss: 0.4156 - val_accuracy: 0.8021\n",
            "Epoch 668/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4158 - accuracy: 0.8000 - val_loss: 0.4155 - val_accuracy: 0.8000\n",
            "Epoch 669/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4158 - accuracy: 0.8021 - val_loss: 0.4155 - val_accuracy: 0.8021\n",
            "Epoch 670/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4157 - accuracy: 0.8021 - val_loss: 0.4153 - val_accuracy: 0.8000\n",
            "Epoch 671/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4156 - accuracy: 0.8000 - val_loss: 0.4153 - val_accuracy: 0.8021\n",
            "Epoch 672/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4154 - accuracy: 0.8021 - val_loss: 0.4152 - val_accuracy: 0.8000\n",
            "Epoch 673/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4155 - accuracy: 0.8021 - val_loss: 0.4152 - val_accuracy: 0.8042\n",
            "Epoch 674/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4156 - accuracy: 0.8042 - val_loss: 0.4151 - val_accuracy: 0.8042\n",
            "Epoch 675/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4153 - accuracy: 0.8021 - val_loss: 0.4150 - val_accuracy: 0.8042\n",
            "Epoch 676/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4152 - accuracy: 0.8042 - val_loss: 0.4150 - val_accuracy: 0.8021\n",
            "Epoch 677/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4154 - accuracy: 0.8000 - val_loss: 0.4149 - val_accuracy: 0.8000\n",
            "Epoch 678/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4151 - accuracy: 0.8021 - val_loss: 0.4149 - val_accuracy: 0.8021\n",
            "Epoch 679/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4153 - accuracy: 0.8021 - val_loss: 0.4149 - val_accuracy: 0.8042\n",
            "Epoch 680/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4150 - accuracy: 0.8062 - val_loss: 0.4148 - val_accuracy: 0.8042\n",
            "Epoch 681/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4149 - accuracy: 0.8042 - val_loss: 0.4147 - val_accuracy: 0.8042\n",
            "Epoch 682/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4149 - accuracy: 0.8042 - val_loss: 0.4146 - val_accuracy: 0.8021\n",
            "Epoch 683/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4152 - accuracy: 0.8021 - val_loss: 0.4145 - val_accuracy: 0.8042\n",
            "Epoch 684/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4148 - accuracy: 0.8021 - val_loss: 0.4145 - val_accuracy: 0.8042\n",
            "Epoch 685/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4147 - accuracy: 0.8042 - val_loss: 0.4144 - val_accuracy: 0.8062\n",
            "Epoch 686/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4147 - accuracy: 0.8042 - val_loss: 0.4144 - val_accuracy: 0.8042\n",
            "Epoch 687/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4146 - accuracy: 0.8042 - val_loss: 0.4143 - val_accuracy: 0.8062\n",
            "Epoch 688/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4144 - accuracy: 0.8062 - val_loss: 0.4142 - val_accuracy: 0.8083\n",
            "Epoch 689/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4146 - accuracy: 0.8083 - val_loss: 0.4142 - val_accuracy: 0.8042\n",
            "Epoch 690/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4146 - accuracy: 0.8062 - val_loss: 0.4141 - val_accuracy: 0.8083\n",
            "Epoch 691/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4144 - accuracy: 0.8083 - val_loss: 0.4140 - val_accuracy: 0.8083\n",
            "Epoch 692/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4142 - accuracy: 0.8083 - val_loss: 0.4140 - val_accuracy: 0.8083\n",
            "Epoch 693/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4142 - accuracy: 0.8083 - val_loss: 0.4139 - val_accuracy: 0.8083\n",
            "Epoch 694/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4141 - accuracy: 0.8083 - val_loss: 0.4138 - val_accuracy: 0.8083\n",
            "Epoch 695/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4141 - accuracy: 0.8083 - val_loss: 0.4138 - val_accuracy: 0.8083\n",
            "Epoch 696/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4140 - accuracy: 0.8083 - val_loss: 0.4138 - val_accuracy: 0.8083\n",
            "Epoch 697/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4141 - accuracy: 0.8083 - val_loss: 0.4137 - val_accuracy: 0.8083\n",
            "Epoch 698/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4141 - accuracy: 0.8083 - val_loss: 0.4140 - val_accuracy: 0.8062\n",
            "Epoch 699/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4144 - accuracy: 0.8042 - val_loss: 0.4140 - val_accuracy: 0.8062\n",
            "Epoch 700/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4141 - accuracy: 0.8062 - val_loss: 0.4138 - val_accuracy: 0.8062\n",
            "Epoch 701/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4139 - accuracy: 0.8083 - val_loss: 0.4137 - val_accuracy: 0.8083\n",
            "Epoch 702/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4138 - accuracy: 0.8083 - val_loss: 0.4136 - val_accuracy: 0.8083\n",
            "Epoch 703/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4138 - accuracy: 0.8083 - val_loss: 0.4135 - val_accuracy: 0.8062\n",
            "Epoch 704/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4138 - accuracy: 0.8062 - val_loss: 0.4135 - val_accuracy: 0.8062\n",
            "Epoch 705/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4137 - accuracy: 0.8062 - val_loss: 0.4134 - val_accuracy: 0.8062\n",
            "Epoch 706/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4136 - accuracy: 0.8083 - val_loss: 0.4133 - val_accuracy: 0.8083\n",
            "Epoch 707/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4135 - accuracy: 0.8062 - val_loss: 0.4133 - val_accuracy: 0.8062\n",
            "Epoch 708/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4134 - accuracy: 0.8062 - val_loss: 0.4133 - val_accuracy: 0.8083\n",
            "Epoch 709/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4134 - accuracy: 0.8083 - val_loss: 0.4132 - val_accuracy: 0.8083\n",
            "Epoch 710/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4134 - accuracy: 0.8083 - val_loss: 0.4132 - val_accuracy: 0.8083\n",
            "Epoch 711/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4133 - accuracy: 0.8083 - val_loss: 0.4131 - val_accuracy: 0.8062\n",
            "Epoch 712/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4133 - accuracy: 0.8062 - val_loss: 0.4131 - val_accuracy: 0.8062\n",
            "Epoch 713/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4132 - accuracy: 0.8062 - val_loss: 0.4130 - val_accuracy: 0.8062\n",
            "Epoch 714/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4132 - accuracy: 0.8062 - val_loss: 0.4130 - val_accuracy: 0.8062\n",
            "Epoch 715/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4134 - accuracy: 0.8042 - val_loss: 0.4130 - val_accuracy: 0.8042\n",
            "Epoch 716/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4133 - accuracy: 0.8042 - val_loss: 0.4129 - val_accuracy: 0.8083\n",
            "Epoch 717/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4131 - accuracy: 0.8062 - val_loss: 0.4128 - val_accuracy: 0.8062\n",
            "Epoch 718/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4131 - accuracy: 0.8062 - val_loss: 0.4128 - val_accuracy: 0.8062\n",
            "Epoch 719/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4130 - accuracy: 0.8083 - val_loss: 0.4128 - val_accuracy: 0.8104\n",
            "Epoch 720/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4130 - accuracy: 0.8083 - val_loss: 0.4127 - val_accuracy: 0.8104\n",
            "Epoch 721/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4129 - accuracy: 0.8104 - val_loss: 0.4126 - val_accuracy: 0.8083\n",
            "Epoch 722/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4128 - accuracy: 0.8083 - val_loss: 0.4126 - val_accuracy: 0.8062\n",
            "Epoch 723/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4129 - accuracy: 0.8062 - val_loss: 0.4126 - val_accuracy: 0.8062\n",
            "Epoch 724/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4128 - accuracy: 0.8104 - val_loss: 0.4125 - val_accuracy: 0.8083\n",
            "Epoch 725/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4127 - accuracy: 0.8062 - val_loss: 0.4126 - val_accuracy: 0.8062\n",
            "Epoch 726/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4128 - accuracy: 0.8062 - val_loss: 0.4125 - val_accuracy: 0.8104\n",
            "Epoch 727/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4127 - accuracy: 0.8104 - val_loss: 0.4125 - val_accuracy: 0.8083\n",
            "Epoch 728/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4127 - accuracy: 0.8083 - val_loss: 0.4124 - val_accuracy: 0.8083\n",
            "Epoch 729/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4127 - accuracy: 0.8104 - val_loss: 0.4123 - val_accuracy: 0.8104\n",
            "Epoch 730/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4125 - accuracy: 0.8104 - val_loss: 0.4123 - val_accuracy: 0.8104\n",
            "Epoch 731/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4125 - accuracy: 0.8104 - val_loss: 0.4122 - val_accuracy: 0.8125\n",
            "Epoch 732/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4125 - accuracy: 0.8104 - val_loss: 0.4122 - val_accuracy: 0.8083\n",
            "Epoch 733/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4125 - accuracy: 0.8083 - val_loss: 0.4123 - val_accuracy: 0.8083\n",
            "Epoch 734/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4125 - accuracy: 0.8083 - val_loss: 0.4122 - val_accuracy: 0.8125\n",
            "Epoch 735/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4125 - accuracy: 0.8125 - val_loss: 0.4122 - val_accuracy: 0.8104\n",
            "Epoch 736/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4124 - accuracy: 0.8104 - val_loss: 0.4121 - val_accuracy: 0.8104\n",
            "Epoch 737/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4126 - accuracy: 0.8083 - val_loss: 0.4120 - val_accuracy: 0.8062\n",
            "Epoch 738/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4122 - accuracy: 0.8062 - val_loss: 0.4120 - val_accuracy: 0.8083\n",
            "Epoch 739/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4121 - accuracy: 0.8083 - val_loss: 0.4119 - val_accuracy: 0.8083\n",
            "Epoch 740/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4122 - accuracy: 0.8083 - val_loss: 0.4119 - val_accuracy: 0.8104\n",
            "Epoch 741/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4121 - accuracy: 0.8083 - val_loss: 0.4118 - val_accuracy: 0.8083\n",
            "Epoch 742/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4121 - accuracy: 0.8083 - val_loss: 0.4118 - val_accuracy: 0.8104\n",
            "Epoch 743/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4120 - accuracy: 0.8104 - val_loss: 0.4117 - val_accuracy: 0.8083\n",
            "Epoch 744/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4120 - accuracy: 0.8083 - val_loss: 0.4117 - val_accuracy: 0.8083\n",
            "Epoch 745/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4119 - accuracy: 0.8083 - val_loss: 0.4116 - val_accuracy: 0.8083\n",
            "Epoch 746/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4119 - accuracy: 0.8083 - val_loss: 0.4116 - val_accuracy: 0.8083\n",
            "Epoch 747/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4119 - accuracy: 0.8083 - val_loss: 0.4116 - val_accuracy: 0.8104\n",
            "Epoch 748/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4117 - accuracy: 0.8104 - val_loss: 0.4116 - val_accuracy: 0.8083\n",
            "Epoch 749/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4120 - accuracy: 0.8083 - val_loss: 0.4117 - val_accuracy: 0.8083\n",
            "Epoch 750/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4119 - accuracy: 0.8083 - val_loss: 0.4116 - val_accuracy: 0.8083\n",
            "Epoch 751/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4118 - accuracy: 0.8083 - val_loss: 0.4115 - val_accuracy: 0.8083\n",
            "Epoch 752/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4116 - accuracy: 0.8104 - val_loss: 0.4114 - val_accuracy: 0.8104\n",
            "Epoch 753/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4115 - accuracy: 0.8104 - val_loss: 0.4113 - val_accuracy: 0.8125\n",
            "Epoch 754/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4116 - accuracy: 0.8104 - val_loss: 0.4113 - val_accuracy: 0.8104\n",
            "Epoch 755/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4115 - accuracy: 0.8083 - val_loss: 0.4113 - val_accuracy: 0.8083\n",
            "Epoch 756/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4116 - accuracy: 0.8083 - val_loss: 0.4112 - val_accuracy: 0.8125\n",
            "Epoch 757/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4114 - accuracy: 0.8125 - val_loss: 0.4112 - val_accuracy: 0.8125\n",
            "Epoch 758/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4114 - accuracy: 0.8125 - val_loss: 0.4111 - val_accuracy: 0.8125\n",
            "Epoch 759/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4115 - accuracy: 0.8083 - val_loss: 0.4111 - val_accuracy: 0.8083\n",
            "Epoch 760/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4113 - accuracy: 0.8083 - val_loss: 0.4110 - val_accuracy: 0.8104\n",
            "Epoch 761/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4114 - accuracy: 0.8083 - val_loss: 0.4110 - val_accuracy: 0.8083\n",
            "Epoch 762/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4112 - accuracy: 0.8104 - val_loss: 0.4110 - val_accuracy: 0.8104\n",
            "Epoch 763/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4113 - accuracy: 0.8104 - val_loss: 0.4109 - val_accuracy: 0.8104\n",
            "Epoch 764/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4112 - accuracy: 0.8104 - val_loss: 0.4110 - val_accuracy: 0.8104\n",
            "Epoch 765/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4113 - accuracy: 0.8083 - val_loss: 0.4110 - val_accuracy: 0.8104\n",
            "Epoch 766/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4112 - accuracy: 0.8104 - val_loss: 0.4109 - val_accuracy: 0.8125\n",
            "Epoch 767/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4112 - accuracy: 0.8125 - val_loss: 0.4109 - val_accuracy: 0.8125\n",
            "Epoch 768/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4110 - accuracy: 0.8104 - val_loss: 0.4108 - val_accuracy: 0.8104\n",
            "Epoch 769/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4111 - accuracy: 0.8125 - val_loss: 0.4108 - val_accuracy: 0.8125\n",
            "Epoch 770/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4109 - accuracy: 0.8125 - val_loss: 0.4107 - val_accuracy: 0.8125\n",
            "Epoch 771/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4108 - accuracy: 0.8125 - val_loss: 0.4106 - val_accuracy: 0.8125\n",
            "Epoch 772/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4110 - accuracy: 0.8104 - val_loss: 0.4106 - val_accuracy: 0.8104\n",
            "Epoch 773/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4110 - accuracy: 0.8104 - val_loss: 0.4106 - val_accuracy: 0.8104\n",
            "Epoch 774/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4108 - accuracy: 0.8104 - val_loss: 0.4105 - val_accuracy: 0.8104\n",
            "Epoch 775/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4108 - accuracy: 0.8104 - val_loss: 0.4105 - val_accuracy: 0.8104\n",
            "Epoch 776/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4107 - accuracy: 0.8083 - val_loss: 0.4105 - val_accuracy: 0.8083\n",
            "Epoch 777/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4107 - accuracy: 0.8104 - val_loss: 0.4105 - val_accuracy: 0.8104\n",
            "Epoch 778/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4106 - accuracy: 0.8104 - val_loss: 0.4104 - val_accuracy: 0.8104\n",
            "Epoch 779/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4106 - accuracy: 0.8125 - val_loss: 0.4104 - val_accuracy: 0.8125\n",
            "Epoch 780/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4107 - accuracy: 0.8125 - val_loss: 0.4104 - val_accuracy: 0.8125\n",
            "Epoch 781/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4105 - accuracy: 0.8125 - val_loss: 0.4104 - val_accuracy: 0.8125\n",
            "Epoch 782/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4107 - accuracy: 0.8104 - val_loss: 0.4103 - val_accuracy: 0.8104\n",
            "Epoch 783/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4105 - accuracy: 0.8125 - val_loss: 0.4103 - val_accuracy: 0.8104\n",
            "Epoch 784/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4106 - accuracy: 0.8083 - val_loss: 0.4103 - val_accuracy: 0.8083\n",
            "Epoch 785/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4105 - accuracy: 0.8104 - val_loss: 0.4103 - val_accuracy: 0.8104\n",
            "Epoch 786/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4105 - accuracy: 0.8104 - val_loss: 0.4102 - val_accuracy: 0.8104\n",
            "Epoch 787/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4105 - accuracy: 0.8083 - val_loss: 0.4102 - val_accuracy: 0.8083\n",
            "Epoch 788/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4105 - accuracy: 0.8083 - val_loss: 0.4102 - val_accuracy: 0.8083\n",
            "Epoch 789/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8083 - val_loss: 0.4101 - val_accuracy: 0.8083\n",
            "Epoch 790/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8104 - val_loss: 0.4101 - val_accuracy: 0.8104\n",
            "Epoch 791/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4104 - accuracy: 0.8104 - val_loss: 0.4101 - val_accuracy: 0.8083\n",
            "Epoch 792/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4102 - accuracy: 0.8062 - val_loss: 0.4100 - val_accuracy: 0.8104\n",
            "Epoch 793/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4102 - accuracy: 0.8083 - val_loss: 0.4100 - val_accuracy: 0.8083\n",
            "Epoch 794/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4102 - accuracy: 0.8083 - val_loss: 0.4099 - val_accuracy: 0.8083\n",
            "Epoch 795/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4102 - accuracy: 0.8062 - val_loss: 0.4099 - val_accuracy: 0.8042\n",
            "Epoch 796/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4100 - accuracy: 0.8042 - val_loss: 0.4100 - val_accuracy: 0.8062\n",
            "Epoch 797/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8062 - val_loss: 0.4099 - val_accuracy: 0.8083\n",
            "Epoch 798/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4103 - accuracy: 0.8062 - val_loss: 0.4099 - val_accuracy: 0.8062\n",
            "Epoch 799/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4102 - accuracy: 0.8062 - val_loss: 0.4099 - val_accuracy: 0.8062\n",
            "Epoch 800/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4101 - accuracy: 0.8062 - val_loss: 0.4099 - val_accuracy: 0.8062\n",
            "Epoch 801/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4102 - accuracy: 0.8062 - val_loss: 0.4099 - val_accuracy: 0.8062\n",
            "Epoch 802/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4100 - accuracy: 0.8062 - val_loss: 0.4098 - val_accuracy: 0.8062\n",
            "Epoch 803/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4099 - accuracy: 0.8083 - val_loss: 0.4098 - val_accuracy: 0.8083\n",
            "Epoch 804/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4099 - accuracy: 0.8083 - val_loss: 0.4098 - val_accuracy: 0.8083\n",
            "Epoch 805/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4100 - accuracy: 0.8083 - val_loss: 0.4097 - val_accuracy: 0.8083\n",
            "Epoch 806/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4099 - accuracy: 0.8083 - val_loss: 0.4097 - val_accuracy: 0.8062\n",
            "Epoch 807/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4099 - accuracy: 0.8062 - val_loss: 0.4097 - val_accuracy: 0.8042\n",
            "Epoch 808/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4098 - accuracy: 0.8062 - val_loss: 0.4096 - val_accuracy: 0.8062\n",
            "Epoch 809/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4099 - accuracy: 0.8083 - val_loss: 0.4096 - val_accuracy: 0.8083\n",
            "Epoch 810/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4098 - accuracy: 0.8062 - val_loss: 0.4096 - val_accuracy: 0.8083\n",
            "Epoch 811/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4099 - accuracy: 0.8083 - val_loss: 0.4096 - val_accuracy: 0.8083\n",
            "Epoch 812/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4098 - accuracy: 0.8083 - val_loss: 0.4096 - val_accuracy: 0.8104\n",
            "Epoch 813/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4099 - accuracy: 0.8083 - val_loss: 0.4095 - val_accuracy: 0.8104\n",
            "Epoch 814/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4098 - accuracy: 0.8104 - val_loss: 0.4095 - val_accuracy: 0.8104\n",
            "Epoch 815/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4102 - accuracy: 0.8083 - val_loss: 0.4098 - val_accuracy: 0.8104\n",
            "Epoch 816/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4100 - accuracy: 0.8104 - val_loss: 0.4097 - val_accuracy: 0.8104\n",
            "Epoch 817/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4098 - accuracy: 0.8104 - val_loss: 0.4096 - val_accuracy: 0.8083\n",
            "Epoch 818/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4097 - accuracy: 0.8083 - val_loss: 0.4095 - val_accuracy: 0.8083\n",
            "Epoch 819/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4096 - accuracy: 0.8083 - val_loss: 0.4095 - val_accuracy: 0.8083\n",
            "Epoch 820/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4098 - accuracy: 0.8083 - val_loss: 0.4095 - val_accuracy: 0.8083\n",
            "Epoch 821/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4097 - accuracy: 0.8083 - val_loss: 0.4094 - val_accuracy: 0.8062\n",
            "Epoch 822/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4096 - accuracy: 0.8042 - val_loss: 0.4094 - val_accuracy: 0.8042\n",
            "Epoch 823/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4096 - accuracy: 0.8062 - val_loss: 0.4094 - val_accuracy: 0.8083\n",
            "Epoch 824/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4096 - accuracy: 0.8062 - val_loss: 0.4093 - val_accuracy: 0.8062\n",
            "Epoch 825/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4097 - accuracy: 0.8062 - val_loss: 0.4093 - val_accuracy: 0.8062\n",
            "Epoch 826/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4095 - accuracy: 0.8062 - val_loss: 0.4093 - val_accuracy: 0.8062\n",
            "Epoch 827/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4094 - accuracy: 0.8062 - val_loss: 0.4092 - val_accuracy: 0.8042\n",
            "Epoch 828/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4095 - accuracy: 0.8042 - val_loss: 0.4092 - val_accuracy: 0.8062\n",
            "Epoch 829/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4094 - accuracy: 0.8042 - val_loss: 0.4092 - val_accuracy: 0.8062\n",
            "Epoch 830/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4094 - accuracy: 0.8062 - val_loss: 0.4091 - val_accuracy: 0.8062\n",
            "Epoch 831/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4093 - accuracy: 0.8062 - val_loss: 0.4091 - val_accuracy: 0.8083\n",
            "Epoch 832/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4093 - accuracy: 0.8062 - val_loss: 0.4091 - val_accuracy: 0.8083\n",
            "Epoch 833/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4094 - accuracy: 0.8083 - val_loss: 0.4091 - val_accuracy: 0.8062\n",
            "Epoch 834/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4093 - accuracy: 0.8062 - val_loss: 0.4091 - val_accuracy: 0.8083\n",
            "Epoch 835/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4093 - accuracy: 0.8083 - val_loss: 0.4091 - val_accuracy: 0.8104\n",
            "Epoch 836/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4094 - accuracy: 0.8083 - val_loss: 0.4090 - val_accuracy: 0.8104\n",
            "Epoch 837/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4093 - accuracy: 0.8104 - val_loss: 0.4091 - val_accuracy: 0.8104\n",
            "Epoch 838/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4095 - accuracy: 0.8083 - val_loss: 0.4091 - val_accuracy: 0.8083\n",
            "Epoch 839/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4092 - accuracy: 0.8083 - val_loss: 0.4090 - val_accuracy: 0.8062\n",
            "Epoch 840/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4093 - accuracy: 0.8042 - val_loss: 0.4090 - val_accuracy: 0.8062\n",
            "Epoch 841/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4096 - accuracy: 0.8062 - val_loss: 0.4091 - val_accuracy: 0.8062\n",
            "Epoch 842/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4093 - accuracy: 0.8062 - val_loss: 0.4090 - val_accuracy: 0.8083\n",
            "Epoch 843/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4094 - accuracy: 0.8062 - val_loss: 0.4090 - val_accuracy: 0.8083\n",
            "Epoch 844/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4092 - accuracy: 0.8083 - val_loss: 0.4089 - val_accuracy: 0.8083\n",
            "Epoch 845/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4092 - accuracy: 0.8083 - val_loss: 0.4089 - val_accuracy: 0.8083\n",
            "Epoch 846/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4092 - accuracy: 0.8083 - val_loss: 0.4089 - val_accuracy: 0.8062\n",
            "Epoch 847/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4091 - accuracy: 0.8042 - val_loss: 0.4088 - val_accuracy: 0.8062\n",
            "Epoch 848/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4090 - accuracy: 0.8083 - val_loss: 0.4088 - val_accuracy: 0.8083\n",
            "Epoch 849/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4090 - accuracy: 0.8083 - val_loss: 0.4087 - val_accuracy: 0.8083\n",
            "Epoch 850/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4089 - accuracy: 0.8083 - val_loss: 0.4087 - val_accuracy: 0.8083\n",
            "Epoch 851/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4090 - accuracy: 0.8083 - val_loss: 0.4088 - val_accuracy: 0.8083\n",
            "Epoch 852/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4090 - accuracy: 0.8083 - val_loss: 0.4087 - val_accuracy: 0.8083\n",
            "Epoch 853/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4090 - accuracy: 0.8083 - val_loss: 0.4087 - val_accuracy: 0.8083\n",
            "Epoch 854/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4089 - accuracy: 0.8083 - val_loss: 0.4087 - val_accuracy: 0.8083\n",
            "Epoch 855/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4090 - accuracy: 0.8083 - val_loss: 0.4087 - val_accuracy: 0.8083\n",
            "Epoch 856/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4090 - accuracy: 0.8083 - val_loss: 0.4086 - val_accuracy: 0.8083\n",
            "Epoch 857/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4088 - accuracy: 0.8083 - val_loss: 0.4086 - val_accuracy: 0.8083\n",
            "Epoch 858/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4087 - accuracy: 0.8083 - val_loss: 0.4085 - val_accuracy: 0.8083\n",
            "Epoch 859/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4088 - accuracy: 0.8083 - val_loss: 0.4085 - val_accuracy: 0.8083\n",
            "Epoch 860/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4088 - accuracy: 0.8083 - val_loss: 0.4085 - val_accuracy: 0.8083\n",
            "Epoch 861/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4089 - accuracy: 0.8083 - val_loss: 0.4085 - val_accuracy: 0.8083\n",
            "Epoch 862/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4088 - accuracy: 0.8083 - val_loss: 0.4086 - val_accuracy: 0.8083\n",
            "Epoch 863/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4090 - accuracy: 0.8083 - val_loss: 0.4086 - val_accuracy: 0.8083\n",
            "Epoch 864/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4089 - accuracy: 0.8083 - val_loss: 0.4085 - val_accuracy: 0.8083\n",
            "Epoch 865/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4088 - accuracy: 0.8062 - val_loss: 0.4085 - val_accuracy: 0.8062\n",
            "Epoch 866/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4087 - accuracy: 0.8062 - val_loss: 0.4084 - val_accuracy: 0.8062\n",
            "Epoch 867/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4087 - accuracy: 0.8062 - val_loss: 0.4084 - val_accuracy: 0.8104\n",
            "Epoch 868/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4087 - accuracy: 0.8104 - val_loss: 0.4084 - val_accuracy: 0.8104\n",
            "Epoch 869/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4086 - accuracy: 0.8104 - val_loss: 0.4084 - val_accuracy: 0.8104\n",
            "Epoch 870/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4087 - accuracy: 0.8104 - val_loss: 0.4084 - val_accuracy: 0.8104\n",
            "Epoch 871/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4085 - accuracy: 0.8104 - val_loss: 0.4083 - val_accuracy: 0.8104\n",
            "Epoch 872/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4084 - accuracy: 0.8104 - val_loss: 0.4083 - val_accuracy: 0.8104\n",
            "Epoch 873/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4086 - accuracy: 0.8104 - val_loss: 0.4083 - val_accuracy: 0.8104\n",
            "Epoch 874/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4085 - accuracy: 0.8083 - val_loss: 0.4082 - val_accuracy: 0.8104\n",
            "Epoch 875/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4085 - accuracy: 0.8104 - val_loss: 0.4083 - val_accuracy: 0.8104\n",
            "Epoch 876/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4085 - accuracy: 0.8083 - val_loss: 0.4082 - val_accuracy: 0.8104\n",
            "Epoch 877/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4084 - accuracy: 0.8104 - val_loss: 0.4082 - val_accuracy: 0.8104\n",
            "Epoch 878/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4084 - accuracy: 0.8104 - val_loss: 0.4082 - val_accuracy: 0.8104\n",
            "Epoch 879/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4084 - accuracy: 0.8104 - val_loss: 0.4081 - val_accuracy: 0.8083\n",
            "Epoch 880/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4085 - accuracy: 0.8083 - val_loss: 0.4082 - val_accuracy: 0.8083\n",
            "Epoch 881/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4084 - accuracy: 0.8083 - val_loss: 0.4081 - val_accuracy: 0.8083\n",
            "Epoch 882/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4084 - accuracy: 0.8083 - val_loss: 0.4081 - val_accuracy: 0.8083\n",
            "Epoch 883/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4084 - accuracy: 0.8083 - val_loss: 0.4081 - val_accuracy: 0.8083\n",
            "Epoch 884/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4083 - accuracy: 0.8083 - val_loss: 0.4081 - val_accuracy: 0.8083\n",
            "Epoch 885/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4083 - accuracy: 0.8083 - val_loss: 0.4081 - val_accuracy: 0.8083\n",
            "Epoch 886/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4083 - accuracy: 0.8083 - val_loss: 0.4080 - val_accuracy: 0.8104\n",
            "Epoch 887/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4082 - accuracy: 0.8104 - val_loss: 0.4080 - val_accuracy: 0.8104\n",
            "Epoch 888/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4084 - accuracy: 0.8104 - val_loss: 0.4080 - val_accuracy: 0.8104\n",
            "Epoch 889/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4082 - accuracy: 0.8104 - val_loss: 0.4080 - val_accuracy: 0.8104\n",
            "Epoch 890/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4084 - accuracy: 0.8104 - val_loss: 0.4082 - val_accuracy: 0.8104\n",
            "Epoch 891/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4084 - accuracy: 0.8104 - val_loss: 0.4081 - val_accuracy: 0.8104\n",
            "Epoch 892/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4083 - accuracy: 0.8104 - val_loss: 0.4080 - val_accuracy: 0.8104\n",
            "Epoch 893/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4082 - accuracy: 0.8104 - val_loss: 0.4079 - val_accuracy: 0.8104\n",
            "Epoch 894/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4081 - accuracy: 0.8104 - val_loss: 0.4078 - val_accuracy: 0.8104\n",
            "Epoch 895/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4081 - accuracy: 0.8104 - val_loss: 0.4078 - val_accuracy: 0.8083\n",
            "Epoch 896/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4080 - accuracy: 0.8104 - val_loss: 0.4077 - val_accuracy: 0.8104\n",
            "Epoch 897/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4081 - accuracy: 0.8083 - val_loss: 0.4076 - val_accuracy: 0.8083\n",
            "Epoch 898/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4078 - accuracy: 0.8083 - val_loss: 0.4075 - val_accuracy: 0.8083\n",
            "Epoch 899/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4078 - accuracy: 0.8104 - val_loss: 0.4075 - val_accuracy: 0.8104\n",
            "Epoch 900/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4078 - accuracy: 0.8104 - val_loss: 0.4075 - val_accuracy: 0.8104\n",
            "Epoch 901/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4077 - accuracy: 0.8104 - val_loss: 0.4075 - val_accuracy: 0.8104\n",
            "Epoch 902/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4077 - accuracy: 0.8104 - val_loss: 0.4074 - val_accuracy: 0.8104\n",
            "Epoch 903/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4076 - accuracy: 0.8104 - val_loss: 0.4074 - val_accuracy: 0.8104\n",
            "Epoch 904/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4076 - accuracy: 0.8083 - val_loss: 0.4074 - val_accuracy: 0.8083\n",
            "Epoch 905/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4077 - accuracy: 0.8104 - val_loss: 0.4073 - val_accuracy: 0.8104\n",
            "Epoch 906/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4075 - accuracy: 0.8104 - val_loss: 0.4073 - val_accuracy: 0.8104\n",
            "Epoch 907/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4076 - accuracy: 0.8104 - val_loss: 0.4073 - val_accuracy: 0.8104\n",
            "Epoch 908/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4075 - accuracy: 0.8104 - val_loss: 0.4072 - val_accuracy: 0.8104\n",
            "Epoch 909/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4074 - accuracy: 0.8104 - val_loss: 0.4072 - val_accuracy: 0.8104\n",
            "Epoch 910/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4075 - accuracy: 0.8104 - val_loss: 0.4071 - val_accuracy: 0.8104\n",
            "Epoch 911/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4074 - accuracy: 0.8104 - val_loss: 0.4071 - val_accuracy: 0.8104\n",
            "Epoch 912/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4074 - accuracy: 0.8083 - val_loss: 0.4071 - val_accuracy: 0.8104\n",
            "Epoch 913/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4073 - accuracy: 0.8104 - val_loss: 0.4071 - val_accuracy: 0.8104\n",
            "Epoch 914/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4074 - accuracy: 0.8104 - val_loss: 0.4071 - val_accuracy: 0.8104\n",
            "Epoch 915/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4073 - accuracy: 0.8104 - val_loss: 0.4071 - val_accuracy: 0.8104\n",
            "Epoch 916/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4072 - accuracy: 0.8104 - val_loss: 0.4070 - val_accuracy: 0.8104\n",
            "Epoch 917/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4072 - accuracy: 0.8104 - val_loss: 0.4070 - val_accuracy: 0.8104\n",
            "Epoch 918/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4071 - accuracy: 0.8104 - val_loss: 0.4069 - val_accuracy: 0.8104\n",
            "Epoch 919/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4071 - accuracy: 0.8104 - val_loss: 0.4069 - val_accuracy: 0.8104\n",
            "Epoch 920/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4071 - accuracy: 0.8104 - val_loss: 0.4069 - val_accuracy: 0.8104\n",
            "Epoch 921/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4073 - accuracy: 0.8104 - val_loss: 0.4070 - val_accuracy: 0.8104\n",
            "Epoch 922/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4072 - accuracy: 0.8104 - val_loss: 0.4069 - val_accuracy: 0.8104\n",
            "Epoch 923/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4072 - accuracy: 0.8104 - val_loss: 0.4069 - val_accuracy: 0.8104\n",
            "Epoch 924/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4072 - accuracy: 0.8104 - val_loss: 0.4068 - val_accuracy: 0.8104\n",
            "Epoch 925/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4070 - accuracy: 0.8104 - val_loss: 0.4068 - val_accuracy: 0.8104\n",
            "Epoch 926/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4071 - accuracy: 0.8104 - val_loss: 0.4068 - val_accuracy: 0.8104\n",
            "Epoch 927/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4069 - accuracy: 0.8104 - val_loss: 0.4067 - val_accuracy: 0.8104\n",
            "Epoch 928/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4070 - accuracy: 0.8104 - val_loss: 0.4067 - val_accuracy: 0.8104\n",
            "Epoch 929/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4071 - accuracy: 0.8104 - val_loss: 0.4067 - val_accuracy: 0.8104\n",
            "Epoch 930/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4069 - accuracy: 0.8104 - val_loss: 0.4066 - val_accuracy: 0.8104\n",
            "Epoch 931/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4069 - accuracy: 0.8104 - val_loss: 0.4066 - val_accuracy: 0.8104\n",
            "Epoch 932/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4068 - accuracy: 0.8104 - val_loss: 0.4066 - val_accuracy: 0.8104\n",
            "Epoch 933/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4068 - accuracy: 0.8104 - val_loss: 0.4065 - val_accuracy: 0.8104\n",
            "Epoch 934/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4067 - accuracy: 0.8104 - val_loss: 0.4065 - val_accuracy: 0.8104\n",
            "Epoch 935/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4067 - accuracy: 0.8104 - val_loss: 0.4065 - val_accuracy: 0.8104\n",
            "Epoch 936/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4067 - accuracy: 0.8104 - val_loss: 0.4065 - val_accuracy: 0.8104\n",
            "Epoch 937/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4067 - accuracy: 0.8104 - val_loss: 0.4064 - val_accuracy: 0.8104\n",
            "Epoch 938/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4067 - accuracy: 0.8104 - val_loss: 0.4064 - val_accuracy: 0.8104\n",
            "Epoch 939/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4066 - accuracy: 0.8104 - val_loss: 0.4063 - val_accuracy: 0.8104\n",
            "Epoch 940/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4067 - accuracy: 0.8104 - val_loss: 0.4063 - val_accuracy: 0.8104\n",
            "Epoch 941/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4065 - accuracy: 0.8104 - val_loss: 0.4063 - val_accuracy: 0.8104\n",
            "Epoch 942/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4067 - accuracy: 0.8125 - val_loss: 0.4063 - val_accuracy: 0.8125\n",
            "Epoch 943/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4065 - accuracy: 0.8146 - val_loss: 0.4062 - val_accuracy: 0.8146\n",
            "Epoch 944/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4064 - accuracy: 0.8146 - val_loss: 0.4062 - val_accuracy: 0.8125\n",
            "Epoch 945/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4063 - accuracy: 0.8125 - val_loss: 0.4061 - val_accuracy: 0.8104\n",
            "Epoch 946/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4064 - accuracy: 0.8104 - val_loss: 0.4061 - val_accuracy: 0.8104\n",
            "Epoch 947/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4063 - accuracy: 0.8104 - val_loss: 0.4061 - val_accuracy: 0.8104\n",
            "Epoch 948/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4064 - accuracy: 0.8104 - val_loss: 0.4061 - val_accuracy: 0.8104\n",
            "Epoch 949/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4062 - accuracy: 0.8104 - val_loss: 0.4060 - val_accuracy: 0.8104\n",
            "Epoch 950/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4062 - accuracy: 0.8104 - val_loss: 0.4060 - val_accuracy: 0.8104\n",
            "Epoch 951/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4061 - accuracy: 0.8104 - val_loss: 0.4060 - val_accuracy: 0.8104\n",
            "Epoch 952/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4063 - accuracy: 0.8104 - val_loss: 0.4060 - val_accuracy: 0.8104\n",
            "Epoch 953/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4063 - accuracy: 0.8125 - val_loss: 0.4059 - val_accuracy: 0.8125\n",
            "Epoch 954/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4061 - accuracy: 0.8104 - val_loss: 0.4059 - val_accuracy: 0.8104\n",
            "Epoch 955/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4061 - accuracy: 0.8104 - val_loss: 0.4059 - val_accuracy: 0.8104\n",
            "Epoch 956/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4066 - accuracy: 0.8104 - val_loss: 0.4061 - val_accuracy: 0.8104\n",
            "Epoch 957/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4063 - accuracy: 0.8104 - val_loss: 0.4062 - val_accuracy: 0.8104\n",
            "Epoch 958/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4063 - accuracy: 0.8104 - val_loss: 0.4061 - val_accuracy: 0.8125\n",
            "Epoch 959/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4064 - accuracy: 0.8125 - val_loss: 0.4059 - val_accuracy: 0.8125\n",
            "Epoch 960/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4062 - accuracy: 0.8104 - val_loss: 0.4059 - val_accuracy: 0.8104\n",
            "Epoch 961/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4060 - accuracy: 0.8104 - val_loss: 0.4058 - val_accuracy: 0.8104\n",
            "Epoch 962/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4060 - accuracy: 0.8104 - val_loss: 0.4057 - val_accuracy: 0.8104\n",
            "Epoch 963/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4060 - accuracy: 0.8104 - val_loss: 0.4057 - val_accuracy: 0.8104\n",
            "Epoch 964/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4061 - accuracy: 0.8104 - val_loss: 0.4057 - val_accuracy: 0.8125\n",
            "Epoch 965/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4058 - accuracy: 0.8125 - val_loss: 0.4056 - val_accuracy: 0.8125\n",
            "Epoch 966/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4059 - accuracy: 0.8125 - val_loss: 0.4056 - val_accuracy: 0.8125\n",
            "Epoch 967/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4059 - accuracy: 0.8125 - val_loss: 0.4056 - val_accuracy: 0.8125\n",
            "Epoch 968/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4058 - accuracy: 0.8125 - val_loss: 0.4056 - val_accuracy: 0.8125\n",
            "Epoch 969/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4058 - accuracy: 0.8125 - val_loss: 0.4055 - val_accuracy: 0.8125\n",
            "Epoch 970/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4057 - accuracy: 0.8125 - val_loss: 0.4054 - val_accuracy: 0.8125\n",
            "Epoch 971/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4057 - accuracy: 0.8104 - val_loss: 0.4054 - val_accuracy: 0.8125\n",
            "Epoch 972/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4056 - accuracy: 0.8125 - val_loss: 0.4054 - val_accuracy: 0.8146\n",
            "Epoch 973/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4056 - accuracy: 0.8146 - val_loss: 0.4054 - val_accuracy: 0.8146\n",
            "Epoch 974/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4056 - accuracy: 0.8146 - val_loss: 0.4053 - val_accuracy: 0.8146\n",
            "Epoch 975/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4056 - accuracy: 0.8146 - val_loss: 0.4053 - val_accuracy: 0.8125\n",
            "Epoch 976/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4055 - accuracy: 0.8125 - val_loss: 0.4053 - val_accuracy: 0.8125\n",
            "Epoch 977/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4055 - accuracy: 0.8125 - val_loss: 0.4053 - val_accuracy: 0.8125\n",
            "Epoch 978/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4056 - accuracy: 0.8125 - val_loss: 0.4052 - val_accuracy: 0.8125\n",
            "Epoch 979/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4054 - accuracy: 0.8125 - val_loss: 0.4052 - val_accuracy: 0.8125\n",
            "Epoch 980/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4053 - accuracy: 0.8125 - val_loss: 0.4051 - val_accuracy: 0.8125\n",
            "Epoch 981/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4053 - accuracy: 0.8125 - val_loss: 0.4051 - val_accuracy: 0.8104\n",
            "Epoch 982/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4054 - accuracy: 0.8104 - val_loss: 0.4051 - val_accuracy: 0.8125\n",
            "Epoch 983/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4053 - accuracy: 0.8125 - val_loss: 0.4050 - val_accuracy: 0.8125\n",
            "Epoch 984/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4054 - accuracy: 0.8125 - val_loss: 0.4050 - val_accuracy: 0.8125\n",
            "Epoch 985/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4053 - accuracy: 0.8104 - val_loss: 0.4049 - val_accuracy: 0.8104\n",
            "Epoch 986/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4052 - accuracy: 0.8104 - val_loss: 0.4049 - val_accuracy: 0.8125\n",
            "Epoch 987/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4051 - accuracy: 0.8125 - val_loss: 0.4049 - val_accuracy: 0.8125\n",
            "Epoch 988/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4051 - accuracy: 0.8125 - val_loss: 0.4049 - val_accuracy: 0.8125\n",
            "Epoch 989/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4051 - accuracy: 0.8125 - val_loss: 0.4048 - val_accuracy: 0.8125\n",
            "Epoch 990/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4050 - accuracy: 0.8125 - val_loss: 0.4048 - val_accuracy: 0.8125\n",
            "Epoch 991/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4050 - accuracy: 0.8125 - val_loss: 0.4048 - val_accuracy: 0.8125\n",
            "Epoch 992/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4050 - accuracy: 0.8125 - val_loss: 0.4047 - val_accuracy: 0.8125\n",
            "Epoch 993/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4049 - accuracy: 0.8125 - val_loss: 0.4047 - val_accuracy: 0.8125\n",
            "Epoch 994/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4049 - accuracy: 0.8125 - val_loss: 0.4046 - val_accuracy: 0.8125\n",
            "Epoch 995/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4049 - accuracy: 0.8125 - val_loss: 0.4047 - val_accuracy: 0.8125\n",
            "Epoch 996/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4048 - accuracy: 0.8125 - val_loss: 0.4046 - val_accuracy: 0.8125\n",
            "Epoch 997/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4049 - accuracy: 0.8125 - val_loss: 0.4046 - val_accuracy: 0.8125\n",
            "Epoch 998/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4048 - accuracy: 0.8125 - val_loss: 0.4045 - val_accuracy: 0.8125\n",
            "Epoch 999/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4047 - accuracy: 0.8125 - val_loss: 0.4045 - val_accuracy: 0.8125\n",
            "Epoch 1000/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4049 - accuracy: 0.8125 - val_loss: 0.4045 - val_accuracy: 0.8125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "E1-SHQ-3Nz0n",
        "outputId": "93b22fe7-85c1-47dd-8b9c-1f18ed6e1109"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Fonction de perte (entropie croisee)')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "dQ0-lbyAOLuV",
        "outputId": "db098aee-16eb-4b8d-9025-43f9f154a9b6"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTQDGhwqPtPT",
        "outputId": "5042fa54-2fd5-4d9d-d6ea-38cb463076a7"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.Input(shape=(11)),\n",
        "  tf.keras.layers.Dense(5, activation='relu'),\n",
        "  tf.keras.layers.Dense(5, activation='relu'),\n",
        "  tf.keras.layers.Dense(2)\n",
        "])\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# On vérifie en regardant le résumé de ce réseau :\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySWJLsINP6Ps",
        "outputId": "cd9f40b5-728c-455d-f36c-f28a462963f3"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 5)                 60        \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 2)                 12        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 102\n",
            "Trainable params: 102\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset, validation_data= test_dataset,epochs=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzeKEnxQQC7H",
        "outputId": "68796bb4-1435-47f9-e123-4c4a97a41435"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "12/12 [==============================] - 1s 22ms/step - loss: 0.7567 - accuracy: 0.5666 - val_loss: 0.6676 - val_accuracy: 0.6250\n",
            "Epoch 2/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7208 - accuracy: 0.5845 - val_loss: 0.6463 - val_accuracy: 0.6292\n",
            "Epoch 3/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6941 - accuracy: 0.5952 - val_loss: 0.6332 - val_accuracy: 0.6354\n",
            "Epoch 4/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6757 - accuracy: 0.6041 - val_loss: 0.6236 - val_accuracy: 0.6417\n",
            "Epoch 5/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6615 - accuracy: 0.6175 - val_loss: 0.6166 - val_accuracy: 0.6583\n",
            "Epoch 6/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6502 - accuracy: 0.6363 - val_loss: 0.6112 - val_accuracy: 0.6562\n",
            "Epoch 7/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6409 - accuracy: 0.6497 - val_loss: 0.6075 - val_accuracy: 0.6500\n",
            "Epoch 8/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6333 - accuracy: 0.6577 - val_loss: 0.6041 - val_accuracy: 0.6458\n",
            "Epoch 9/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6270 - accuracy: 0.6685 - val_loss: 0.6011 - val_accuracy: 0.6521\n",
            "Epoch 10/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6218 - accuracy: 0.6693 - val_loss: 0.5984 - val_accuracy: 0.6708\n",
            "Epoch 11/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6168 - accuracy: 0.6729 - val_loss: 0.5963 - val_accuracy: 0.6750\n",
            "Epoch 12/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6127 - accuracy: 0.6819 - val_loss: 0.5947 - val_accuracy: 0.6875\n",
            "Epoch 13/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6087 - accuracy: 0.6890 - val_loss: 0.5925 - val_accuracy: 0.6833\n",
            "Epoch 14/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6055 - accuracy: 0.6926 - val_loss: 0.5905 - val_accuracy: 0.6979\n",
            "Epoch 15/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6023 - accuracy: 0.6899 - val_loss: 0.5885 - val_accuracy: 0.7000\n",
            "Epoch 16/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5993 - accuracy: 0.6926 - val_loss: 0.5864 - val_accuracy: 0.7021\n",
            "Epoch 17/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5965 - accuracy: 0.6953 - val_loss: 0.5850 - val_accuracy: 0.7063\n",
            "Epoch 18/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.6944 - val_loss: 0.5834 - val_accuracy: 0.7063\n",
            "Epoch 19/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.6962 - val_loss: 0.5820 - val_accuracy: 0.7021\n",
            "Epoch 20/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.6979 - val_loss: 0.5810 - val_accuracy: 0.7021\n",
            "Epoch 21/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5871 - accuracy: 0.6971 - val_loss: 0.5795 - val_accuracy: 0.7021\n",
            "Epoch 22/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5850 - accuracy: 0.6997 - val_loss: 0.5776 - val_accuracy: 0.7021\n",
            "Epoch 23/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5831 - accuracy: 0.7006 - val_loss: 0.5761 - val_accuracy: 0.7021\n",
            "Epoch 24/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5813 - accuracy: 0.7024 - val_loss: 0.5751 - val_accuracy: 0.7021\n",
            "Epoch 25/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.7033 - val_loss: 0.5743 - val_accuracy: 0.6979\n",
            "Epoch 26/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5778 - accuracy: 0.7033 - val_loss: 0.5727 - val_accuracy: 0.7000\n",
            "Epoch 27/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5760 - accuracy: 0.7087 - val_loss: 0.5717 - val_accuracy: 0.7063\n",
            "Epoch 28/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5745 - accuracy: 0.7113 - val_loss: 0.5710 - val_accuracy: 0.7083\n",
            "Epoch 29/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5727 - accuracy: 0.7140 - val_loss: 0.5706 - val_accuracy: 0.7104\n",
            "Epoch 30/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7131 - val_loss: 0.5690 - val_accuracy: 0.7125\n",
            "Epoch 31/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5699 - accuracy: 0.7176 - val_loss: 0.5677 - val_accuracy: 0.7125\n",
            "Epoch 32/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7203 - val_loss: 0.5667 - val_accuracy: 0.7125\n",
            "Epoch 33/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5670 - accuracy: 0.7221 - val_loss: 0.5660 - val_accuracy: 0.7042\n",
            "Epoch 34/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5657 - accuracy: 0.7239 - val_loss: 0.5653 - val_accuracy: 0.7063\n",
            "Epoch 35/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5645 - accuracy: 0.7256 - val_loss: 0.5647 - val_accuracy: 0.7042\n",
            "Epoch 36/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.7265 - val_loss: 0.5647 - val_accuracy: 0.7125\n",
            "Epoch 37/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5622 - accuracy: 0.7265 - val_loss: 0.5638 - val_accuracy: 0.7146\n",
            "Epoch 38/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5613 - accuracy: 0.7265 - val_loss: 0.5625 - val_accuracy: 0.7167\n",
            "Epoch 39/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5602 - accuracy: 0.7319 - val_loss: 0.5620 - val_accuracy: 0.7229\n",
            "Epoch 40/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5593 - accuracy: 0.7301 - val_loss: 0.5618 - val_accuracy: 0.7208\n",
            "Epoch 41/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.7364 - val_loss: 0.5611 - val_accuracy: 0.7250\n",
            "Epoch 42/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5572 - accuracy: 0.7382 - val_loss: 0.5609 - val_accuracy: 0.7250\n",
            "Epoch 43/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5563 - accuracy: 0.7382 - val_loss: 0.5609 - val_accuracy: 0.7250\n",
            "Epoch 44/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5555 - accuracy: 0.7382 - val_loss: 0.5599 - val_accuracy: 0.7208\n",
            "Epoch 45/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5545 - accuracy: 0.7373 - val_loss: 0.5583 - val_accuracy: 0.7271\n",
            "Epoch 46/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5532 - accuracy: 0.7408 - val_loss: 0.5573 - val_accuracy: 0.7250\n",
            "Epoch 47/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5523 - accuracy: 0.7426 - val_loss: 0.5569 - val_accuracy: 0.7292\n",
            "Epoch 48/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5513 - accuracy: 0.7426 - val_loss: 0.5562 - val_accuracy: 0.7292\n",
            "Epoch 49/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.7408 - val_loss: 0.5558 - val_accuracy: 0.7271\n",
            "Epoch 50/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7426 - val_loss: 0.5547 - val_accuracy: 0.7250\n",
            "Epoch 51/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5486 - accuracy: 0.7426 - val_loss: 0.5541 - val_accuracy: 0.7271\n",
            "Epoch 52/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5478 - accuracy: 0.7435 - val_loss: 0.5530 - val_accuracy: 0.7312\n",
            "Epoch 53/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5469 - accuracy: 0.7408 - val_loss: 0.5528 - val_accuracy: 0.7292\n",
            "Epoch 54/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.7408 - val_loss: 0.5523 - val_accuracy: 0.7354\n",
            "Epoch 55/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7417 - val_loss: 0.5520 - val_accuracy: 0.7271\n",
            "Epoch 56/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.7399 - val_loss: 0.5513 - val_accuracy: 0.7354\n",
            "Epoch 57/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.7426 - val_loss: 0.5510 - val_accuracy: 0.7250\n",
            "Epoch 58/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.7417 - val_loss: 0.5508 - val_accuracy: 0.7271\n",
            "Epoch 59/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5417 - accuracy: 0.7408 - val_loss: 0.5500 - val_accuracy: 0.7354\n",
            "Epoch 60/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5408 - accuracy: 0.7391 - val_loss: 0.5501 - val_accuracy: 0.7333\n",
            "Epoch 61/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7408 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
            "Epoch 62/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7382 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
            "Epoch 63/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5386 - accuracy: 0.7453 - val_loss: 0.5482 - val_accuracy: 0.7292\n",
            "Epoch 64/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.7453 - val_loss: 0.5480 - val_accuracy: 0.7292\n",
            "Epoch 65/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7435 - val_loss: 0.5471 - val_accuracy: 0.7312\n",
            "Epoch 66/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7426 - val_loss: 0.5469 - val_accuracy: 0.7312\n",
            "Epoch 67/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.7435 - val_loss: 0.5474 - val_accuracy: 0.7312\n",
            "Epoch 68/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7462 - val_loss: 0.5485 - val_accuracy: 0.7312\n",
            "Epoch 69/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5347 - accuracy: 0.7453 - val_loss: 0.5477 - val_accuracy: 0.7312\n",
            "Epoch 70/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5342 - accuracy: 0.7462 - val_loss: 0.5469 - val_accuracy: 0.7292\n",
            "Epoch 71/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.7444 - val_loss: 0.5455 - val_accuracy: 0.7312\n",
            "Epoch 72/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7462 - val_loss: 0.5446 - val_accuracy: 0.7333\n",
            "Epoch 73/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.7462 - val_loss: 0.5441 - val_accuracy: 0.7396\n",
            "Epoch 74/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5320 - accuracy: 0.7444 - val_loss: 0.5441 - val_accuracy: 0.7375\n",
            "Epoch 75/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7462 - val_loss: 0.5432 - val_accuracy: 0.7396\n",
            "Epoch 76/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.7471 - val_loss: 0.5426 - val_accuracy: 0.7417\n",
            "Epoch 77/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.7462 - val_loss: 0.5432 - val_accuracy: 0.7417\n",
            "Epoch 78/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.7444 - val_loss: 0.5430 - val_accuracy: 0.7396\n",
            "Epoch 79/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.7471 - val_loss: 0.5425 - val_accuracy: 0.7437\n",
            "Epoch 80/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5288 - accuracy: 0.7444 - val_loss: 0.5436 - val_accuracy: 0.7437\n",
            "Epoch 81/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7435 - val_loss: 0.5431 - val_accuracy: 0.7458\n",
            "Epoch 82/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7435 - val_loss: 0.5420 - val_accuracy: 0.7458\n",
            "Epoch 83/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5276 - accuracy: 0.7435 - val_loss: 0.5415 - val_accuracy: 0.7458\n",
            "Epoch 84/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.7444 - val_loss: 0.5406 - val_accuracy: 0.7437\n",
            "Epoch 85/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7498 - val_loss: 0.5397 - val_accuracy: 0.7417\n",
            "Epoch 86/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7507 - val_loss: 0.5405 - val_accuracy: 0.7417\n",
            "Epoch 87/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.7498 - val_loss: 0.5407 - val_accuracy: 0.7396\n",
            "Epoch 88/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7480 - val_loss: 0.5395 - val_accuracy: 0.7396\n",
            "Epoch 89/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7462 - val_loss: 0.5385 - val_accuracy: 0.7396\n",
            "Epoch 90/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5249 - accuracy: 0.7471 - val_loss: 0.5396 - val_accuracy: 0.7375\n",
            "Epoch 91/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7462 - val_loss: 0.5390 - val_accuracy: 0.7396\n",
            "Epoch 92/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5240 - accuracy: 0.7525 - val_loss: 0.5388 - val_accuracy: 0.7375\n",
            "Epoch 93/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7534 - val_loss: 0.5387 - val_accuracy: 0.7354\n",
            "Epoch 94/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7534 - val_loss: 0.5393 - val_accuracy: 0.7375\n",
            "Epoch 95/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7507 - val_loss: 0.5379 - val_accuracy: 0.7333\n",
            "Epoch 96/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5227 - accuracy: 0.7525 - val_loss: 0.5381 - val_accuracy: 0.7333\n",
            "Epoch 97/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.7525 - val_loss: 0.5379 - val_accuracy: 0.7333\n",
            "Epoch 98/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7525 - val_loss: 0.5385 - val_accuracy: 0.7312\n",
            "Epoch 99/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.7525 - val_loss: 0.5380 - val_accuracy: 0.7312\n",
            "Epoch 100/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.7542 - val_loss: 0.5370 - val_accuracy: 0.7333\n",
            "Epoch 101/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7507 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
            "Epoch 102/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7516 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
            "Epoch 103/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7507 - val_loss: 0.5360 - val_accuracy: 0.7312\n",
            "Epoch 104/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7516 - val_loss: 0.5351 - val_accuracy: 0.7312\n",
            "Epoch 105/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7480 - val_loss: 0.5354 - val_accuracy: 0.7312\n",
            "Epoch 106/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.7480 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
            "Epoch 107/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.7462 - val_loss: 0.5358 - val_accuracy: 0.7375\n",
            "Epoch 108/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.7462 - val_loss: 0.5340 - val_accuracy: 0.7312\n",
            "Epoch 109/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7489 - val_loss: 0.5338 - val_accuracy: 0.7271\n",
            "Epoch 110/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7507 - val_loss: 0.5344 - val_accuracy: 0.7292\n",
            "Epoch 111/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7480 - val_loss: 0.5347 - val_accuracy: 0.7312\n",
            "Epoch 112/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7471 - val_loss: 0.5343 - val_accuracy: 0.7333\n",
            "Epoch 113/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7507 - val_loss: 0.5340 - val_accuracy: 0.7333\n",
            "Epoch 114/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5168 - accuracy: 0.7516 - val_loss: 0.5335 - val_accuracy: 0.7292\n",
            "Epoch 115/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7542 - val_loss: 0.5337 - val_accuracy: 0.7292\n",
            "Epoch 116/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7498 - val_loss: 0.5341 - val_accuracy: 0.7312\n",
            "Epoch 117/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7480 - val_loss: 0.5345 - val_accuracy: 0.7312\n",
            "Epoch 118/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7525 - val_loss: 0.5337 - val_accuracy: 0.7333\n",
            "Epoch 119/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7525 - val_loss: 0.5324 - val_accuracy: 0.7375\n",
            "Epoch 120/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7551 - val_loss: 0.5318 - val_accuracy: 0.7354\n",
            "Epoch 121/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5148 - accuracy: 0.7551 - val_loss: 0.5320 - val_accuracy: 0.7312\n",
            "Epoch 122/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5143 - accuracy: 0.7551 - val_loss: 0.5309 - val_accuracy: 0.7396\n",
            "Epoch 123/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7578 - val_loss: 0.5312 - val_accuracy: 0.7333\n",
            "Epoch 124/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7578 - val_loss: 0.5314 - val_accuracy: 0.7375\n",
            "Epoch 125/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7596 - val_loss: 0.5305 - val_accuracy: 0.7375\n",
            "Epoch 126/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.7578 - val_loss: 0.5309 - val_accuracy: 0.7375\n",
            "Epoch 127/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7569 - val_loss: 0.5310 - val_accuracy: 0.7354\n",
            "Epoch 128/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7605 - val_loss: 0.5297 - val_accuracy: 0.7396\n",
            "Epoch 129/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7605 - val_loss: 0.5297 - val_accuracy: 0.7396\n",
            "Epoch 130/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7596 - val_loss: 0.5296 - val_accuracy: 0.7417\n",
            "Epoch 131/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7587 - val_loss: 0.5307 - val_accuracy: 0.7396\n",
            "Epoch 132/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7587 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
            "Epoch 133/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7596 - val_loss: 0.5300 - val_accuracy: 0.7417\n",
            "Epoch 134/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7578 - val_loss: 0.5301 - val_accuracy: 0.7417\n",
            "Epoch 135/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7596 - val_loss: 0.5279 - val_accuracy: 0.7437\n",
            "Epoch 136/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7551 - val_loss: 0.5312 - val_accuracy: 0.7396\n",
            "Epoch 137/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7578 - val_loss: 0.5292 - val_accuracy: 0.7458\n",
            "Epoch 138/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7587 - val_loss: 0.5292 - val_accuracy: 0.7437\n",
            "Epoch 139/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7578 - val_loss: 0.5285 - val_accuracy: 0.7437\n",
            "Epoch 140/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5063 - accuracy: 0.7587 - val_loss: 0.5290 - val_accuracy: 0.7437\n",
            "Epoch 141/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7569 - val_loss: 0.5282 - val_accuracy: 0.7437\n",
            "Epoch 142/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7560 - val_loss: 0.5289 - val_accuracy: 0.7437\n",
            "Epoch 143/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7578 - val_loss: 0.5284 - val_accuracy: 0.7479\n",
            "Epoch 144/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7578 - val_loss: 0.5296 - val_accuracy: 0.7437\n",
            "Epoch 145/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5040 - accuracy: 0.7578 - val_loss: 0.5286 - val_accuracy: 0.7479\n",
            "Epoch 146/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7605 - val_loss: 0.5285 - val_accuracy: 0.7437\n",
            "Epoch 147/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7605 - val_loss: 0.5285 - val_accuracy: 0.7437\n",
            "Epoch 148/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7596 - val_loss: 0.5282 - val_accuracy: 0.7458\n",
            "Epoch 149/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7605 - val_loss: 0.5276 - val_accuracy: 0.7458\n",
            "Epoch 150/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5020 - accuracy: 0.7614 - val_loss: 0.5289 - val_accuracy: 0.7521\n",
            "Epoch 151/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.7623 - val_loss: 0.5271 - val_accuracy: 0.7521\n",
            "Epoch 152/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7605 - val_loss: 0.5283 - val_accuracy: 0.7563\n",
            "Epoch 153/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7659 - val_loss: 0.5261 - val_accuracy: 0.7563\n",
            "Epoch 154/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.7650 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
            "Epoch 155/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.7632 - val_loss: 0.5261 - val_accuracy: 0.7479\n",
            "Epoch 156/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.7641 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 157/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7632 - val_loss: 0.5243 - val_accuracy: 0.7500\n",
            "Epoch 158/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7632 - val_loss: 0.5234 - val_accuracy: 0.7563\n",
            "Epoch 159/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7659 - val_loss: 0.5255 - val_accuracy: 0.7542\n",
            "Epoch 160/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4985 - accuracy: 0.7623 - val_loss: 0.5275 - val_accuracy: 0.7500\n",
            "Epoch 161/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.7596 - val_loss: 0.5251 - val_accuracy: 0.7604\n",
            "Epoch 162/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.7650 - val_loss: 0.5250 - val_accuracy: 0.7583\n",
            "Epoch 163/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.7632 - val_loss: 0.5272 - val_accuracy: 0.7583\n",
            "Epoch 164/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.7632 - val_loss: 0.5263 - val_accuracy: 0.7563\n",
            "Epoch 165/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.7641 - val_loss: 0.5258 - val_accuracy: 0.7563\n",
            "Epoch 166/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4964 - accuracy: 0.7676 - val_loss: 0.5243 - val_accuracy: 0.7604\n",
            "Epoch 167/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.7668 - val_loss: 0.5246 - val_accuracy: 0.7583\n",
            "Epoch 168/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.7668 - val_loss: 0.5259 - val_accuracy: 0.7563\n",
            "Epoch 169/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4952 - accuracy: 0.7668 - val_loss: 0.5243 - val_accuracy: 0.7604\n",
            "Epoch 170/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.7694 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
            "Epoch 171/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.7694 - val_loss: 0.5230 - val_accuracy: 0.7646\n",
            "Epoch 172/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.7703 - val_loss: 0.5219 - val_accuracy: 0.7667\n",
            "Epoch 173/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7712 - val_loss: 0.5225 - val_accuracy: 0.7688\n",
            "Epoch 174/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7730 - val_loss: 0.5216 - val_accuracy: 0.7729\n",
            "Epoch 175/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.7712 - val_loss: 0.5224 - val_accuracy: 0.7688\n",
            "Epoch 176/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.7721 - val_loss: 0.5245 - val_accuracy: 0.7625\n",
            "Epoch 177/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7703 - val_loss: 0.5231 - val_accuracy: 0.7646\n",
            "Epoch 178/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4929 - accuracy: 0.7712 - val_loss: 0.5237 - val_accuracy: 0.7604\n",
            "Epoch 179/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4924 - accuracy: 0.7730 - val_loss: 0.5226 - val_accuracy: 0.7667\n",
            "Epoch 180/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.7659 - val_loss: 0.5207 - val_accuracy: 0.7708\n",
            "Epoch 181/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.7730 - val_loss: 0.5210 - val_accuracy: 0.7729\n",
            "Epoch 182/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.7739 - val_loss: 0.5223 - val_accuracy: 0.7604\n",
            "Epoch 183/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4911 - accuracy: 0.7721 - val_loss: 0.5222 - val_accuracy: 0.7708\n",
            "Epoch 184/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.7739 - val_loss: 0.5240 - val_accuracy: 0.7604\n",
            "Epoch 185/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.7739 - val_loss: 0.5254 - val_accuracy: 0.7708\n",
            "Epoch 186/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7739 - val_loss: 0.5261 - val_accuracy: 0.7688\n",
            "Epoch 187/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4903 - accuracy: 0.7730 - val_loss: 0.5251 - val_accuracy: 0.7646\n",
            "Epoch 188/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4900 - accuracy: 0.7757 - val_loss: 0.5230 - val_accuracy: 0.7667\n",
            "Epoch 189/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4894 - accuracy: 0.7739 - val_loss: 0.5223 - val_accuracy: 0.7625\n",
            "Epoch 190/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4889 - accuracy: 0.7739 - val_loss: 0.5240 - val_accuracy: 0.7667\n",
            "Epoch 191/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4889 - accuracy: 0.7721 - val_loss: 0.5253 - val_accuracy: 0.7563\n",
            "Epoch 192/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4882 - accuracy: 0.7721 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
            "Epoch 193/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4882 - accuracy: 0.7757 - val_loss: 0.5225 - val_accuracy: 0.7646\n",
            "Epoch 194/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4879 - accuracy: 0.7748 - val_loss: 0.5240 - val_accuracy: 0.7646\n",
            "Epoch 195/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4876 - accuracy: 0.7748 - val_loss: 0.5245 - val_accuracy: 0.7604\n",
            "Epoch 196/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4872 - accuracy: 0.7739 - val_loss: 0.5248 - val_accuracy: 0.7604\n",
            "Epoch 197/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4872 - accuracy: 0.7739 - val_loss: 0.5242 - val_accuracy: 0.7688\n",
            "Epoch 198/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4868 - accuracy: 0.7739 - val_loss: 0.5245 - val_accuracy: 0.7646\n",
            "Epoch 199/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4867 - accuracy: 0.7721 - val_loss: 0.5244 - val_accuracy: 0.7646\n",
            "Epoch 200/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4862 - accuracy: 0.7721 - val_loss: 0.5245 - val_accuracy: 0.7646\n",
            "Epoch 201/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4860 - accuracy: 0.7721 - val_loss: 0.5242 - val_accuracy: 0.7604\n",
            "Epoch 202/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4857 - accuracy: 0.7721 - val_loss: 0.5249 - val_accuracy: 0.7583\n",
            "Epoch 203/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.4855 - accuracy: 0.7712 - val_loss: 0.5258 - val_accuracy: 0.7542\n",
            "Epoch 204/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.4857 - accuracy: 0.7721 - val_loss: 0.5246 - val_accuracy: 0.7583\n",
            "Epoch 205/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4854 - accuracy: 0.7730 - val_loss: 0.5237 - val_accuracy: 0.7667\n",
            "Epoch 206/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4850 - accuracy: 0.7739 - val_loss: 0.5250 - val_accuracy: 0.7563\n",
            "Epoch 207/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4845 - accuracy: 0.7766 - val_loss: 0.5255 - val_accuracy: 0.7583\n",
            "Epoch 208/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7748 - val_loss: 0.5282 - val_accuracy: 0.7563\n",
            "Epoch 209/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7748 - val_loss: 0.5280 - val_accuracy: 0.7563\n",
            "Epoch 210/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4837 - accuracy: 0.7730 - val_loss: 0.5267 - val_accuracy: 0.7542\n",
            "Epoch 211/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4834 - accuracy: 0.7721 - val_loss: 0.5264 - val_accuracy: 0.7542\n",
            "Epoch 212/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4831 - accuracy: 0.7721 - val_loss: 0.5262 - val_accuracy: 0.7563\n",
            "Epoch 213/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4831 - accuracy: 0.7739 - val_loss: 0.5260 - val_accuracy: 0.7688\n",
            "Epoch 214/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4830 - accuracy: 0.7775 - val_loss: 0.5261 - val_accuracy: 0.7688\n",
            "Epoch 215/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4826 - accuracy: 0.7766 - val_loss: 0.5283 - val_accuracy: 0.7521\n",
            "Epoch 216/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4823 - accuracy: 0.7730 - val_loss: 0.5293 - val_accuracy: 0.7521\n",
            "Epoch 217/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4823 - accuracy: 0.7748 - val_loss: 0.5303 - val_accuracy: 0.7563\n",
            "Epoch 218/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4820 - accuracy: 0.7748 - val_loss: 0.5284 - val_accuracy: 0.7542\n",
            "Epoch 219/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4815 - accuracy: 0.7739 - val_loss: 0.5260 - val_accuracy: 0.7625\n",
            "Epoch 220/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4814 - accuracy: 0.7766 - val_loss: 0.5260 - val_accuracy: 0.7604\n",
            "Epoch 221/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4814 - accuracy: 0.7766 - val_loss: 0.5285 - val_accuracy: 0.7583\n",
            "Epoch 222/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4807 - accuracy: 0.7775 - val_loss: 0.5277 - val_accuracy: 0.7646\n",
            "Epoch 223/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4808 - accuracy: 0.7775 - val_loss: 0.5278 - val_accuracy: 0.7688\n",
            "Epoch 224/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4806 - accuracy: 0.7802 - val_loss: 0.5291 - val_accuracy: 0.7667\n",
            "Epoch 225/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4802 - accuracy: 0.7793 - val_loss: 0.5300 - val_accuracy: 0.7604\n",
            "Epoch 226/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4800 - accuracy: 0.7775 - val_loss: 0.5300 - val_accuracy: 0.7521\n",
            "Epoch 227/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4801 - accuracy: 0.7837 - val_loss: 0.5288 - val_accuracy: 0.7625\n",
            "Epoch 228/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4793 - accuracy: 0.7855 - val_loss: 0.5328 - val_accuracy: 0.7479\n",
            "Epoch 229/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4804 - accuracy: 0.7811 - val_loss: 0.5325 - val_accuracy: 0.7521\n",
            "Epoch 230/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4798 - accuracy: 0.7819 - val_loss: 0.5298 - val_accuracy: 0.7583\n",
            "Epoch 231/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4787 - accuracy: 0.7819 - val_loss: 0.5278 - val_accuracy: 0.7625\n",
            "Epoch 232/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.7837 - val_loss: 0.5282 - val_accuracy: 0.7563\n",
            "Epoch 233/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4784 - accuracy: 0.7828 - val_loss: 0.5303 - val_accuracy: 0.7542\n",
            "Epoch 234/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4785 - accuracy: 0.7837 - val_loss: 0.5288 - val_accuracy: 0.7604\n",
            "Epoch 235/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4778 - accuracy: 0.7846 - val_loss: 0.5292 - val_accuracy: 0.7604\n",
            "Epoch 236/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4775 - accuracy: 0.7837 - val_loss: 0.5301 - val_accuracy: 0.7583\n",
            "Epoch 237/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4772 - accuracy: 0.7802 - val_loss: 0.5307 - val_accuracy: 0.7542\n",
            "Epoch 238/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4770 - accuracy: 0.7811 - val_loss: 0.5288 - val_accuracy: 0.7563\n",
            "Epoch 239/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4766 - accuracy: 0.7819 - val_loss: 0.5312 - val_accuracy: 0.7521\n",
            "Epoch 240/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.7837 - val_loss: 0.5301 - val_accuracy: 0.7500\n",
            "Epoch 241/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4761 - accuracy: 0.7846 - val_loss: 0.5295 - val_accuracy: 0.7583\n",
            "Epoch 242/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4761 - accuracy: 0.7819 - val_loss: 0.5301 - val_accuracy: 0.7521\n",
            "Epoch 243/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7819 - val_loss: 0.5294 - val_accuracy: 0.7563\n",
            "Epoch 244/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7811 - val_loss: 0.5290 - val_accuracy: 0.7583\n",
            "Epoch 245/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7819 - val_loss: 0.5298 - val_accuracy: 0.7604\n",
            "Epoch 246/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4750 - accuracy: 0.7846 - val_loss: 0.5325 - val_accuracy: 0.7542\n",
            "Epoch 247/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7828 - val_loss: 0.5309 - val_accuracy: 0.7542\n",
            "Epoch 248/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4746 - accuracy: 0.7802 - val_loss: 0.5307 - val_accuracy: 0.7521\n",
            "Epoch 249/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7819 - val_loss: 0.5293 - val_accuracy: 0.7563\n",
            "Epoch 250/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7837 - val_loss: 0.5292 - val_accuracy: 0.7500\n",
            "Epoch 251/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7846 - val_loss: 0.5298 - val_accuracy: 0.7542\n",
            "Epoch 252/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7837 - val_loss: 0.5318 - val_accuracy: 0.7563\n",
            "Epoch 253/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4735 - accuracy: 0.7855 - val_loss: 0.5313 - val_accuracy: 0.7542\n",
            "Epoch 254/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7837 - val_loss: 0.5325 - val_accuracy: 0.7542\n",
            "Epoch 255/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7837 - val_loss: 0.5314 - val_accuracy: 0.7500\n",
            "Epoch 256/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7802 - val_loss: 0.5307 - val_accuracy: 0.7521\n",
            "Epoch 257/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7793 - val_loss: 0.5305 - val_accuracy: 0.7542\n",
            "Epoch 258/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7811 - val_loss: 0.5322 - val_accuracy: 0.7521\n",
            "Epoch 259/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7811 - val_loss: 0.5313 - val_accuracy: 0.7521\n",
            "Epoch 260/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7811 - val_loss: 0.5327 - val_accuracy: 0.7542\n",
            "Epoch 261/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7811 - val_loss: 0.5334 - val_accuracy: 0.7542\n",
            "Epoch 262/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7811 - val_loss: 0.5318 - val_accuracy: 0.7542\n",
            "Epoch 263/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7811 - val_loss: 0.5322 - val_accuracy: 0.7542\n",
            "Epoch 264/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7811 - val_loss: 0.5328 - val_accuracy: 0.7542\n",
            "Epoch 265/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4708 - accuracy: 0.7819 - val_loss: 0.5327 - val_accuracy: 0.7542\n",
            "Epoch 266/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7811 - val_loss: 0.5327 - val_accuracy: 0.7542\n",
            "Epoch 267/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7819 - val_loss: 0.5339 - val_accuracy: 0.7563\n",
            "Epoch 268/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7819 - val_loss: 0.5348 - val_accuracy: 0.7542\n",
            "Epoch 269/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7837 - val_loss: 0.5354 - val_accuracy: 0.7521\n",
            "Epoch 270/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7811 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
            "Epoch 271/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4693 - accuracy: 0.7811 - val_loss: 0.5334 - val_accuracy: 0.7583\n",
            "Epoch 272/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7819 - val_loss: 0.5347 - val_accuracy: 0.7563\n",
            "Epoch 273/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7819 - val_loss: 0.5354 - val_accuracy: 0.7521\n",
            "Epoch 274/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.7793 - val_loss: 0.5352 - val_accuracy: 0.7521\n",
            "Epoch 275/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7828 - val_loss: 0.5330 - val_accuracy: 0.7521\n",
            "Epoch 276/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7855 - val_loss: 0.5337 - val_accuracy: 0.7521\n",
            "Epoch 277/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7802 - val_loss: 0.5366 - val_accuracy: 0.7500\n",
            "Epoch 278/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7766 - val_loss: 0.5404 - val_accuracy: 0.7521\n",
            "Epoch 279/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7793 - val_loss: 0.5387 - val_accuracy: 0.7458\n",
            "Epoch 280/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7793 - val_loss: 0.5377 - val_accuracy: 0.7458\n",
            "Epoch 281/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7793 - val_loss: 0.5383 - val_accuracy: 0.7479\n",
            "Epoch 282/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7784 - val_loss: 0.5394 - val_accuracy: 0.7521\n",
            "Epoch 283/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7757 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
            "Epoch 284/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7748 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
            "Epoch 285/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.7766 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
            "Epoch 286/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.7748 - val_loss: 0.5385 - val_accuracy: 0.7500\n",
            "Epoch 287/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7757 - val_loss: 0.5387 - val_accuracy: 0.7521\n",
            "Epoch 288/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4646 - accuracy: 0.7775 - val_loss: 0.5411 - val_accuracy: 0.7521\n",
            "Epoch 289/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4643 - accuracy: 0.7766 - val_loss: 0.5399 - val_accuracy: 0.7521\n",
            "Epoch 290/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4644 - accuracy: 0.7784 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
            "Epoch 291/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4640 - accuracy: 0.7811 - val_loss: 0.5411 - val_accuracy: 0.7521\n",
            "Epoch 292/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4639 - accuracy: 0.7819 - val_loss: 0.5399 - val_accuracy: 0.7542\n",
            "Epoch 293/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4638 - accuracy: 0.7837 - val_loss: 0.5402 - val_accuracy: 0.7542\n",
            "Epoch 294/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4633 - accuracy: 0.7855 - val_loss: 0.5422 - val_accuracy: 0.7563\n",
            "Epoch 295/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4633 - accuracy: 0.7828 - val_loss: 0.5411 - val_accuracy: 0.7542\n",
            "Epoch 296/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4631 - accuracy: 0.7828 - val_loss: 0.5416 - val_accuracy: 0.7542\n",
            "Epoch 297/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4632 - accuracy: 0.7837 - val_loss: 0.5412 - val_accuracy: 0.7542\n",
            "Epoch 298/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4627 - accuracy: 0.7837 - val_loss: 0.5428 - val_accuracy: 0.7521\n",
            "Epoch 299/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4624 - accuracy: 0.7837 - val_loss: 0.5414 - val_accuracy: 0.7542\n",
            "Epoch 300/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4626 - accuracy: 0.7837 - val_loss: 0.5422 - val_accuracy: 0.7521\n",
            "Epoch 301/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4622 - accuracy: 0.7802 - val_loss: 0.5428 - val_accuracy: 0.7500\n",
            "Epoch 302/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4621 - accuracy: 0.7802 - val_loss: 0.5420 - val_accuracy: 0.7521\n",
            "Epoch 303/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4624 - accuracy: 0.7846 - val_loss: 0.5464 - val_accuracy: 0.7458\n",
            "Epoch 304/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4618 - accuracy: 0.7828 - val_loss: 0.5433 - val_accuracy: 0.7542\n",
            "Epoch 305/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.7882 - val_loss: 0.5429 - val_accuracy: 0.7521\n",
            "Epoch 306/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4613 - accuracy: 0.7882 - val_loss: 0.5441 - val_accuracy: 0.7521\n",
            "Epoch 307/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4615 - accuracy: 0.7855 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
            "Epoch 308/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4617 - accuracy: 0.7819 - val_loss: 0.5465 - val_accuracy: 0.7542\n",
            "Epoch 309/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4615 - accuracy: 0.7811 - val_loss: 0.5457 - val_accuracy: 0.7521\n",
            "Epoch 310/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.7811 - val_loss: 0.5463 - val_accuracy: 0.7521\n",
            "Epoch 311/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4608 - accuracy: 0.7828 - val_loss: 0.5442 - val_accuracy: 0.7500\n",
            "Epoch 312/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7855 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
            "Epoch 313/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7864 - val_loss: 0.5442 - val_accuracy: 0.7500\n",
            "Epoch 314/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7882 - val_loss: 0.5438 - val_accuracy: 0.7542\n",
            "Epoch 315/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7846 - val_loss: 0.5437 - val_accuracy: 0.7542\n",
            "Epoch 316/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7855 - val_loss: 0.5447 - val_accuracy: 0.7563\n",
            "Epoch 317/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7864 - val_loss: 0.5443 - val_accuracy: 0.7542\n",
            "Epoch 318/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7909 - val_loss: 0.5431 - val_accuracy: 0.7542\n",
            "Epoch 319/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7918 - val_loss: 0.5433 - val_accuracy: 0.7521\n",
            "Epoch 320/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7927 - val_loss: 0.5431 - val_accuracy: 0.7542\n",
            "Epoch 321/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4597 - accuracy: 0.7909 - val_loss: 0.5443 - val_accuracy: 0.7542\n",
            "Epoch 322/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7918 - val_loss: 0.5458 - val_accuracy: 0.7542\n",
            "Epoch 323/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7900 - val_loss: 0.5474 - val_accuracy: 0.7458\n",
            "Epoch 324/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7909 - val_loss: 0.5444 - val_accuracy: 0.7521\n",
            "Epoch 325/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7918 - val_loss: 0.5460 - val_accuracy: 0.7479\n",
            "Epoch 326/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7891 - val_loss: 0.5468 - val_accuracy: 0.7542\n",
            "Epoch 327/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7891 - val_loss: 0.5446 - val_accuracy: 0.7521\n",
            "Epoch 328/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7900 - val_loss: 0.5429 - val_accuracy: 0.7521\n",
            "Epoch 329/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7882 - val_loss: 0.5469 - val_accuracy: 0.7521\n",
            "Epoch 330/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7864 - val_loss: 0.5466 - val_accuracy: 0.7521\n",
            "Epoch 331/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7900 - val_loss: 0.5457 - val_accuracy: 0.7521\n",
            "Epoch 332/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7855 - val_loss: 0.5452 - val_accuracy: 0.7542\n",
            "Epoch 333/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7855 - val_loss: 0.5457 - val_accuracy: 0.7542\n",
            "Epoch 334/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7846 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
            "Epoch 335/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7864 - val_loss: 0.5448 - val_accuracy: 0.7542\n",
            "Epoch 336/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7918 - val_loss: 0.5446 - val_accuracy: 0.7521\n",
            "Epoch 337/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7918 - val_loss: 0.5440 - val_accuracy: 0.7521\n",
            "Epoch 338/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7909 - val_loss: 0.5452 - val_accuracy: 0.7479\n",
            "Epoch 339/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7936 - val_loss: 0.5452 - val_accuracy: 0.7479\n",
            "Epoch 340/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7909 - val_loss: 0.5443 - val_accuracy: 0.7542\n",
            "Epoch 341/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7873 - val_loss: 0.5457 - val_accuracy: 0.7521\n",
            "Epoch 342/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7891 - val_loss: 0.5460 - val_accuracy: 0.7521\n",
            "Epoch 343/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7873 - val_loss: 0.5471 - val_accuracy: 0.7521\n",
            "Epoch 344/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7900 - val_loss: 0.5470 - val_accuracy: 0.7583\n",
            "Epoch 345/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7882 - val_loss: 0.5470 - val_accuracy: 0.7604\n",
            "Epoch 346/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7927 - val_loss: 0.5448 - val_accuracy: 0.7563\n",
            "Epoch 347/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7891 - val_loss: 0.5454 - val_accuracy: 0.7542\n",
            "Epoch 348/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7909 - val_loss: 0.5469 - val_accuracy: 0.7521\n",
            "Epoch 349/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7936 - val_loss: 0.5477 - val_accuracy: 0.7500\n",
            "Epoch 350/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7909 - val_loss: 0.5472 - val_accuracy: 0.7500\n",
            "Epoch 351/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7900 - val_loss: 0.5463 - val_accuracy: 0.7521\n",
            "Epoch 352/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.7891 - val_loss: 0.5448 - val_accuracy: 0.7500\n",
            "Epoch 353/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7909 - val_loss: 0.5437 - val_accuracy: 0.7542\n",
            "Epoch 354/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7909 - val_loss: 0.5462 - val_accuracy: 0.7521\n",
            "Epoch 355/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7927 - val_loss: 0.5468 - val_accuracy: 0.7521\n",
            "Epoch 356/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7927 - val_loss: 0.5493 - val_accuracy: 0.7542\n",
            "Epoch 357/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7945 - val_loss: 0.5478 - val_accuracy: 0.7521\n",
            "Epoch 358/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7900 - val_loss: 0.5447 - val_accuracy: 0.7583\n",
            "Epoch 359/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7855 - val_loss: 0.5457 - val_accuracy: 0.7521\n",
            "Epoch 360/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7918 - val_loss: 0.5469 - val_accuracy: 0.7521\n",
            "Epoch 361/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7909 - val_loss: 0.5476 - val_accuracy: 0.7521\n",
            "Epoch 362/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7882 - val_loss: 0.5473 - val_accuracy: 0.7521\n",
            "Epoch 363/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7846 - val_loss: 0.5475 - val_accuracy: 0.7521\n",
            "Epoch 364/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7837 - val_loss: 0.5468 - val_accuracy: 0.7521\n",
            "Epoch 365/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4552 - accuracy: 0.7882 - val_loss: 0.5458 - val_accuracy: 0.7500\n",
            "Epoch 366/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4551 - accuracy: 0.7882 - val_loss: 0.5490 - val_accuracy: 0.7521\n",
            "Epoch 367/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7900 - val_loss: 0.5508 - val_accuracy: 0.7563\n",
            "Epoch 368/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7882 - val_loss: 0.5516 - val_accuracy: 0.7563\n",
            "Epoch 369/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7918 - val_loss: 0.5476 - val_accuracy: 0.7563\n",
            "Epoch 370/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7936 - val_loss: 0.5472 - val_accuracy: 0.7563\n",
            "Epoch 371/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7918 - val_loss: 0.5465 - val_accuracy: 0.7542\n",
            "Epoch 372/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7945 - val_loss: 0.5468 - val_accuracy: 0.7542\n",
            "Epoch 373/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.7936 - val_loss: 0.5458 - val_accuracy: 0.7563\n",
            "Epoch 374/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.7918 - val_loss: 0.5444 - val_accuracy: 0.7542\n",
            "Epoch 375/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7891 - val_loss: 0.5465 - val_accuracy: 0.7583\n",
            "Epoch 376/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7891 - val_loss: 0.5480 - val_accuracy: 0.7563\n",
            "Epoch 377/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4537 - accuracy: 0.7891 - val_loss: 0.5489 - val_accuracy: 0.7500\n",
            "Epoch 378/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7882 - val_loss: 0.5496 - val_accuracy: 0.7500\n",
            "Epoch 379/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.7891 - val_loss: 0.5469 - val_accuracy: 0.7521\n",
            "Epoch 380/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4537 - accuracy: 0.7891 - val_loss: 0.5467 - val_accuracy: 0.7521\n",
            "Epoch 381/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.7927 - val_loss: 0.5483 - val_accuracy: 0.7500\n",
            "Epoch 382/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7900 - val_loss: 0.5486 - val_accuracy: 0.7521\n",
            "Epoch 383/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.7909 - val_loss: 0.5487 - val_accuracy: 0.7500\n",
            "Epoch 384/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7900 - val_loss: 0.5483 - val_accuracy: 0.7479\n",
            "Epoch 385/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7945 - val_loss: 0.5494 - val_accuracy: 0.7479\n",
            "Epoch 386/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.7945 - val_loss: 0.5499 - val_accuracy: 0.7500\n",
            "Epoch 387/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7918 - val_loss: 0.5491 - val_accuracy: 0.7458\n",
            "Epoch 388/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7918 - val_loss: 0.5495 - val_accuracy: 0.7479\n",
            "Epoch 389/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.7918 - val_loss: 0.5501 - val_accuracy: 0.7479\n",
            "Epoch 390/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7918 - val_loss: 0.5499 - val_accuracy: 0.7479\n",
            "Epoch 391/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7936 - val_loss: 0.5518 - val_accuracy: 0.7500\n",
            "Epoch 392/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7891 - val_loss: 0.5491 - val_accuracy: 0.7521\n",
            "Epoch 393/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7891 - val_loss: 0.5494 - val_accuracy: 0.7479\n",
            "Epoch 394/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7909 - val_loss: 0.5494 - val_accuracy: 0.7479\n",
            "Epoch 395/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7909 - val_loss: 0.5505 - val_accuracy: 0.7458\n",
            "Epoch 396/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7927 - val_loss: 0.5519 - val_accuracy: 0.7479\n",
            "Epoch 397/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.7918 - val_loss: 0.5507 - val_accuracy: 0.7458\n",
            "Epoch 398/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7927 - val_loss: 0.5507 - val_accuracy: 0.7458\n",
            "Epoch 399/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7918 - val_loss: 0.5532 - val_accuracy: 0.7458\n",
            "Epoch 400/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7891 - val_loss: 0.5526 - val_accuracy: 0.7479\n",
            "Epoch 401/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7909 - val_loss: 0.5497 - val_accuracy: 0.7458\n",
            "Epoch 402/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7891 - val_loss: 0.5485 - val_accuracy: 0.7437\n",
            "Epoch 403/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4521 - accuracy: 0.7900 - val_loss: 0.5511 - val_accuracy: 0.7458\n",
            "Epoch 404/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7909 - val_loss: 0.5535 - val_accuracy: 0.7479\n",
            "Epoch 405/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.7918 - val_loss: 0.5518 - val_accuracy: 0.7458\n",
            "Epoch 406/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7927 - val_loss: 0.5514 - val_accuracy: 0.7458\n",
            "Epoch 407/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7900 - val_loss: 0.5513 - val_accuracy: 0.7458\n",
            "Epoch 408/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.7909 - val_loss: 0.5509 - val_accuracy: 0.7458\n",
            "Epoch 409/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7882 - val_loss: 0.5512 - val_accuracy: 0.7458\n",
            "Epoch 410/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.7900 - val_loss: 0.5530 - val_accuracy: 0.7458\n",
            "Epoch 411/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7882 - val_loss: 0.5532 - val_accuracy: 0.7458\n",
            "Epoch 412/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7891 - val_loss: 0.5494 - val_accuracy: 0.7458\n",
            "Epoch 413/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7873 - val_loss: 0.5509 - val_accuracy: 0.7458\n",
            "Epoch 414/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7855 - val_loss: 0.5512 - val_accuracy: 0.7458\n",
            "Epoch 415/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7864 - val_loss: 0.5516 - val_accuracy: 0.7458\n",
            "Epoch 416/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7882 - val_loss: 0.5532 - val_accuracy: 0.7458\n",
            "Epoch 417/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4512 - accuracy: 0.7864 - val_loss: 0.5532 - val_accuracy: 0.7458\n",
            "Epoch 418/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7864 - val_loss: 0.5496 - val_accuracy: 0.7396\n",
            "Epoch 419/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7882 - val_loss: 0.5516 - val_accuracy: 0.7437\n",
            "Epoch 420/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7882 - val_loss: 0.5542 - val_accuracy: 0.7458\n",
            "Epoch 421/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7855 - val_loss: 0.5537 - val_accuracy: 0.7437\n",
            "Epoch 422/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7855 - val_loss: 0.5538 - val_accuracy: 0.7437\n",
            "Epoch 423/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7864 - val_loss: 0.5535 - val_accuracy: 0.7417\n",
            "Epoch 424/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7864 - val_loss: 0.5539 - val_accuracy: 0.7458\n",
            "Epoch 425/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7864 - val_loss: 0.5556 - val_accuracy: 0.7458\n",
            "Epoch 426/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7855 - val_loss: 0.5556 - val_accuracy: 0.7479\n",
            "Epoch 427/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7855 - val_loss: 0.5545 - val_accuracy: 0.7500\n",
            "Epoch 428/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7882 - val_loss: 0.5547 - val_accuracy: 0.7479\n",
            "Epoch 429/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7891 - val_loss: 0.5564 - val_accuracy: 0.7458\n",
            "Epoch 430/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7891 - val_loss: 0.5547 - val_accuracy: 0.7500\n",
            "Epoch 431/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7891 - val_loss: 0.5550 - val_accuracy: 0.7458\n",
            "Epoch 432/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7900 - val_loss: 0.5514 - val_accuracy: 0.7521\n",
            "Epoch 433/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7882 - val_loss: 0.5519 - val_accuracy: 0.7521\n",
            "Epoch 434/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.7873 - val_loss: 0.5553 - val_accuracy: 0.7500\n",
            "Epoch 435/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7936 - val_loss: 0.5590 - val_accuracy: 0.7458\n",
            "Epoch 436/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7927 - val_loss: 0.5566 - val_accuracy: 0.7458\n",
            "Epoch 437/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7909 - val_loss: 0.5540 - val_accuracy: 0.7479\n",
            "Epoch 438/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7891 - val_loss: 0.5543 - val_accuracy: 0.7479\n",
            "Epoch 439/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.7891 - val_loss: 0.5574 - val_accuracy: 0.7479\n",
            "Epoch 440/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.7873 - val_loss: 0.5568 - val_accuracy: 0.7500\n",
            "Epoch 441/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7918 - val_loss: 0.5558 - val_accuracy: 0.7479\n",
            "Epoch 442/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7918 - val_loss: 0.5551 - val_accuracy: 0.7479\n",
            "Epoch 443/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7891 - val_loss: 0.5545 - val_accuracy: 0.7458\n",
            "Epoch 444/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7891 - val_loss: 0.5555 - val_accuracy: 0.7437\n",
            "Epoch 445/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7936 - val_loss: 0.5540 - val_accuracy: 0.7437\n",
            "Epoch 446/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7936 - val_loss: 0.5532 - val_accuracy: 0.7417\n",
            "Epoch 447/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7918 - val_loss: 0.5549 - val_accuracy: 0.7417\n",
            "Epoch 448/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7909 - val_loss: 0.5556 - val_accuracy: 0.7417\n",
            "Epoch 449/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.7900 - val_loss: 0.5556 - val_accuracy: 0.7417\n",
            "Epoch 450/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7882 - val_loss: 0.5543 - val_accuracy: 0.7417\n",
            "Epoch 451/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7909 - val_loss: 0.5551 - val_accuracy: 0.7417\n",
            "Epoch 452/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7882 - val_loss: 0.5568 - val_accuracy: 0.7417\n",
            "Epoch 453/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7864 - val_loss: 0.5569 - val_accuracy: 0.7417\n",
            "Epoch 454/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7873 - val_loss: 0.5553 - val_accuracy: 0.7417\n",
            "Epoch 455/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7918 - val_loss: 0.5539 - val_accuracy: 0.7437\n",
            "Epoch 456/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4496 - accuracy: 0.7909 - val_loss: 0.5561 - val_accuracy: 0.7437\n",
            "Epoch 457/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7873 - val_loss: 0.5574 - val_accuracy: 0.7458\n",
            "Epoch 458/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7846 - val_loss: 0.5581 - val_accuracy: 0.7417\n",
            "Epoch 459/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7864 - val_loss: 0.5599 - val_accuracy: 0.7417\n",
            "Epoch 460/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7864 - val_loss: 0.5573 - val_accuracy: 0.7437\n",
            "Epoch 461/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7855 - val_loss: 0.5561 - val_accuracy: 0.7396\n",
            "Epoch 462/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7882 - val_loss: 0.5555 - val_accuracy: 0.7396\n",
            "Epoch 463/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7882 - val_loss: 0.5556 - val_accuracy: 0.7437\n",
            "Epoch 464/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7882 - val_loss: 0.5574 - val_accuracy: 0.7437\n",
            "Epoch 465/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7882 - val_loss: 0.5555 - val_accuracy: 0.7417\n",
            "Epoch 466/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7864 - val_loss: 0.5549 - val_accuracy: 0.7437\n",
            "Epoch 467/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7873 - val_loss: 0.5538 - val_accuracy: 0.7396\n",
            "Epoch 468/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7864 - val_loss: 0.5569 - val_accuracy: 0.7417\n",
            "Epoch 469/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.7882 - val_loss: 0.5576 - val_accuracy: 0.7437\n",
            "Epoch 470/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.7891 - val_loss: 0.5593 - val_accuracy: 0.7437\n",
            "Epoch 471/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7909 - val_loss: 0.5592 - val_accuracy: 0.7437\n",
            "Epoch 472/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7900 - val_loss: 0.5581 - val_accuracy: 0.7458\n",
            "Epoch 473/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7918 - val_loss: 0.5591 - val_accuracy: 0.7458\n",
            "Epoch 474/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7864 - val_loss: 0.5616 - val_accuracy: 0.7479\n",
            "Epoch 475/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7891 - val_loss: 0.5584 - val_accuracy: 0.7417\n",
            "Epoch 476/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7900 - val_loss: 0.5587 - val_accuracy: 0.7417\n",
            "Epoch 477/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7873 - val_loss: 0.5595 - val_accuracy: 0.7437\n",
            "Epoch 478/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4487 - accuracy: 0.7891 - val_loss: 0.5589 - val_accuracy: 0.7417\n",
            "Epoch 479/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7900 - val_loss: 0.5575 - val_accuracy: 0.7417\n",
            "Epoch 480/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7873 - val_loss: 0.5599 - val_accuracy: 0.7417\n",
            "Epoch 481/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7873 - val_loss: 0.5578 - val_accuracy: 0.7375\n",
            "Epoch 482/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4487 - accuracy: 0.7882 - val_loss: 0.5574 - val_accuracy: 0.7375\n",
            "Epoch 483/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7891 - val_loss: 0.5574 - val_accuracy: 0.7417\n",
            "Epoch 484/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7891 - val_loss: 0.5626 - val_accuracy: 0.7458\n",
            "Epoch 485/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7900 - val_loss: 0.5604 - val_accuracy: 0.7437\n",
            "Epoch 486/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7891 - val_loss: 0.5546 - val_accuracy: 0.7375\n",
            "Epoch 487/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7900 - val_loss: 0.5555 - val_accuracy: 0.7396\n",
            "Epoch 488/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.7891 - val_loss: 0.5566 - val_accuracy: 0.7396\n",
            "Epoch 489/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7909 - val_loss: 0.5584 - val_accuracy: 0.7375\n",
            "Epoch 490/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7918 - val_loss: 0.5606 - val_accuracy: 0.7437\n",
            "Epoch 491/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7927 - val_loss: 0.5580 - val_accuracy: 0.7417\n",
            "Epoch 492/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4484 - accuracy: 0.7900 - val_loss: 0.5561 - val_accuracy: 0.7458\n",
            "Epoch 493/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.7873 - val_loss: 0.5571 - val_accuracy: 0.7479\n",
            "Epoch 494/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7873 - val_loss: 0.5590 - val_accuracy: 0.7417\n",
            "Epoch 495/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7891 - val_loss: 0.5601 - val_accuracy: 0.7437\n",
            "Epoch 496/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7855 - val_loss: 0.5605 - val_accuracy: 0.7417\n",
            "Epoch 497/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7909 - val_loss: 0.5586 - val_accuracy: 0.7375\n",
            "Epoch 498/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7891 - val_loss: 0.5604 - val_accuracy: 0.7437\n",
            "Epoch 499/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7900 - val_loss: 0.5608 - val_accuracy: 0.7417\n",
            "Epoch 500/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.7900 - val_loss: 0.5610 - val_accuracy: 0.7417\n",
            "Epoch 501/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7900 - val_loss: 0.5644 - val_accuracy: 0.7417\n",
            "Epoch 502/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.7873 - val_loss: 0.5632 - val_accuracy: 0.7437\n",
            "Epoch 503/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7900 - val_loss: 0.5594 - val_accuracy: 0.7396\n",
            "Epoch 504/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7900 - val_loss: 0.5593 - val_accuracy: 0.7396\n",
            "Epoch 505/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7900 - val_loss: 0.5599 - val_accuracy: 0.7375\n",
            "Epoch 506/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7891 - val_loss: 0.5641 - val_accuracy: 0.7396\n",
            "Epoch 507/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7900 - val_loss: 0.5624 - val_accuracy: 0.7417\n",
            "Epoch 508/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7918 - val_loss: 0.5606 - val_accuracy: 0.7396\n",
            "Epoch 509/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7900 - val_loss: 0.5621 - val_accuracy: 0.7375\n",
            "Epoch 510/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7909 - val_loss: 0.5626 - val_accuracy: 0.7396\n",
            "Epoch 511/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7873 - val_loss: 0.5647 - val_accuracy: 0.7417\n",
            "Epoch 512/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4474 - accuracy: 0.7927 - val_loss: 0.5628 - val_accuracy: 0.7396\n",
            "Epoch 513/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4474 - accuracy: 0.7891 - val_loss: 0.5631 - val_accuracy: 0.7375\n",
            "Epoch 514/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7918 - val_loss: 0.5638 - val_accuracy: 0.7396\n",
            "Epoch 515/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7900 - val_loss: 0.5638 - val_accuracy: 0.7375\n",
            "Epoch 516/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7909 - val_loss: 0.5641 - val_accuracy: 0.7396\n",
            "Epoch 517/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7900 - val_loss: 0.5648 - val_accuracy: 0.7396\n",
            "Epoch 518/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7909 - val_loss: 0.5615 - val_accuracy: 0.7396\n",
            "Epoch 519/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.7909 - val_loss: 0.5638 - val_accuracy: 0.7396\n",
            "Epoch 520/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7909 - val_loss: 0.5629 - val_accuracy: 0.7375\n",
            "Epoch 521/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7927 - val_loss: 0.5620 - val_accuracy: 0.7396\n",
            "Epoch 522/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4474 - accuracy: 0.7918 - val_loss: 0.5636 - val_accuracy: 0.7396\n",
            "Epoch 523/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7909 - val_loss: 0.5653 - val_accuracy: 0.7417\n",
            "Epoch 524/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7900 - val_loss: 0.5656 - val_accuracy: 0.7458\n",
            "Epoch 525/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7891 - val_loss: 0.5636 - val_accuracy: 0.7417\n",
            "Epoch 526/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4471 - accuracy: 0.7882 - val_loss: 0.5637 - val_accuracy: 0.7396\n",
            "Epoch 527/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.7882 - val_loss: 0.5633 - val_accuracy: 0.7375\n",
            "Epoch 528/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.7900 - val_loss: 0.5630 - val_accuracy: 0.7375\n",
            "Epoch 529/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4465 - accuracy: 0.7891 - val_loss: 0.5653 - val_accuracy: 0.7375\n",
            "Epoch 530/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.7891 - val_loss: 0.5668 - val_accuracy: 0.7417\n",
            "Epoch 531/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7882 - val_loss: 0.5642 - val_accuracy: 0.7396\n",
            "Epoch 532/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4471 - accuracy: 0.7882 - val_loss: 0.5667 - val_accuracy: 0.7417\n",
            "Epoch 533/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4470 - accuracy: 0.7891 - val_loss: 0.5652 - val_accuracy: 0.7396\n",
            "Epoch 534/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4476 - accuracy: 0.7918 - val_loss: 0.5668 - val_accuracy: 0.7437\n",
            "Epoch 535/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4468 - accuracy: 0.7909 - val_loss: 0.5673 - val_accuracy: 0.7417\n",
            "Epoch 536/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4469 - accuracy: 0.7891 - val_loss: 0.5695 - val_accuracy: 0.7417\n",
            "Epoch 537/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4467 - accuracy: 0.7891 - val_loss: 0.5680 - val_accuracy: 0.7437\n",
            "Epoch 538/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4464 - accuracy: 0.7891 - val_loss: 0.5688 - val_accuracy: 0.7437\n",
            "Epoch 539/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.7882 - val_loss: 0.5675 - val_accuracy: 0.7417\n",
            "Epoch 540/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4464 - accuracy: 0.7891 - val_loss: 0.5679 - val_accuracy: 0.7437\n",
            "Epoch 541/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4463 - accuracy: 0.7882 - val_loss: 0.5703 - val_accuracy: 0.7458\n",
            "Epoch 542/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4473 - accuracy: 0.7864 - val_loss: 0.5721 - val_accuracy: 0.7458\n",
            "Epoch 543/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4467 - accuracy: 0.7882 - val_loss: 0.5731 - val_accuracy: 0.7437\n",
            "Epoch 544/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4464 - accuracy: 0.7882 - val_loss: 0.5709 - val_accuracy: 0.7417\n",
            "Epoch 545/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.7891 - val_loss: 0.5646 - val_accuracy: 0.7354\n",
            "Epoch 546/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.7900 - val_loss: 0.5622 - val_accuracy: 0.7292\n",
            "Epoch 547/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4474 - accuracy: 0.7900 - val_loss: 0.5650 - val_accuracy: 0.7396\n",
            "Epoch 548/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7927 - val_loss: 0.5675 - val_accuracy: 0.7458\n",
            "Epoch 549/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7909 - val_loss: 0.5668 - val_accuracy: 0.7458\n",
            "Epoch 550/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4461 - accuracy: 0.7918 - val_loss: 0.5677 - val_accuracy: 0.7417\n",
            "Epoch 551/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4459 - accuracy: 0.7909 - val_loss: 0.5660 - val_accuracy: 0.7479\n",
            "Epoch 552/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4463 - accuracy: 0.7873 - val_loss: 0.5645 - val_accuracy: 0.7437\n",
            "Epoch 553/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4465 - accuracy: 0.7900 - val_loss: 0.5645 - val_accuracy: 0.7417\n",
            "Epoch 554/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4459 - accuracy: 0.7900 - val_loss: 0.5658 - val_accuracy: 0.7437\n",
            "Epoch 555/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4461 - accuracy: 0.7945 - val_loss: 0.5681 - val_accuracy: 0.7437\n",
            "Epoch 556/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4462 - accuracy: 0.7891 - val_loss: 0.5669 - val_accuracy: 0.7458\n",
            "Epoch 557/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4459 - accuracy: 0.7882 - val_loss: 0.5678 - val_accuracy: 0.7458\n",
            "Epoch 558/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4459 - accuracy: 0.7891 - val_loss: 0.5694 - val_accuracy: 0.7458\n",
            "Epoch 559/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.7927 - val_loss: 0.5707 - val_accuracy: 0.7437\n",
            "Epoch 560/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7882 - val_loss: 0.5666 - val_accuracy: 0.7458\n",
            "Epoch 561/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.7891 - val_loss: 0.5677 - val_accuracy: 0.7417\n",
            "Epoch 562/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.7909 - val_loss: 0.5657 - val_accuracy: 0.7417\n",
            "Epoch 563/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4458 - accuracy: 0.7918 - val_loss: 0.5644 - val_accuracy: 0.7417\n",
            "Epoch 564/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4458 - accuracy: 0.7927 - val_loss: 0.5672 - val_accuracy: 0.7417\n",
            "Epoch 565/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4453 - accuracy: 0.7927 - val_loss: 0.5679 - val_accuracy: 0.7417\n",
            "Epoch 566/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4454 - accuracy: 0.7882 - val_loss: 0.5697 - val_accuracy: 0.7437\n",
            "Epoch 567/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4457 - accuracy: 0.7891 - val_loss: 0.5684 - val_accuracy: 0.7437\n",
            "Epoch 568/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.7900 - val_loss: 0.5678 - val_accuracy: 0.7417\n",
            "Epoch 569/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.4452 - accuracy: 0.7882 - val_loss: 0.5675 - val_accuracy: 0.7417\n",
            "Epoch 570/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4451 - accuracy: 0.7927 - val_loss: 0.5679 - val_accuracy: 0.7396\n",
            "Epoch 571/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.4452 - accuracy: 0.7891 - val_loss: 0.5698 - val_accuracy: 0.7437\n",
            "Epoch 572/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4451 - accuracy: 0.7900 - val_loss: 0.5717 - val_accuracy: 0.7437\n",
            "Epoch 573/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4452 - accuracy: 0.7918 - val_loss: 0.5715 - val_accuracy: 0.7437\n",
            "Epoch 574/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4451 - accuracy: 0.7873 - val_loss: 0.5691 - val_accuracy: 0.7417\n",
            "Epoch 575/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.4451 - accuracy: 0.7945 - val_loss: 0.5711 - val_accuracy: 0.7479\n",
            "Epoch 576/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4445 - accuracy: 0.7927 - val_loss: 0.5678 - val_accuracy: 0.7437\n",
            "Epoch 577/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4453 - accuracy: 0.7909 - val_loss: 0.5682 - val_accuracy: 0.7437\n",
            "Epoch 578/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4449 - accuracy: 0.7891 - val_loss: 0.5695 - val_accuracy: 0.7437\n",
            "Epoch 579/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4450 - accuracy: 0.7900 - val_loss: 0.5684 - val_accuracy: 0.7437\n",
            "Epoch 580/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.7918 - val_loss: 0.5706 - val_accuracy: 0.7458\n",
            "Epoch 581/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.7927 - val_loss: 0.5688 - val_accuracy: 0.7458\n",
            "Epoch 582/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4461 - accuracy: 0.7918 - val_loss: 0.5674 - val_accuracy: 0.7458\n",
            "Epoch 583/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4447 - accuracy: 0.7927 - val_loss: 0.5707 - val_accuracy: 0.7437\n",
            "Epoch 584/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4450 - accuracy: 0.7918 - val_loss: 0.5745 - val_accuracy: 0.7437\n",
            "Epoch 585/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.7927 - val_loss: 0.5699 - val_accuracy: 0.7437\n",
            "Epoch 586/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4454 - accuracy: 0.7900 - val_loss: 0.5689 - val_accuracy: 0.7479\n",
            "Epoch 587/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4448 - accuracy: 0.7900 - val_loss: 0.5714 - val_accuracy: 0.7437\n",
            "Epoch 588/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.7891 - val_loss: 0.5735 - val_accuracy: 0.7417\n",
            "Epoch 589/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7909 - val_loss: 0.5759 - val_accuracy: 0.7479\n",
            "Epoch 590/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.7918 - val_loss: 0.5710 - val_accuracy: 0.7458\n",
            "Epoch 591/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4446 - accuracy: 0.7936 - val_loss: 0.5696 - val_accuracy: 0.7437\n",
            "Epoch 592/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4445 - accuracy: 0.7927 - val_loss: 0.5701 - val_accuracy: 0.7437\n",
            "Epoch 593/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.7918 - val_loss: 0.5712 - val_accuracy: 0.7437\n",
            "Epoch 594/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7927 - val_loss: 0.5735 - val_accuracy: 0.7458\n",
            "Epoch 595/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4446 - accuracy: 0.7927 - val_loss: 0.5698 - val_accuracy: 0.7458\n",
            "Epoch 596/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4444 - accuracy: 0.7962 - val_loss: 0.5681 - val_accuracy: 0.7458\n",
            "Epoch 597/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.7936 - val_loss: 0.5696 - val_accuracy: 0.7417\n",
            "Epoch 598/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4442 - accuracy: 0.7927 - val_loss: 0.5694 - val_accuracy: 0.7417\n",
            "Epoch 599/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4444 - accuracy: 0.7909 - val_loss: 0.5681 - val_accuracy: 0.7417\n",
            "Epoch 600/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.7909 - val_loss: 0.5711 - val_accuracy: 0.7437\n",
            "Epoch 601/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4441 - accuracy: 0.7927 - val_loss: 0.5730 - val_accuracy: 0.7479\n",
            "Epoch 602/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.7891 - val_loss: 0.5711 - val_accuracy: 0.7458\n",
            "Epoch 603/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.7909 - val_loss: 0.5695 - val_accuracy: 0.7458\n",
            "Epoch 604/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4438 - accuracy: 0.7918 - val_loss: 0.5715 - val_accuracy: 0.7458\n",
            "Epoch 605/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.7918 - val_loss: 0.5714 - val_accuracy: 0.7458\n",
            "Epoch 606/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4441 - accuracy: 0.7918 - val_loss: 0.5707 - val_accuracy: 0.7458\n",
            "Epoch 607/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4443 - accuracy: 0.7945 - val_loss: 0.5710 - val_accuracy: 0.7458\n",
            "Epoch 608/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4443 - accuracy: 0.7918 - val_loss: 0.5709 - val_accuracy: 0.7458\n",
            "Epoch 609/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.7918 - val_loss: 0.5703 - val_accuracy: 0.7437\n",
            "Epoch 610/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7927 - val_loss: 0.5691 - val_accuracy: 0.7479\n",
            "Epoch 611/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7936 - val_loss: 0.5717 - val_accuracy: 0.7458\n",
            "Epoch 612/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7936 - val_loss: 0.5702 - val_accuracy: 0.7479\n",
            "Epoch 613/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7927 - val_loss: 0.5713 - val_accuracy: 0.7479\n",
            "Epoch 614/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7936 - val_loss: 0.5709 - val_accuracy: 0.7479\n",
            "Epoch 615/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.7954 - val_loss: 0.5751 - val_accuracy: 0.7458\n",
            "Epoch 616/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7936 - val_loss: 0.5765 - val_accuracy: 0.7479\n",
            "Epoch 617/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7918 - val_loss: 0.5739 - val_accuracy: 0.7458\n",
            "Epoch 618/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.7927 - val_loss: 0.5723 - val_accuracy: 0.7458\n",
            "Epoch 619/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.7918 - val_loss: 0.5662 - val_accuracy: 0.7458\n",
            "Epoch 620/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7962 - val_loss: 0.5679 - val_accuracy: 0.7375\n",
            "Epoch 621/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7962 - val_loss: 0.5703 - val_accuracy: 0.7437\n",
            "Epoch 622/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7954 - val_loss: 0.5735 - val_accuracy: 0.7437\n",
            "Epoch 623/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7954 - val_loss: 0.5722 - val_accuracy: 0.7437\n",
            "Epoch 624/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7918 - val_loss: 0.5740 - val_accuracy: 0.7417\n",
            "Epoch 625/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7918 - val_loss: 0.5724 - val_accuracy: 0.7437\n",
            "Epoch 626/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7927 - val_loss: 0.5709 - val_accuracy: 0.7437\n",
            "Epoch 627/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7927 - val_loss: 0.5696 - val_accuracy: 0.7437\n",
            "Epoch 628/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7945 - val_loss: 0.5719 - val_accuracy: 0.7458\n",
            "Epoch 629/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7918 - val_loss: 0.5713 - val_accuracy: 0.7417\n",
            "Epoch 630/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7918 - val_loss: 0.5720 - val_accuracy: 0.7437\n",
            "Epoch 631/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7900 - val_loss: 0.5720 - val_accuracy: 0.7417\n",
            "Epoch 632/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4431 - accuracy: 0.7891 - val_loss: 0.5722 - val_accuracy: 0.7417\n",
            "Epoch 633/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7918 - val_loss: 0.5724 - val_accuracy: 0.7417\n",
            "Epoch 634/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4429 - accuracy: 0.7936 - val_loss: 0.5737 - val_accuracy: 0.7437\n",
            "Epoch 635/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7918 - val_loss: 0.5749 - val_accuracy: 0.7437\n",
            "Epoch 636/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7918 - val_loss: 0.5727 - val_accuracy: 0.7458\n",
            "Epoch 637/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7900 - val_loss: 0.5741 - val_accuracy: 0.7437\n",
            "Epoch 638/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7918 - val_loss: 0.5730 - val_accuracy: 0.7458\n",
            "Epoch 639/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4433 - accuracy: 0.7945 - val_loss: 0.5708 - val_accuracy: 0.7417\n",
            "Epoch 640/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7918 - val_loss: 0.5766 - val_accuracy: 0.7437\n",
            "Epoch 641/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4433 - accuracy: 0.7900 - val_loss: 0.5767 - val_accuracy: 0.7458\n",
            "Epoch 642/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7918 - val_loss: 0.5761 - val_accuracy: 0.7437\n",
            "Epoch 643/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4427 - accuracy: 0.7900 - val_loss: 0.5750 - val_accuracy: 0.7458\n",
            "Epoch 644/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7918 - val_loss: 0.5747 - val_accuracy: 0.7417\n",
            "Epoch 645/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7900 - val_loss: 0.5730 - val_accuracy: 0.7437\n",
            "Epoch 646/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.7909 - val_loss: 0.5712 - val_accuracy: 0.7437\n",
            "Epoch 647/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7945 - val_loss: 0.5740 - val_accuracy: 0.7458\n",
            "Epoch 648/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7927 - val_loss: 0.5749 - val_accuracy: 0.7417\n",
            "Epoch 649/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7891 - val_loss: 0.5753 - val_accuracy: 0.7417\n",
            "Epoch 650/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7918 - val_loss: 0.5760 - val_accuracy: 0.7417\n",
            "Epoch 651/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7927 - val_loss: 0.5743 - val_accuracy: 0.7396\n",
            "Epoch 652/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4425 - accuracy: 0.7927 - val_loss: 0.5751 - val_accuracy: 0.7417\n",
            "Epoch 653/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7927 - val_loss: 0.5752 - val_accuracy: 0.7417\n",
            "Epoch 654/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7945 - val_loss: 0.5740 - val_accuracy: 0.7437\n",
            "Epoch 655/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.7891 - val_loss: 0.5768 - val_accuracy: 0.7375\n",
            "Epoch 656/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4429 - accuracy: 0.7855 - val_loss: 0.5800 - val_accuracy: 0.7354\n",
            "Epoch 657/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4425 - accuracy: 0.7882 - val_loss: 0.5775 - val_accuracy: 0.7437\n",
            "Epoch 658/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4431 - accuracy: 0.7900 - val_loss: 0.5738 - val_accuracy: 0.7458\n",
            "Epoch 659/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.7945 - val_loss: 0.5766 - val_accuracy: 0.7437\n",
            "Epoch 660/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4423 - accuracy: 0.7909 - val_loss: 0.5788 - val_accuracy: 0.7396\n",
            "Epoch 661/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.7900 - val_loss: 0.5759 - val_accuracy: 0.7458\n",
            "Epoch 662/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.7909 - val_loss: 0.5771 - val_accuracy: 0.7458\n",
            "Epoch 663/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4422 - accuracy: 0.7900 - val_loss: 0.5792 - val_accuracy: 0.7437\n",
            "Epoch 664/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.7891 - val_loss: 0.5786 - val_accuracy: 0.7437\n",
            "Epoch 665/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7918 - val_loss: 0.5742 - val_accuracy: 0.7437\n",
            "Epoch 666/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.7918 - val_loss: 0.5747 - val_accuracy: 0.7437\n",
            "Epoch 667/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4421 - accuracy: 0.7927 - val_loss: 0.5764 - val_accuracy: 0.7437\n",
            "Epoch 668/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.7891 - val_loss: 0.5818 - val_accuracy: 0.7396\n",
            "Epoch 669/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4424 - accuracy: 0.7882 - val_loss: 0.5830 - val_accuracy: 0.7396\n",
            "Epoch 670/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4418 - accuracy: 0.7909 - val_loss: 0.5796 - val_accuracy: 0.7437\n",
            "Epoch 671/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7927 - val_loss: 0.5793 - val_accuracy: 0.7437\n",
            "Epoch 672/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4421 - accuracy: 0.7936 - val_loss: 0.5768 - val_accuracy: 0.7458\n",
            "Epoch 673/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4418 - accuracy: 0.7945 - val_loss: 0.5819 - val_accuracy: 0.7396\n",
            "Epoch 674/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.7900 - val_loss: 0.5865 - val_accuracy: 0.7396\n",
            "Epoch 675/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4423 - accuracy: 0.7909 - val_loss: 0.5832 - val_accuracy: 0.7396\n",
            "Epoch 676/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4415 - accuracy: 0.7891 - val_loss: 0.5806 - val_accuracy: 0.7437\n",
            "Epoch 677/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.7909 - val_loss: 0.5759 - val_accuracy: 0.7437\n",
            "Epoch 678/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.7909 - val_loss: 0.5769 - val_accuracy: 0.7437\n",
            "Epoch 679/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.7918 - val_loss: 0.5756 - val_accuracy: 0.7479\n",
            "Epoch 680/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.7936 - val_loss: 0.5773 - val_accuracy: 0.7458\n",
            "Epoch 681/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.7927 - val_loss: 0.5794 - val_accuracy: 0.7437\n",
            "Epoch 682/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4417 - accuracy: 0.7927 - val_loss: 0.5773 - val_accuracy: 0.7479\n",
            "Epoch 683/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.7927 - val_loss: 0.5786 - val_accuracy: 0.7479\n",
            "Epoch 684/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.7927 - val_loss: 0.5810 - val_accuracy: 0.7437\n",
            "Epoch 685/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4418 - accuracy: 0.7927 - val_loss: 0.5811 - val_accuracy: 0.7458\n",
            "Epoch 686/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.7900 - val_loss: 0.5822 - val_accuracy: 0.7417\n",
            "Epoch 687/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.7918 - val_loss: 0.5820 - val_accuracy: 0.7437\n",
            "Epoch 688/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4415 - accuracy: 0.7909 - val_loss: 0.5805 - val_accuracy: 0.7417\n",
            "Epoch 689/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.7918 - val_loss: 0.5808 - val_accuracy: 0.7437\n",
            "Epoch 690/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4415 - accuracy: 0.7900 - val_loss: 0.5829 - val_accuracy: 0.7417\n",
            "Epoch 691/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4413 - accuracy: 0.7891 - val_loss: 0.5818 - val_accuracy: 0.7417\n",
            "Epoch 692/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7900 - val_loss: 0.5812 - val_accuracy: 0.7417\n",
            "Epoch 693/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7909 - val_loss: 0.5809 - val_accuracy: 0.7437\n",
            "Epoch 694/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7900 - val_loss: 0.5809 - val_accuracy: 0.7437\n",
            "Epoch 695/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7936 - val_loss: 0.5812 - val_accuracy: 0.7458\n",
            "Epoch 696/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7891 - val_loss: 0.5817 - val_accuracy: 0.7437\n",
            "Epoch 697/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.7909 - val_loss: 0.5830 - val_accuracy: 0.7458\n",
            "Epoch 698/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7900 - val_loss: 0.5819 - val_accuracy: 0.7458\n",
            "Epoch 699/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7936 - val_loss: 0.5782 - val_accuracy: 0.7479\n",
            "Epoch 700/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7909 - val_loss: 0.5832 - val_accuracy: 0.7437\n",
            "Epoch 701/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.7900 - val_loss: 0.5834 - val_accuracy: 0.7437\n",
            "Epoch 702/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7900 - val_loss: 0.5831 - val_accuracy: 0.7437\n",
            "Epoch 703/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7927 - val_loss: 0.5829 - val_accuracy: 0.7479\n",
            "Epoch 704/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7927 - val_loss: 0.5818 - val_accuracy: 0.7458\n",
            "Epoch 705/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7927 - val_loss: 0.5786 - val_accuracy: 0.7417\n",
            "Epoch 706/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.7918 - val_loss: 0.5818 - val_accuracy: 0.7479\n",
            "Epoch 707/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7909 - val_loss: 0.5870 - val_accuracy: 0.7458\n",
            "Epoch 708/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7927 - val_loss: 0.5882 - val_accuracy: 0.7458\n",
            "Epoch 709/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7936 - val_loss: 0.5839 - val_accuracy: 0.7437\n",
            "Epoch 710/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.7918 - val_loss: 0.5824 - val_accuracy: 0.7458\n",
            "Epoch 711/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7909 - val_loss: 0.5817 - val_accuracy: 0.7458\n",
            "Epoch 712/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7918 - val_loss: 0.5845 - val_accuracy: 0.7417\n",
            "Epoch 713/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.7900 - val_loss: 0.5846 - val_accuracy: 0.7437\n",
            "Epoch 714/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7909 - val_loss: 0.5832 - val_accuracy: 0.7437\n",
            "Epoch 715/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7918 - val_loss: 0.5861 - val_accuracy: 0.7458\n",
            "Epoch 716/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7918 - val_loss: 0.5819 - val_accuracy: 0.7458\n",
            "Epoch 717/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7909 - val_loss: 0.5848 - val_accuracy: 0.7417\n",
            "Epoch 718/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7900 - val_loss: 0.5860 - val_accuracy: 0.7437\n",
            "Epoch 719/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7909 - val_loss: 0.5835 - val_accuracy: 0.7458\n",
            "Epoch 720/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.7918 - val_loss: 0.5833 - val_accuracy: 0.7521\n",
            "Epoch 721/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7918 - val_loss: 0.5829 - val_accuracy: 0.7458\n",
            "Epoch 722/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.7900 - val_loss: 0.5848 - val_accuracy: 0.7458\n",
            "Epoch 723/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7900 - val_loss: 0.5870 - val_accuracy: 0.7458\n",
            "Epoch 724/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7900 - val_loss: 0.5860 - val_accuracy: 0.7458\n",
            "Epoch 725/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.7927 - val_loss: 0.5880 - val_accuracy: 0.7417\n",
            "Epoch 726/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7900 - val_loss: 0.5871 - val_accuracy: 0.7417\n",
            "Epoch 727/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7909 - val_loss: 0.5857 - val_accuracy: 0.7417\n",
            "Epoch 728/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.7918 - val_loss: 0.5831 - val_accuracy: 0.7458\n",
            "Epoch 729/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7891 - val_loss: 0.5833 - val_accuracy: 0.7437\n",
            "Epoch 730/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7927 - val_loss: 0.5877 - val_accuracy: 0.7417\n",
            "Epoch 731/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7900 - val_loss: 0.5855 - val_accuracy: 0.7437\n",
            "Epoch 732/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7909 - val_loss: 0.5861 - val_accuracy: 0.7437\n",
            "Epoch 733/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7891 - val_loss: 0.5868 - val_accuracy: 0.7417\n",
            "Epoch 734/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7909 - val_loss: 0.5858 - val_accuracy: 0.7417\n",
            "Epoch 735/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.7927 - val_loss: 0.5831 - val_accuracy: 0.7500\n",
            "Epoch 736/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.7909 - val_loss: 0.5854 - val_accuracy: 0.7458\n",
            "Epoch 737/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.7900 - val_loss: 0.5874 - val_accuracy: 0.7396\n",
            "Epoch 738/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7909 - val_loss: 0.5848 - val_accuracy: 0.7437\n",
            "Epoch 739/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.7927 - val_loss: 0.5842 - val_accuracy: 0.7458\n",
            "Epoch 740/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7909 - val_loss: 0.5849 - val_accuracy: 0.7500\n",
            "Epoch 741/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7945 - val_loss: 0.5872 - val_accuracy: 0.7458\n",
            "Epoch 742/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7927 - val_loss: 0.5865 - val_accuracy: 0.7458\n",
            "Epoch 743/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7900 - val_loss: 0.5869 - val_accuracy: 0.7437\n",
            "Epoch 744/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7936 - val_loss: 0.5817 - val_accuracy: 0.7500\n",
            "Epoch 745/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7900 - val_loss: 0.5842 - val_accuracy: 0.7479\n",
            "Epoch 746/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7900 - val_loss: 0.5816 - val_accuracy: 0.7458\n",
            "Epoch 747/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7909 - val_loss: 0.5826 - val_accuracy: 0.7500\n",
            "Epoch 748/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7900 - val_loss: 0.5850 - val_accuracy: 0.7479\n",
            "Epoch 749/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7891 - val_loss: 0.5870 - val_accuracy: 0.7437\n",
            "Epoch 750/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.7927 - val_loss: 0.5893 - val_accuracy: 0.7458\n",
            "Epoch 751/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7945 - val_loss: 0.5892 - val_accuracy: 0.7458\n",
            "Epoch 752/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.7945 - val_loss: 0.5898 - val_accuracy: 0.7458\n",
            "Epoch 753/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7927 - val_loss: 0.5858 - val_accuracy: 0.7417\n",
            "Epoch 754/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7873 - val_loss: 0.5843 - val_accuracy: 0.7458\n",
            "Epoch 755/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7882 - val_loss: 0.5856 - val_accuracy: 0.7437\n",
            "Epoch 756/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7900 - val_loss: 0.5887 - val_accuracy: 0.7458\n",
            "Epoch 757/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7873 - val_loss: 0.5894 - val_accuracy: 0.7458\n",
            "Epoch 758/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7891 - val_loss: 0.5906 - val_accuracy: 0.7417\n",
            "Epoch 759/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.7909 - val_loss: 0.5886 - val_accuracy: 0.7437\n",
            "Epoch 760/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4398 - accuracy: 0.7927 - val_loss: 0.5924 - val_accuracy: 0.7437\n",
            "Epoch 761/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7918 - val_loss: 0.5895 - val_accuracy: 0.7437\n",
            "Epoch 762/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7873 - val_loss: 0.5882 - val_accuracy: 0.7458\n",
            "Epoch 763/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4397 - accuracy: 0.7918 - val_loss: 0.5886 - val_accuracy: 0.7500\n",
            "Epoch 764/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7909 - val_loss: 0.5903 - val_accuracy: 0.7500\n",
            "Epoch 765/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7900 - val_loss: 0.5904 - val_accuracy: 0.7458\n",
            "Epoch 766/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7891 - val_loss: 0.5873 - val_accuracy: 0.7500\n",
            "Epoch 767/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7927 - val_loss: 0.5861 - val_accuracy: 0.7563\n",
            "Epoch 768/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7927 - val_loss: 0.5864 - val_accuracy: 0.7542\n",
            "Epoch 769/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7909 - val_loss: 0.5866 - val_accuracy: 0.7542\n",
            "Epoch 770/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7936 - val_loss: 0.5830 - val_accuracy: 0.7542\n",
            "Epoch 771/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.7900 - val_loss: 0.5870 - val_accuracy: 0.7500\n",
            "Epoch 772/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7909 - val_loss: 0.5922 - val_accuracy: 0.7458\n",
            "Epoch 773/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7909 - val_loss: 0.5902 - val_accuracy: 0.7437\n",
            "Epoch 774/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7918 - val_loss: 0.5878 - val_accuracy: 0.7479\n",
            "Epoch 775/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7918 - val_loss: 0.5842 - val_accuracy: 0.7521\n",
            "Epoch 776/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7900 - val_loss: 0.5861 - val_accuracy: 0.7521\n",
            "Epoch 777/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.7918 - val_loss: 0.5890 - val_accuracy: 0.7458\n",
            "Epoch 778/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7918 - val_loss: 0.5898 - val_accuracy: 0.7417\n",
            "Epoch 779/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7918 - val_loss: 0.5880 - val_accuracy: 0.7458\n",
            "Epoch 780/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7918 - val_loss: 0.5860 - val_accuracy: 0.7500\n",
            "Epoch 781/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4392 - accuracy: 0.7900 - val_loss: 0.5891 - val_accuracy: 0.7417\n",
            "Epoch 782/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.7918 - val_loss: 0.5893 - val_accuracy: 0.7417\n",
            "Epoch 783/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4389 - accuracy: 0.7927 - val_loss: 0.5900 - val_accuracy: 0.7375\n",
            "Epoch 784/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7936 - val_loss: 0.5903 - val_accuracy: 0.7417\n",
            "Epoch 785/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7918 - val_loss: 0.5842 - val_accuracy: 0.7500\n",
            "Epoch 786/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7936 - val_loss: 0.5825 - val_accuracy: 0.7479\n",
            "Epoch 787/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7936 - val_loss: 0.5886 - val_accuracy: 0.7437\n",
            "Epoch 788/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7936 - val_loss: 0.5933 - val_accuracy: 0.7458\n",
            "Epoch 789/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7971 - val_loss: 0.5897 - val_accuracy: 0.7500\n",
            "Epoch 790/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7900 - val_loss: 0.5859 - val_accuracy: 0.7521\n",
            "Epoch 791/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7918 - val_loss: 0.5856 - val_accuracy: 0.7521\n",
            "Epoch 792/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7909 - val_loss: 0.5895 - val_accuracy: 0.7417\n",
            "Epoch 793/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.7936 - val_loss: 0.5874 - val_accuracy: 0.7437\n",
            "Epoch 794/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7936 - val_loss: 0.5833 - val_accuracy: 0.7479\n",
            "Epoch 795/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7936 - val_loss: 0.5855 - val_accuracy: 0.7396\n",
            "Epoch 796/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.7936 - val_loss: 0.5885 - val_accuracy: 0.7375\n",
            "Epoch 797/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7918 - val_loss: 0.5922 - val_accuracy: 0.7375\n",
            "Epoch 798/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.7918 - val_loss: 0.5914 - val_accuracy: 0.7458\n",
            "Epoch 799/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7900 - val_loss: 0.5887 - val_accuracy: 0.7479\n",
            "Epoch 800/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7927 - val_loss: 0.5856 - val_accuracy: 0.7500\n",
            "Epoch 801/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7954 - val_loss: 0.5887 - val_accuracy: 0.7500\n",
            "Epoch 802/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7918 - val_loss: 0.5905 - val_accuracy: 0.7375\n",
            "Epoch 803/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7945 - val_loss: 0.5884 - val_accuracy: 0.7458\n",
            "Epoch 804/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7945 - val_loss: 0.5906 - val_accuracy: 0.7417\n",
            "Epoch 805/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7909 - val_loss: 0.5924 - val_accuracy: 0.7417\n",
            "Epoch 806/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7954 - val_loss: 0.5894 - val_accuracy: 0.7458\n",
            "Epoch 807/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7918 - val_loss: 0.5909 - val_accuracy: 0.7417\n",
            "Epoch 808/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7954 - val_loss: 0.5877 - val_accuracy: 0.7479\n",
            "Epoch 809/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.7954 - val_loss: 0.5832 - val_accuracy: 0.7458\n",
            "Epoch 810/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.7936 - val_loss: 0.5896 - val_accuracy: 0.7479\n",
            "Epoch 811/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4380 - accuracy: 0.7909 - val_loss: 0.5919 - val_accuracy: 0.7417\n",
            "Epoch 812/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7927 - val_loss: 0.5949 - val_accuracy: 0.7417\n",
            "Epoch 813/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7918 - val_loss: 0.5906 - val_accuracy: 0.7458\n",
            "Epoch 814/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.7909 - val_loss: 0.5881 - val_accuracy: 0.7479\n",
            "Epoch 815/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.7945 - val_loss: 0.5867 - val_accuracy: 0.7458\n",
            "Epoch 816/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7945 - val_loss: 0.5893 - val_accuracy: 0.7437\n",
            "Epoch 817/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7918 - val_loss: 0.5910 - val_accuracy: 0.7479\n",
            "Epoch 818/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7945 - val_loss: 0.5916 - val_accuracy: 0.7437\n",
            "Epoch 819/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7945 - val_loss: 0.5910 - val_accuracy: 0.7417\n",
            "Epoch 820/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7936 - val_loss: 0.5876 - val_accuracy: 0.7437\n",
            "Epoch 821/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7936 - val_loss: 0.5895 - val_accuracy: 0.7396\n",
            "Epoch 822/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7936 - val_loss: 0.5888 - val_accuracy: 0.7417\n",
            "Epoch 823/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4375 - accuracy: 0.7927 - val_loss: 0.5907 - val_accuracy: 0.7437\n",
            "Epoch 824/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7909 - val_loss: 0.5921 - val_accuracy: 0.7458\n",
            "Epoch 825/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7900 - val_loss: 0.5933 - val_accuracy: 0.7417\n",
            "Epoch 826/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4377 - accuracy: 0.7909 - val_loss: 0.5919 - val_accuracy: 0.7375\n",
            "Epoch 827/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.7927 - val_loss: 0.5939 - val_accuracy: 0.7396\n",
            "Epoch 828/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7936 - val_loss: 0.5943 - val_accuracy: 0.7417\n",
            "Epoch 829/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.7918 - val_loss: 0.5920 - val_accuracy: 0.7396\n",
            "Epoch 830/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.7909 - val_loss: 0.5919 - val_accuracy: 0.7417\n",
            "Epoch 831/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7909 - val_loss: 0.5910 - val_accuracy: 0.7437\n",
            "Epoch 832/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.7927 - val_loss: 0.5961 - val_accuracy: 0.7417\n",
            "Epoch 833/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7927 - val_loss: 0.5946 - val_accuracy: 0.7375\n",
            "Epoch 834/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7918 - val_loss: 0.5945 - val_accuracy: 0.7375\n",
            "Epoch 835/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7927 - val_loss: 0.5921 - val_accuracy: 0.7417\n",
            "Epoch 836/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7918 - val_loss: 0.5951 - val_accuracy: 0.7458\n",
            "Epoch 837/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4373 - accuracy: 0.7936 - val_loss: 0.5969 - val_accuracy: 0.7396\n",
            "Epoch 838/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7936 - val_loss: 0.5967 - val_accuracy: 0.7417\n",
            "Epoch 839/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7918 - val_loss: 0.5930 - val_accuracy: 0.7417\n",
            "Epoch 840/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7918 - val_loss: 0.5941 - val_accuracy: 0.7396\n",
            "Epoch 841/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.7909 - val_loss: 0.5930 - val_accuracy: 0.7437\n",
            "Epoch 842/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7945 - val_loss: 0.5949 - val_accuracy: 0.7458\n",
            "Epoch 843/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4382 - accuracy: 0.7909 - val_loss: 0.5899 - val_accuracy: 0.7479\n",
            "Epoch 844/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7909 - val_loss: 0.5921 - val_accuracy: 0.7479\n",
            "Epoch 845/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.7882 - val_loss: 0.5966 - val_accuracy: 0.7479\n",
            "Epoch 846/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7918 - val_loss: 0.5938 - val_accuracy: 0.7479\n",
            "Epoch 847/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7900 - val_loss: 0.5917 - val_accuracy: 0.7458\n",
            "Epoch 848/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4368 - accuracy: 0.7900 - val_loss: 0.5934 - val_accuracy: 0.7417\n",
            "Epoch 849/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.7900 - val_loss: 0.5936 - val_accuracy: 0.7396\n",
            "Epoch 850/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7891 - val_loss: 0.5953 - val_accuracy: 0.7437\n",
            "Epoch 851/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4378 - accuracy: 0.7927 - val_loss: 0.5888 - val_accuracy: 0.7458\n",
            "Epoch 852/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7954 - val_loss: 0.5931 - val_accuracy: 0.7458\n",
            "Epoch 853/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.7909 - val_loss: 0.5938 - val_accuracy: 0.7479\n",
            "Epoch 854/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7936 - val_loss: 0.5958 - val_accuracy: 0.7417\n",
            "Epoch 855/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7971 - val_loss: 0.5978 - val_accuracy: 0.7437\n",
            "Epoch 856/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7971 - val_loss: 0.5953 - val_accuracy: 0.7417\n",
            "Epoch 857/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7936 - val_loss: 0.5922 - val_accuracy: 0.7375\n",
            "Epoch 858/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.7971 - val_loss: 0.5914 - val_accuracy: 0.7396\n",
            "Epoch 859/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7936 - val_loss: 0.5973 - val_accuracy: 0.7396\n",
            "Epoch 860/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7909 - val_loss: 0.5958 - val_accuracy: 0.7437\n",
            "Epoch 861/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.7927 - val_loss: 0.5958 - val_accuracy: 0.7437\n",
            "Epoch 862/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7918 - val_loss: 0.5944 - val_accuracy: 0.7437\n",
            "Epoch 863/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.7927 - val_loss: 0.5978 - val_accuracy: 0.7396\n",
            "Epoch 864/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.7945 - val_loss: 0.5955 - val_accuracy: 0.7458\n",
            "Epoch 865/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7936 - val_loss: 0.5974 - val_accuracy: 0.7437\n",
            "Epoch 866/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.7927 - val_loss: 0.5988 - val_accuracy: 0.7458\n",
            "Epoch 867/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.7945 - val_loss: 0.5955 - val_accuracy: 0.7354\n",
            "Epoch 868/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7927 - val_loss: 0.5972 - val_accuracy: 0.7396\n",
            "Epoch 869/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7989 - val_loss: 0.5951 - val_accuracy: 0.7396\n",
            "Epoch 870/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7945 - val_loss: 0.5973 - val_accuracy: 0.7417\n",
            "Epoch 871/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7936 - val_loss: 0.5971 - val_accuracy: 0.7458\n",
            "Epoch 872/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.7945 - val_loss: 0.5986 - val_accuracy: 0.7479\n",
            "Epoch 873/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7971 - val_loss: 0.6002 - val_accuracy: 0.7437\n",
            "Epoch 874/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.7954 - val_loss: 0.5981 - val_accuracy: 0.7417\n",
            "Epoch 875/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7936 - val_loss: 0.5956 - val_accuracy: 0.7396\n",
            "Epoch 876/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7954 - val_loss: 0.5979 - val_accuracy: 0.7437\n",
            "Epoch 877/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4362 - accuracy: 0.7936 - val_loss: 0.6003 - val_accuracy: 0.7458\n",
            "Epoch 878/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.7954 - val_loss: 0.6008 - val_accuracy: 0.7500\n",
            "Epoch 879/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7954 - val_loss: 0.5983 - val_accuracy: 0.7458\n",
            "Epoch 880/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7936 - val_loss: 0.5987 - val_accuracy: 0.7437\n",
            "Epoch 881/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7927 - val_loss: 0.5973 - val_accuracy: 0.7458\n",
            "Epoch 882/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.7954 - val_loss: 0.5966 - val_accuracy: 0.7458\n",
            "Epoch 883/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.7945 - val_loss: 0.5978 - val_accuracy: 0.7417\n",
            "Epoch 884/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4362 - accuracy: 0.7962 - val_loss: 0.5962 - val_accuracy: 0.7437\n",
            "Epoch 885/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7980 - val_loss: 0.5972 - val_accuracy: 0.7417\n",
            "Epoch 886/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.7971 - val_loss: 0.5956 - val_accuracy: 0.7396\n",
            "Epoch 887/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7989 - val_loss: 0.5971 - val_accuracy: 0.7417\n",
            "Epoch 888/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4355 - accuracy: 0.7989 - val_loss: 0.5968 - val_accuracy: 0.7437\n",
            "Epoch 889/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4361 - accuracy: 0.7945 - val_loss: 0.5995 - val_accuracy: 0.7437\n",
            "Epoch 890/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7954 - val_loss: 0.5967 - val_accuracy: 0.7417\n",
            "Epoch 891/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7962 - val_loss: 0.5949 - val_accuracy: 0.7437\n",
            "Epoch 892/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7971 - val_loss: 0.5964 - val_accuracy: 0.7396\n",
            "Epoch 893/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.7954 - val_loss: 0.5984 - val_accuracy: 0.7417\n",
            "Epoch 894/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7971 - val_loss: 0.5952 - val_accuracy: 0.7458\n",
            "Epoch 895/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7954 - val_loss: 0.5995 - val_accuracy: 0.7437\n",
            "Epoch 896/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7980 - val_loss: 0.5993 - val_accuracy: 0.7417\n",
            "Epoch 897/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.7971 - val_loss: 0.6013 - val_accuracy: 0.7396\n",
            "Epoch 898/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7927 - val_loss: 0.5995 - val_accuracy: 0.7396\n",
            "Epoch 899/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7954 - val_loss: 0.6008 - val_accuracy: 0.7417\n",
            "Epoch 900/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.7971 - val_loss: 0.6014 - val_accuracy: 0.7417\n",
            "Epoch 901/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7980 - val_loss: 0.6003 - val_accuracy: 0.7396\n",
            "Epoch 902/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7980 - val_loss: 0.6001 - val_accuracy: 0.7417\n",
            "Epoch 903/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.7989 - val_loss: 0.5963 - val_accuracy: 0.7333\n",
            "Epoch 904/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7971 - val_loss: 0.5982 - val_accuracy: 0.7396\n",
            "Epoch 905/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7927 - val_loss: 0.5979 - val_accuracy: 0.7354\n",
            "Epoch 906/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4363 - accuracy: 0.7971 - val_loss: 0.6000 - val_accuracy: 0.7396\n",
            "Epoch 907/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7962 - val_loss: 0.5996 - val_accuracy: 0.7354\n",
            "Epoch 908/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7945 - val_loss: 0.6013 - val_accuracy: 0.7437\n",
            "Epoch 909/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7954 - val_loss: 0.6021 - val_accuracy: 0.7479\n",
            "Epoch 910/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7962 - val_loss: 0.6013 - val_accuracy: 0.7437\n",
            "Epoch 911/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7962 - val_loss: 0.6014 - val_accuracy: 0.7458\n",
            "Epoch 912/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7980 - val_loss: 0.5987 - val_accuracy: 0.7417\n",
            "Epoch 913/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7962 - val_loss: 0.5983 - val_accuracy: 0.7396\n",
            "Epoch 914/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4349 - accuracy: 0.7962 - val_loss: 0.5988 - val_accuracy: 0.7396\n",
            "Epoch 915/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7980 - val_loss: 0.5997 - val_accuracy: 0.7417\n",
            "Epoch 916/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4348 - accuracy: 0.7962 - val_loss: 0.6017 - val_accuracy: 0.7437\n",
            "Epoch 917/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.7936 - val_loss: 0.6036 - val_accuracy: 0.7354\n",
            "Epoch 918/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.7971 - val_loss: 0.6002 - val_accuracy: 0.7396\n",
            "Epoch 919/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7954 - val_loss: 0.6000 - val_accuracy: 0.7375\n",
            "Epoch 920/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4346 - accuracy: 0.7954 - val_loss: 0.6033 - val_accuracy: 0.7479\n",
            "Epoch 921/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7936 - val_loss: 0.6066 - val_accuracy: 0.7479\n",
            "Epoch 922/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7909 - val_loss: 0.6010 - val_accuracy: 0.7437\n",
            "Epoch 923/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.7962 - val_loss: 0.6034 - val_accuracy: 0.7417\n",
            "Epoch 924/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.7927 - val_loss: 0.5981 - val_accuracy: 0.7333\n",
            "Epoch 925/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7945 - val_loss: 0.6007 - val_accuracy: 0.7396\n",
            "Epoch 926/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.7909 - val_loss: 0.6073 - val_accuracy: 0.7437\n",
            "Epoch 927/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7945 - val_loss: 0.6045 - val_accuracy: 0.7375\n",
            "Epoch 928/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.7936 - val_loss: 0.6032 - val_accuracy: 0.7417\n",
            "Epoch 929/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7936 - val_loss: 0.6024 - val_accuracy: 0.7417\n",
            "Epoch 930/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.7945 - val_loss: 0.6014 - val_accuracy: 0.7396\n",
            "Epoch 931/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4348 - accuracy: 0.7962 - val_loss: 0.6045 - val_accuracy: 0.7417\n",
            "Epoch 932/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4347 - accuracy: 0.7980 - val_loss: 0.6057 - val_accuracy: 0.7375\n",
            "Epoch 933/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4349 - accuracy: 0.7945 - val_loss: 0.6071 - val_accuracy: 0.7437\n",
            "Epoch 934/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7962 - val_loss: 0.6019 - val_accuracy: 0.7437\n",
            "Epoch 935/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.8007 - val_loss: 0.5995 - val_accuracy: 0.7458\n",
            "Epoch 936/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.7998 - val_loss: 0.6011 - val_accuracy: 0.7417\n",
            "Epoch 937/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.7971 - val_loss: 0.6000 - val_accuracy: 0.7437\n",
            "Epoch 938/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.7980 - val_loss: 0.6012 - val_accuracy: 0.7458\n",
            "Epoch 939/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7962 - val_loss: 0.6054 - val_accuracy: 0.7458\n",
            "Epoch 940/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7936 - val_loss: 0.6036 - val_accuracy: 0.7458\n",
            "Epoch 941/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.7962 - val_loss: 0.6075 - val_accuracy: 0.7458\n",
            "Epoch 942/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7980 - val_loss: 0.6063 - val_accuracy: 0.7458\n",
            "Epoch 943/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.7962 - val_loss: 0.6093 - val_accuracy: 0.7437\n",
            "Epoch 944/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7962 - val_loss: 0.6019 - val_accuracy: 0.7396\n",
            "Epoch 945/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.7936 - val_loss: 0.6027 - val_accuracy: 0.7458\n",
            "Epoch 946/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7945 - val_loss: 0.6097 - val_accuracy: 0.7396\n",
            "Epoch 947/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4345 - accuracy: 0.7936 - val_loss: 0.6046 - val_accuracy: 0.7437\n",
            "Epoch 948/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4343 - accuracy: 0.7945 - val_loss: 0.6027 - val_accuracy: 0.7437\n",
            "Epoch 949/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7936 - val_loss: 0.6017 - val_accuracy: 0.7396\n",
            "Epoch 950/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4347 - accuracy: 0.7936 - val_loss: 0.6056 - val_accuracy: 0.7437\n",
            "Epoch 951/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7971 - val_loss: 0.6051 - val_accuracy: 0.7458\n",
            "Epoch 952/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.7962 - val_loss: 0.6078 - val_accuracy: 0.7417\n",
            "Epoch 953/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4348 - accuracy: 0.7989 - val_loss: 0.6045 - val_accuracy: 0.7417\n",
            "Epoch 954/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.7954 - val_loss: 0.6056 - val_accuracy: 0.7375\n",
            "Epoch 955/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7971 - val_loss: 0.6064 - val_accuracy: 0.7458\n",
            "Epoch 956/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.7954 - val_loss: 0.6094 - val_accuracy: 0.7417\n",
            "Epoch 957/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7998 - val_loss: 0.6067 - val_accuracy: 0.7417\n",
            "Epoch 958/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4346 - accuracy: 0.7971 - val_loss: 0.5999 - val_accuracy: 0.7417\n",
            "Epoch 959/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4346 - accuracy: 0.7954 - val_loss: 0.6013 - val_accuracy: 0.7417\n",
            "Epoch 960/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7971 - val_loss: 0.6051 - val_accuracy: 0.7458\n",
            "Epoch 961/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.7954 - val_loss: 0.6031 - val_accuracy: 0.7458\n",
            "Epoch 962/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.7980 - val_loss: 0.6032 - val_accuracy: 0.7437\n",
            "Epoch 963/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.7989 - val_loss: 0.6026 - val_accuracy: 0.7479\n",
            "Epoch 964/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.8007 - val_loss: 0.6024 - val_accuracy: 0.7479\n",
            "Epoch 965/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.7971 - val_loss: 0.6079 - val_accuracy: 0.7500\n",
            "Epoch 966/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.8016 - val_loss: 0.6076 - val_accuracy: 0.7437\n",
            "Epoch 967/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7980 - val_loss: 0.6009 - val_accuracy: 0.7479\n",
            "Epoch 968/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.7954 - val_loss: 0.5991 - val_accuracy: 0.7354\n",
            "Epoch 969/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7954 - val_loss: 0.6056 - val_accuracy: 0.7458\n",
            "Epoch 970/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7998 - val_loss: 0.6087 - val_accuracy: 0.7417\n",
            "Epoch 971/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7989 - val_loss: 0.6095 - val_accuracy: 0.7458\n",
            "Epoch 972/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.8007 - val_loss: 0.6036 - val_accuracy: 0.7354\n",
            "Epoch 973/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4347 - accuracy: 0.7998 - val_loss: 0.6005 - val_accuracy: 0.7333\n",
            "Epoch 974/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.7989 - val_loss: 0.6018 - val_accuracy: 0.7312\n",
            "Epoch 975/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.7989 - val_loss: 0.6093 - val_accuracy: 0.7292\n",
            "Epoch 976/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7980 - val_loss: 0.6119 - val_accuracy: 0.7333\n",
            "Epoch 977/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.8007 - val_loss: 0.6160 - val_accuracy: 0.7354\n",
            "Epoch 978/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4344 - accuracy: 0.8025 - val_loss: 0.6131 - val_accuracy: 0.7396\n",
            "Epoch 979/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7989 - val_loss: 0.6063 - val_accuracy: 0.7396\n",
            "Epoch 980/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.7954 - val_loss: 0.6102 - val_accuracy: 0.7375\n",
            "Epoch 981/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.7971 - val_loss: 0.6095 - val_accuracy: 0.7333\n",
            "Epoch 982/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.7971 - val_loss: 0.6110 - val_accuracy: 0.7333\n",
            "Epoch 983/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4336 - accuracy: 0.7971 - val_loss: 0.6073 - val_accuracy: 0.7375\n",
            "Epoch 984/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7954 - val_loss: 0.6041 - val_accuracy: 0.7354\n",
            "Epoch 985/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7962 - val_loss: 0.6046 - val_accuracy: 0.7312\n",
            "Epoch 986/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7918 - val_loss: 0.6105 - val_accuracy: 0.7292\n",
            "Epoch 987/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4340 - accuracy: 0.7954 - val_loss: 0.6120 - val_accuracy: 0.7333\n",
            "Epoch 988/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7962 - val_loss: 0.6101 - val_accuracy: 0.7333\n",
            "Epoch 989/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7962 - val_loss: 0.6119 - val_accuracy: 0.7354\n",
            "Epoch 990/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4339 - accuracy: 0.7936 - val_loss: 0.6086 - val_accuracy: 0.7354\n",
            "Epoch 991/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.7962 - val_loss: 0.6081 - val_accuracy: 0.7333\n",
            "Epoch 992/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.7980 - val_loss: 0.6084 - val_accuracy: 0.7333\n",
            "Epoch 993/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7962 - val_loss: 0.6103 - val_accuracy: 0.7333\n",
            "Epoch 994/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4338 - accuracy: 0.7962 - val_loss: 0.6105 - val_accuracy: 0.7333\n",
            "Epoch 995/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7954 - val_loss: 0.6078 - val_accuracy: 0.7312\n",
            "Epoch 996/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4341 - accuracy: 0.7954 - val_loss: 0.6092 - val_accuracy: 0.7312\n",
            "Epoch 997/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4330 - accuracy: 0.7945 - val_loss: 0.6167 - val_accuracy: 0.7396\n",
            "Epoch 998/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7989 - val_loss: 0.6167 - val_accuracy: 0.7396\n",
            "Epoch 999/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7989 - val_loss: 0.6129 - val_accuracy: 0.7333\n",
            "Epoch 1000/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7971 - val_loss: 0.6089 - val_accuracy: 0.7271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlKuGt_VQG6j",
        "outputId": "e868180d-5792-41ad-b35b-fe8a0d097e0e"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6089 - accuracy: 0.7271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Ok4g8eiVQJbr",
        "outputId": "ad5422d5-59b9-42e1-8040-e08a52aadfa6"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Fonction de perte (entropie croisee)')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "drLaZvJkQPVG",
        "outputId": "ecf73570-73c8-4c6f-a27b-11df2984d383"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}